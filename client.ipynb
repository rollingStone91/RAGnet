{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2dfced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "from datasets import load_dataset\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "\n",
    "# DASHSCOPE_API_KEY = os.getenv(\"DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1399b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# 自定义 LangChain 的 Embeddings 类封装\n",
    "class LlamaCppEmbeddings(Embeddings):\n",
    "    def __init__(self, model_path: str):\n",
    "        self.llm = Llama(model_path=model_path, embedding=True)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        # return [self.llm.embed(text)[\"data\"][0][\"embedding\"] for text in texts]\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            result = self.llm.embed(text)\n",
    "            if isinstance(result, list) and isinstance(result[0], list):\n",
    "                embeddings.append(result[0])\n",
    "            else:\n",
    "                embeddings.append(result)\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        # return self.llm.embed(text)[\"data\"][0][\"embedding\"]\n",
    "        result = self.llm.embed(text)\n",
    "        return result[0] if isinstance(result, list) and isinstance(result[0], list) else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb293a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Proof:\n",
    "    \"\"\"\n",
    "    隐私证明数据结构\n",
    "    \"\"\"\n",
    "    def __init__(self, doc_id: str, score: float, vector: List[float], proof_data: Any):\n",
    "        self.doc_id = doc_id\n",
    "        self.score = score\n",
    "        self.vector = vector\n",
    "        self.proof_data = proof_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec073e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    \"\"\"\n",
    "    轻量级rag客户端，负责数据集加载、向量存储构建与检索。\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path: str = \"./models/Qwen3-Embedding/Qwen3-Embedding-0.6B-Q8_0.gguf\", \n",
    "                vectorstore_path: str = \"faiss_db\"): # dashscope_api_key: str,使用api调用embedding模型\n",
    "        os.environ.setdefault(\"KMP_DUPLICATE_LIB_OK\", \"TRUE\")\n",
    "        self.vectorstore_path = vectorstore_path\n",
    "        # self.embeddings = DashScopeEmbeddings(\n",
    "        #     model=\"text-embedding-v1\",\n",
    "        #     dashscope_api_key=dashscope_api_key\n",
    "        # )\n",
    "        self.embeddings = LlamaCppEmbeddings(model_path=model_path)\n",
    "        self.db: FAISS = None\n",
    "\n",
    "    def _chunk_text(self, text: str, chunk_size=1000, overlap= 200) -> list[str]:\n",
    "        \"\"\"\n",
    "        将文本分块处理，使用递归字符分割器。\n",
    "        \"\"\"\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "\n",
    "    def _read_pdfs(self, pdf_paths: List[str]) -> str:\n",
    "        text = []\n",
    "        for path in pdf_paths:\n",
    "            reader = PdfReader(path)\n",
    "            for page in reader.pages:\n",
    "                text.append(page.extract_text() or \"\")\n",
    "        return \"\\n\".join(text)\n",
    "\n",
    "    def build_vectorstore_from_pdf(self, pdf_paths: list[str]) -> None:\n",
    "        \"\"\"\n",
    "        处理pdf文件并构建FAISS向量存储。\n",
    "        \"\"\"\n",
    "        raw = self._read_pdfs(pdf_paths)\n",
    "        chunks = self._chunk_text(raw)\n",
    "        self.db = FAISS.from_texts(chunks, embedding=self.embeddings)\n",
    "        self.db.save_local(self.vectorstore_path)\n",
    "        print(f\"Vectorstore built at '{self.vectorstore_path}' with {len(chunks)} chunks.\")\n",
    "\n",
    "    def build_vectorstore_from_wiki(self, sample_size=100, batch_size=10):\n",
    "        # 启用streaming模式在线读取huggingface datasets\n",
    "        dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", streaming=True)\n",
    "        iterator = iter(dataset[\"train\"])\n",
    "        texts = []\n",
    "        count = 0\n",
    "        for item in iterator:\n",
    "            if count >= sample_size:\n",
    "                break\n",
    "            text = item.get(\"text\", \"\")\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "                count += 1\n",
    "        print(f\"Total collected Wikipedia texts: {len(texts)}\")\n",
    "\n",
    "        # 分块并批量处理\n",
    "        all_chunks = []\n",
    "        for i, text in enumerate(texts):\n",
    "            chunks = self._chunk_text(text)\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "            # 每 batch_size 保存一次，防止内存溢出\n",
    "            if len(all_chunks) >= batch_size or i == len(texts) - 1:\n",
    "                if self.db is None:\n",
    "                    self.db = FAISS.from_texts(all_chunks, embedding=self.embeddings)\n",
    "                else:\n",
    "                    self.db.add_texts(all_chunks)\n",
    "                all_chunks.clear()\n",
    "                print(f\"Processed {i+1}/{len(texts)} articles...\")\n",
    "\n",
    "        # 保存向量库\n",
    "        if self.db:\n",
    "            self.db.save_local(self.vectorstore_path)\n",
    "            print(f\"Vectorstore saved to {self.vectorstore_path}\")\n",
    "        else:\n",
    "            print(\"No data processed.\")\n",
    "\n",
    "    def load_vectorstore(self) -> None:\n",
    "        \"\"\"\n",
    "        加载已保存的向量存储，并初始化检索器。\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.vectorstore_path):\n",
    "            raise FileNotFoundError(f\"Vectorstore directory '{self.vectorstore_path}' not found.\")\n",
    "        self.db = FAISS.load_local(\n",
    "            self.vectorstore_path,\n",
    "            embeddings=self.embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        self.retriever = self.db.as_retriever()\n",
    "        print(\"Vectorstore loaded and retriever initialized.\")\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5) -> Tuple[List[Document], List[List[float]]]:\n",
    "        \"\"\"\n",
    "        对输入 query 执行检索，返回 top_k 最相似文档及其向量。\n",
    "        Output:\n",
    "          docs: List[langchain.schema.Document]\n",
    "          vectors: List[List[float]]\n",
    "        \"\"\"\n",
    "        if self.db is None:\n",
    "            raise RuntimeError(\"Vectorstore 未初始化，调用 load_vectorstore 或 build 方法先初始化。\")\n",
    "        # 生成 query 向量\n",
    "        q_vec = self.embeddings.embed_query(query)\n",
    "        print(q_vec)\n",
    "        # 确保转换成 2D NumPy 数组，FAISS 要求 shape = (n_queries, dim)\n",
    "        if isinstance(q_vec, list):\n",
    "            q_vec = np.array(q_vec, dtype=\"float32\").reshape(1, -1)\n",
    "        # 使用 FAISS 原生 index.search\n",
    "        D, I = self.db.index.search(q_vec, top_k)  # D: 距离, I: 索引ID\n",
    "        docs = []\n",
    "        vecs = []\n",
    "\n",
    "        for idx in I[0]:\n",
    "            if idx == -1:\n",
    "                continue\n",
    "            # 用 LangChain 的 docstore 获取 Document\n",
    "            doc_id = self.db.index_to_docstore_id[idx]\n",
    "            doc = self.db.docstore.search(doc_id)\n",
    "            docs.append(doc)\n",
    "\n",
    "            # 从 FAISS 中 reconstruct 向量\n",
    "            vec = self.db.index.reconstruct(int(idx))\n",
    "            vecs.append(vec)\n",
    "\n",
    "        return docs, vecs\n",
    "        # results = self.db.index.search(q_vec, top_k)\n",
    "        # print(results)\n",
    "        # ids, scores = results[1].tolist()[0], results[0].tolist()[0]\n",
    "        # docs = [self.db.docstore.search(id) for id in ids]\n",
    "        # vecs = [self.db.index.reconstruct(id) for id in ids]\n",
    "        # return docs, vecs\n",
    "\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5) -> Tuple[List[Proof], List[float]]:\n",
    "        \"\"\"\n",
    "        基于检索结果计算 Proof，并返回 proofs 列表及 query 向量。\n",
    "        \"\"\"\n",
    "        docs, vecs = self.retrieve(question, top_k)\n",
    "        proofs: List[Proof] = []\n",
    "        for doc, vec in zip(docs, vecs):\n",
    "            proof_data = {\"doc_id\": doc.metadata[\"source\"], \"merkle_path\": []}\n",
    "            proofs.append(Proof(doc.metadata.get(\"source\", \"\"), score=0.0, vector=vec, proof_data=proof_data))\n",
    "        q_vec = self.embeddings.embed_query(question)\n",
    "        return proofs, q_vec\n",
    "    \n",
    "    # 这一段query包含了调用llm生成答案部分，一种是调用ollama部署的llm，一种是调用api并使用agent工具\n",
    "    # def query(self, question: str) -> str:\n",
    "    #     \"\"\"\n",
    "    #     基于已加载的向量存储进行查询，并返回生成的答案。\n",
    "    #     \"\"\"\n",
    "    #     if self.retriever is None:\n",
    "    #         raise RuntimeError(\"Retriever not initialized. Call 'load_vectorstore()' first.\")\n",
    "    #     llm = ChatOllama(model=self.ollama_model)\n",
    "    #     qa_chain = RetrievalQA.from_chain_type(\n",
    "    #         llm=llm,\n",
    "    #         retriever=self.retriever,\n",
    "    #         chain_type=\"stuff\",\n",
    "    #         return_source_documents=False\n",
    "    #     )\n",
    "    #     result = qa_chain.invoke({\"query\": question})\n",
    "    #     return result[\"result\"]\n",
    "        # 创建检索工具\n",
    "        # retrieval_tool = create_retriever_tool(\n",
    "        #     self.retriever,\n",
    "        #     name=\"pdf_extractor\",\n",
    "        #     description=\"Tool to answer queries based on the processed PDF content.\"\n",
    "        # )\n",
    "\n",
    "        # prompt = ChatPromptTemplate.from_messages([\n",
    "        #     (\"system\", \n",
    "        #      \"\"\"\n",
    "        #      你是AI助手，请根据提供的上下文回答问题，确保提供所有细节，\n",
    "        #      如果答案不在上下文中，请说 '答案不在上下文中'，不要提供错误的答案\n",
    "        #      \"\"\"),\n",
    "        #     (\"human\", \"{input}\"),\n",
    "        #     (\"placeholder\", \"{agent_scratchpad}\")\n",
    "        # ])\n",
    "        # agent = create_tool_calling_agent(llm, [retrieval_tool], prompt)\n",
    "        # executor = AgentExecutor(agent=agent, tools=[retrieval_tool], verbose=False)\n",
    "        # result = executor.invoke({\"input\": question})\n",
    "        # return result.get('output', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9ddfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 36 key-value pairs and 310 tensors from ./models/Qwen3-Embedding/Qwen3-Embedding-0.6B-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen3\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen3 Embedding 0.6b\n",
      "llama_model_loader: - kv   3:                           general.basename str              = qwen3-embedding\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 0.6B\n",
      "llama_model_loader: - kv   5:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   6:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   7:                  general.base_model.0.name str              = Qwen3 0.6B Base\n",
      "llama_model_loader: - kv   8:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv   9:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen3-0.6...\n",
      "llama_model_loader: - kv  10:                               general.tags arr[str,5]       = [\"transformers\", \"sentence-transforme...\n",
      "llama_model_loader: - kv  11:                          qwen3.block_count u32              = 28\n",
      "llama_model_loader: - kv  12:                       qwen3.context_length u32              = 32768\n",
      "llama_model_loader: - kv  13:                     qwen3.embedding_length u32              = 1024\n",
      "llama_model_loader: - kv  14:                  qwen3.feed_forward_length u32              = 3072\n",
      "llama_model_loader: - kv  15:                 qwen3.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  16:              qwen3.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  17:                       qwen3.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  18:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  19:                 qwen3.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  20:               qwen3.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  21:                         qwen3.pooling_type u32              = 3\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,151669]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,151669]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.eot_token_id u32              = 151645\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = true\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  33:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  34:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  35:                          general.file_type u32              = 7\n",
      "llama_model_loader: - type  f32:  113 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 603.87 MiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "load: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "load: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "load: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "load: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "load: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "load: special tokens cache size = 26\n",
      "load: token to piece cache size = 0.9311 MB\n",
      "print_info: arch             = qwen3\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 1024\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 16\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 2\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 3072\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 0.6B\n",
      "print_info: model params     = 595.78 M\n",
      "print_info: general.name     = Qwen3 Embedding 0.6b\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 151669\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOT token        = 151645 '<|im_end|>'\n",
      "print_info: PAD token        = 151643 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
      "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "print_info: EOG token        = 151643 '<|endoftext|>'\n",
      "print_info: EOG token        = 151645 '<|im_end|>'\n",
      "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
      "print_info: EOG token        = 151663 '<|repo_name|>'\n",
      "print_info: EOG token        = 151664 '<|file_sep|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 310 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =   603.87 MiB\n",
      "...........................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 512\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.58 MiB\n",
      "create_memory: n_ctx = 512 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =    56.00 MiB\n",
      "llama_kv_cache_unified: size =   56.00 MiB (   512 cells,  28 layers,  1 seqs), K (f16):   28.00 MiB, V (f16):   28.00 MiB\n",
      "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   298.23 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Qwen3 Embedding 0.6b', 'general.architecture': 'qwen3', 'qwen3.rope.freq_base': '1000000.000000', 'general.base_model.0.name': 'Qwen3 0.6B Base', 'qwen3.attention.layer_norm_rms_epsilon': '0.000001', 'general.type': 'model', 'general.basename': 'qwen3-embedding', 'general.size_label': '0.6B', 'general.license': 'apache-2.0', 'general.base_model.count': '1', 'general.base_model.0.organization': 'Qwen', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen3-0.6B-Base', 'tokenizer.ggml.pre': 'qwen2', 'qwen3.block_count': '28', 'qwen3.context_length': '32768', 'qwen3.embedding_length': '1024', 'qwen3.feed_forward_length': '3072', 'qwen3.attention.head_count': '16', 'qwen3.attention.head_count_kv': '8', 'tokenizer.ggml.add_bos_token': 'false', 'qwen3.attention.key_length': '128', 'qwen3.attention.value_length': '128', 'qwen3.pooling_type': '3', 'tokenizer.ggml.model': 'gpt2', 'general.file_type': '7', 'tokenizer.ggml.eos_token_id': '151643', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eot_token_id': '151645', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151643', 'tokenizer.ggml.add_eos_token': 'true', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0].role == \\'system\\' %}\\n        {{- messages[0].content + \\'\\\\n\\\\n\\' }}\\n    {%- endif %}\\n    {{- \"# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0].role == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0].content + \\'<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\\n{%- for message in messages[::-1] %}\\n    {%- set index = (messages|length - 1) - loop.index0 %}\\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith(\\'<tool_response>\\') and message.content.endswith(\\'</tool_response>\\')) %}\\n        {%- set ns.multi_step_tool = false %}\\n        {%- set ns.last_query_index = index %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {%- set content = message.content %}\\n        {%- set reasoning_content = \\'\\' %}\\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\\n            {%- set reasoning_content = message.reasoning_content %}\\n        {%- else %}\\n            {%- if \\'</think>\\' in message.content %}\\n                {%- set content = message.content.split(\\'</think>\\')[-1].lstrip(\\'\\\\n\\') %}\\n                {%- set reasoning_content = message.content.split(\\'</think>\\')[0].rstrip(\\'\\\\n\\').split(\\'<think>\\')[-1].lstrip(\\'\\\\n\\') %}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if loop.index0 > ns.last_query_index %}\\n            {%- if loop.last or (not loop.last and reasoning_content) %}\\n                {{- \\'<|im_start|>\\' + message.role + \\'\\\\n<think>\\\\n\\' + reasoning_content.strip(\\'\\\\n\\') + \\'\\\\n</think>\\\\n\\\\n\\' + content.lstrip(\\'\\\\n\\') }}\\n            {%- else %}\\n                {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content }}\\n            {%- endif %}\\n        {%- else %}\\n            {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content }}\\n        {%- endif %}\\n        {%- if message.tool_calls %}\\n            {%- for tool_call in message.tool_calls %}\\n                {%- if (loop.first and content) or (not loop.first) %}\\n                    {{- \\'\\\\n\\' }}\\n                {%- endif %}\\n                {%- if tool_call.function %}\\n                    {%- set tool_call = tool_call.function %}\\n                {%- endif %}\\n                {{- \\'<tool_call>\\\\n{\"name\": \"\\' }}\\n                {{- tool_call.name }}\\n                {{- \\'\", \"arguments\": \\' }}\\n                {%- if tool_call.arguments is string %}\\n                    {{- tool_call.arguments }}\\n                {%- else %}\\n                    {{- tool_call.arguments | tojson }}\\n                {%- endif %}\\n                {{- \\'}\\\\n</tool_call>\\' }}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n    {%- if enable_thinking is defined and enable_thinking is false %}\\n        {{- \\'<think>\\\\n\\\\n</think>\\\\n\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for message in messages[::-1] %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set content = message.content %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in message.content %}\n",
      "                {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n",
      "                {%- set reasoning_content = message.content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and reasoning_content) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <|endoftext|>\n",
      "llama_perf_context_print:        load time =    1659.64 ms\n",
      "llama_perf_context_print: prompt eval time =    1653.14 ms /   247 tokens (    6.69 ms per token,   149.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1663.99 ms /   248 tokens\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 构建或加载向量库\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pdf_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRAGnet\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpaper.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# 替换为你的 PDF 路径列表\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vectorstore_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m client\u001b[38;5;241m.\u001b[39mload_vectorstore()\n\u001b[0;32m      7\u001b[0m docs, vecs \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mretrieve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the main topic of the paper?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[68], line 40\u001b[0m, in \u001b[0;36mClient.build_vectorstore_from_pdf\u001b[1;34m(self, pdf_paths)\u001b[0m\n\u001b[0;32m     38\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_pdfs(pdf_paths)\n\u001b[0;32m     39\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_text(raw)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore_path)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorstore built at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chunks.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\rag_env\\lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \n\u001b[0;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1045\u001b[0m         texts,\n\u001b[0;32m   1046\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[66], line 13\u001b[0m, in \u001b[0;36mLlamaCppEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     11\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[1;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     15\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\rag_env\\lib\\site-packages\\llama_cpp\\llama.py:1108\u001b[0m, in \u001b[0;36mLlama.embed\u001b[1;34m(self, input, normalize, truncate, return_count)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     p_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# hanlde last batch\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m \u001b[43mdecode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m   1111\u001b[0m     llama_cpp\u001b[38;5;241m.\u001b[39mllama_perf_context_print(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mctx)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\rag_env\\lib\\site-packages\\llama_cpp\\llama.py:1045\u001b[0m, in \u001b[0;36mLlama.embed.<locals>.decode_batch\u001b[1;34m(seq_sizes)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_batch\u001b[39m(seq_sizes: List[\u001b[38;5;28mint\u001b[39m]):\n\u001b[0;32m   1044\u001b[0m     llama_cpp\u001b[38;5;241m.\u001b[39mllama_kv_self_clear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx\u001b[38;5;241m.\u001b[39mctx)\n\u001b[1;32m-> 1045\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;66;03m# store embeddings\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\rag_env\\lib\\site-packages\\llama_cpp\\_internals.py:316\u001b[0m, in \u001b[0;36mLlamaContext.decode\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[1;32m--> 316\u001b[0m     return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 初始化 RAG 客户端\n",
    "client = Client()\n",
    "# 构建或加载向量库\n",
    "pdf_files = ['D:\\RAGnet\\paper.pdf']\n",
    "client.build_vectorstore_from_pdf(pdf_files)\n",
    "client.load_vectorstore()\n",
    "docs, vecs = client.retrieve(\"What is the main topic of the paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ce5240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 36 key-value pairs and 310 tensors from ./models/Qwen3-Embedding/Qwen3-Embedding-0.6B-Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen3\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen3 Embedding 0.6b\n",
      "llama_model_loader: - kv   3:                           general.basename str              = qwen3-embedding\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 0.6B\n",
      "llama_model_loader: - kv   5:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   6:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   7:                  general.base_model.0.name str              = Qwen3 0.6B Base\n",
      "llama_model_loader: - kv   8:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv   9:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen3-0.6...\n",
      "llama_model_loader: - kv  10:                               general.tags arr[str,5]       = [\"transformers\", \"sentence-transforme...\n",
      "llama_model_loader: - kv  11:                          qwen3.block_count u32              = 28\n",
      "llama_model_loader: - kv  12:                       qwen3.context_length u32              = 32768\n",
      "llama_model_loader: - kv  13:                     qwen3.embedding_length u32              = 1024\n",
      "llama_model_loader: - kv  14:                  qwen3.feed_forward_length u32              = 3072\n",
      "llama_model_loader: - kv  15:                 qwen3.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  16:              qwen3.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  17:                       qwen3.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  18:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  19:                 qwen3.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  20:               qwen3.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  21:                         qwen3.pooling_type u32              = 3\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,151669]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,151669]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.eot_token_id u32              = 151645\n",
      "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = true\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  33:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  34:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  35:                          general.file_type u32              = 7\n",
      "llama_model_loader: - type  f32:  113 tensors\n",
      "llama_model_loader: - type q8_0:  197 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 603.87 MiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "load: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "load: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "load: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "load: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "load: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "load: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "load: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "load: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "load: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "load: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "load: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "load: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "load: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "load: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "load: special tokens cache size = 26\n",
      "load: token to piece cache size = 0.9311 MB\n",
      "print_info: arch             = qwen3\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 1024\n",
      "print_info: n_layer          = 28\n",
      "print_info: n_head           = 16\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 2\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 3072\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 0.6B\n",
      "print_info: model params     = 595.78 M\n",
      "print_info: general.name     = Qwen3 Embedding 0.6b\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 151669\n",
      "print_info: n_merges         = 151387\n",
      "print_info: BOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOS token        = 151643 '<|endoftext|>'\n",
      "print_info: EOT token        = 151645 '<|im_end|>'\n",
      "print_info: PAD token        = 151643 '<|endoftext|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
      "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "print_info: EOG token        = 151643 '<|endoftext|>'\n",
      "print_info: EOG token        = 151645 '<|im_end|>'\n",
      "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
      "print_info: EOG token        = 151663 '<|repo_name|>'\n",
      "print_info: EOG token        = 151664 '<|file_sep|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 310 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =   603.87 MiB\n",
      "...........................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 512\n",
      "llama_context: n_ctx_per_seq = 512\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.58 MiB\n",
      "create_memory: n_ctx = 512 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =    56.00 MiB\n",
      "llama_kv_cache_unified: size =   56.00 MiB (   512 cells,  28 layers,  1 seqs), K (f16):   28.00 MiB, V (f16):   28.00 MiB\n",
      "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   298.23 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Qwen3 Embedding 0.6b', 'general.architecture': 'qwen3', 'qwen3.rope.freq_base': '1000000.000000', 'general.base_model.0.name': 'Qwen3 0.6B Base', 'qwen3.attention.layer_norm_rms_epsilon': '0.000001', 'general.type': 'model', 'general.basename': 'qwen3-embedding', 'general.size_label': '0.6B', 'general.license': 'apache-2.0', 'general.base_model.count': '1', 'general.base_model.0.organization': 'Qwen', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen3-0.6B-Base', 'tokenizer.ggml.pre': 'qwen2', 'qwen3.block_count': '28', 'qwen3.context_length': '32768', 'qwen3.embedding_length': '1024', 'qwen3.feed_forward_length': '3072', 'qwen3.attention.head_count': '16', 'qwen3.attention.head_count_kv': '8', 'tokenizer.ggml.add_bos_token': 'false', 'qwen3.attention.key_length': '128', 'qwen3.attention.value_length': '128', 'qwen3.pooling_type': '3', 'tokenizer.ggml.model': 'gpt2', 'general.file_type': '7', 'tokenizer.ggml.eos_token_id': '151643', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eot_token_id': '151645', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '151643', 'tokenizer.ggml.add_eos_token': 'true', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0].role == \\'system\\' %}\\n        {{- messages[0].content + \\'\\\\n\\\\n\\' }}\\n    {%- endif %}\\n    {{- \"# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0].role == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0].content + \\'<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\\n{%- for message in messages[::-1] %}\\n    {%- set index = (messages|length - 1) - loop.index0 %}\\n    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith(\\'<tool_response>\\') and message.content.endswith(\\'</tool_response>\\')) %}\\n        {%- set ns.multi_step_tool = false %}\\n        {%- set ns.last_query_index = index %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {%- set content = message.content %}\\n        {%- set reasoning_content = \\'\\' %}\\n        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\\n            {%- set reasoning_content = message.reasoning_content %}\\n        {%- else %}\\n            {%- if \\'</think>\\' in message.content %}\\n                {%- set content = message.content.split(\\'</think>\\')[-1].lstrip(\\'\\\\n\\') %}\\n                {%- set reasoning_content = message.content.split(\\'</think>\\')[0].rstrip(\\'\\\\n\\').split(\\'<think>\\')[-1].lstrip(\\'\\\\n\\') %}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if loop.index0 > ns.last_query_index %}\\n            {%- if loop.last or (not loop.last and reasoning_content) %}\\n                {{- \\'<|im_start|>\\' + message.role + \\'\\\\n<think>\\\\n\\' + reasoning_content.strip(\\'\\\\n\\') + \\'\\\\n</think>\\\\n\\\\n\\' + content.lstrip(\\'\\\\n\\') }}\\n            {%- else %}\\n                {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content }}\\n            {%- endif %}\\n        {%- else %}\\n            {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + content }}\\n        {%- endif %}\\n        {%- if message.tool_calls %}\\n            {%- for tool_call in message.tool_calls %}\\n                {%- if (loop.first and content) or (not loop.first) %}\\n                    {{- \\'\\\\n\\' }}\\n                {%- endif %}\\n                {%- if tool_call.function %}\\n                    {%- set tool_call = tool_call.function %}\\n                {%- endif %}\\n                {{- \\'<tool_call>\\\\n{\"name\": \"\\' }}\\n                {{- tool_call.name }}\\n                {{- \\'\", \"arguments\": \\' }}\\n                {%- if tool_call.arguments is string %}\\n                    {{- tool_call.arguments }}\\n                {%- else %}\\n                    {{- tool_call.arguments | tojson }}\\n                {%- endif %}\\n                {{- \\'}\\\\n</tool_call>\\' }}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n    {%- if enable_thinking is defined and enable_thinking is false %}\\n        {{- \\'<think>\\\\n\\\\n</think>\\\\n\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- messages[0].content + '\\n\\n' }}\n",
      "    {%- endif %}\n",
      "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0].role == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
      "{%- for message in messages[::-1] %}\n",
      "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
      "    {%- if ns.multi_step_tool and message.role == \"user\" and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n",
      "        {%- set ns.multi_step_tool = false %}\n",
      "        {%- set ns.last_query_index = index %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {%- set content = message.content %}\n",
      "        {%- set reasoning_content = '' %}\n",
      "        {%- if message.reasoning_content is defined and message.reasoning_content is not none %}\n",
      "            {%- set reasoning_content = message.reasoning_content %}\n",
      "        {%- else %}\n",
      "            {%- if '</think>' in message.content %}\n",
      "                {%- set content = message.content.split('</think>')[-1].lstrip('\\n') %}\n",
      "                {%- set reasoning_content = message.content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n",
      "            {%- endif %}\n",
      "        {%- endif %}\n",
      "        {%- if loop.index0 > ns.last_query_index %}\n",
      "            {%- if loop.last or (not loop.last and reasoning_content) %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
      "            {%- else %}\n",
      "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "            {%- endif %}\n",
      "        {%- else %}\n",
      "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
      "        {%- endif %}\n",
      "        {%- if message.tool_calls %}\n",
      "            {%- for tool_call in message.tool_calls %}\n",
      "                {%- if (loop.first and content) or (not loop.first) %}\n",
      "                    {{- '\\n' }}\n",
      "                {%- endif %}\n",
      "                {%- if tool_call.function %}\n",
      "                    {%- set tool_call = tool_call.function %}\n",
      "                {%- endif %}\n",
      "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
      "                {{- tool_call.name }}\n",
      "                {{- '\", \"arguments\": ' }}\n",
      "                {%- if tool_call.arguments is string %}\n",
      "                    {{- tool_call.arguments }}\n",
      "                {%- else %}\n",
      "                    {{- tool_call.arguments | tojson }}\n",
      "                {%- endif %}\n",
      "                {{- '}\\n</tool_call>' }}\n",
      "            {%- endfor %}\n",
      "        {%- endif %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "    {%- if enable_thinking is defined and enable_thinking is false %}\n",
      "        {{- '<think>\\n\\n</think>\\n\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb14a42b93e4e0f9921704a5bb817cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total collected Wikipedia texts: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.01 ms /   100 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     542.37 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.42 ms /   200 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.61 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     244.87 ms /    46 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.48 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     439.16 ms /    86 tokens (    5.11 ms per token,   195.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     444.62 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.61 ms /   196 tokens (    5.48 ms per token,   182.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1082.62 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     577.08 ms /   114 tokens (    5.06 ms per token,   197.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     582.71 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.46 ms /   175 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.81 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.99 ms /    50 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     271.12 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     592.97 ms /   111 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     598.03 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.83 ms /   111 tokens (    5.05 ms per token,   197.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     565.98 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.09 ms /   175 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     929.05 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     554.85 ms /    99 tokens (    5.60 ms per token,   178.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     559.78 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.69 ms /   163 tokens (    5.08 ms per token,   196.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     834.55 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.77 ms /   201 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1075.39 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     591.79 ms /   107 tokens (    5.53 ms per token,   180.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     598.61 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.42 ms /   194 tokens (    5.19 ms per token,   192.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.50 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     394.10 ms /    73 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.80 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.71 ms /   176 tokens (    5.11 ms per token,   195.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.91 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.95 ms /    59 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     307.79 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.73 ms /   178 tokens (    5.07 ms per token,   197.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     908.39 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.36 ms /   207 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.43 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     996.61 ms /   180 tokens (    5.54 ms per token,   180.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.38 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.69 ms /   178 tokens (    5.13 ms per token,   195.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     920.18 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     348.14 ms /    67 tokens (    5.20 ms per token,   192.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.10 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     661.24 ms /   127 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     668.37 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.98 ms /   134 tokens (    5.15 ms per token,   194.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     696.59 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.50 ms /   191 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1020.01 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.88 ms /    68 tokens (    4.94 ms per token,   202.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     342.14 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     257.12 ms /    52 tokens (    4.94 ms per token,   202.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     261.50 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1072.86 ms /   194 tokens (    5.53 ms per token,   180.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.59 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     275.53 ms /    55 tokens (    5.01 ms per token,   199.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.05 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.66 ms /   197 tokens (    5.10 ms per token,   196.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.08 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     531.77 ms /   103 tokens (    5.16 ms per token,   193.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     538.72 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.39 ms /   116 tokens (    5.14 ms per token,   194.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.09 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1076.80 ms /   166 tokens (    6.49 ms per token,   154.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1084.50 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.31 ms /   152 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     818.16 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.12 ms /   156 tokens (    5.84 ms per token,   171.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.69 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.71 ms /   173 tokens (    6.98 ms per token,   143.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1214.74 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.83 ms /   120 tokens (    5.91 ms per token,   169.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     716.16 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     489.39 ms /    93 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     493.86 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.83 ms /   130 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.91 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     514.84 ms /    94 tokens (    5.48 ms per token,   182.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     519.42 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      40.76 ms /     4 tokens (   10.19 ms per token,    98.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      43.08 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.11 ms /   183 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     964.44 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     321.74 ms /    58 tokens (    5.55 ms per token,   180.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.41 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.69 ms /   171 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.75 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     516.58 ms /    98 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.77 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.92 ms /   148 tokens (    5.09 ms per token,   196.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.29 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.54 ms /   172 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     918.13 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.05 ms /   168 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.67 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.16 ms /   150 tokens (    5.08 ms per token,   196.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.16 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.01 ms /   187 tokens (    5.10 ms per token,   196.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.49 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     645.44 ms /   110 tokens (    5.87 ms per token,   170.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     651.18 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.04 ms /   149 tokens (    6.84 ms per token,   146.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.15 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.84 ms /    95 tokens (    6.94 ms per token,   144.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     667.35 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.73 ms /   189 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.31 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     328.92 ms /    51 tokens (    6.45 ms per token,   155.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.70 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.32 ms /   172 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.80 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     586.96 ms /   105 tokens (    5.59 ms per token,   178.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.31 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.20 ms /   136 tokens (    5.12 ms per token,   195.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.13 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     549.67 ms /   109 tokens (    5.04 ms per token,   198.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     554.92 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.24 ms /   139 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     754.10 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.74 ms /   136 tokens (    5.53 ms per token,   180.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     758.74 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1348.41 ms /   192 tokens (    7.02 ms per token,   142.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1357.43 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1200.13 ms /   175 tokens (    6.86 ms per token,   145.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1207.78 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.18 ms /   123 tokens (    5.90 ms per token,   169.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     733.48 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.46 ms /   163 tokens (    5.84 ms per token,   171.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.63 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.99 ms /   171 tokens (    5.66 ms per token,   176.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     976.74 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.69 ms /   193 tokens (    5.17 ms per token,   193.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.93 ms /   194 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1079.40 ms /   207 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1087.11 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     983.51 ms /   187 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     995.83 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1113.48 ms /   206 tokens (    5.41 ms per token,   185.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.93 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.56 ms /   157 tokens (    5.16 ms per token,   193.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     817.58 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.76 ms /   183 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.42 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.61 ms /   171 tokens (    5.49 ms per token,   182.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     945.33 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.75 ms /   200 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.71 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.10 ms /   200 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1045.18 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     516.43 ms /   101 tokens (    5.11 ms per token,   195.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.71 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.66 ms /   150 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     796.54 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.07 ms /   196 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1031.42 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1116.84 ms /   179 tokens (    6.24 ms per token,   160.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1127.01 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     569.59 ms /   108 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     574.81 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.78 ms /   182 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     950.33 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.93 ms /   157 tokens (    5.13 ms per token,   195.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     811.45 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      48.83 ms /     6 tokens (    8.14 ms per token,   122.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.18 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.07 ms /   198 tokens (    5.15 ms per token,   194.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1028.55 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     337.96 ms /    60 tokens (    5.63 ms per token,   177.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     343.49 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     481.48 ms /    93 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.45 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.22 ms /   171 tokens (    5.14 ms per token,   194.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.70 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.42 ms /   160 tokens (    5.06 ms per token,   197.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     815.97 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.61 ms /   178 tokens (    5.10 ms per token,   195.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.60 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.75 ms /   176 tokens (    5.20 ms per token,   192.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.37 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.07 ms /   153 tokens (    5.43 ms per token,   184.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     840.99 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.97 ms /   109 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.80 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     558.94 ms /   108 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     564.21 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.14 ms /   167 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.97 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.17 ms /   178 tokens (    5.11 ms per token,   195.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.01 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     971.27 ms /   191 tokens (    5.09 ms per token,   196.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     978.13 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.95 ms /   175 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.83 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.03 ms /   182 tokens (    5.08 ms per token,   196.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     933.23 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.70 ms /   189 tokens (    5.12 ms per token,   195.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     974.63 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1381.84 ms /   224 tokens (    6.17 ms per token,   162.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1390.35 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.51 ms /   114 tokens (    6.36 ms per token,   157.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     730.68 ms /   115 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.32 ms /   163 tokens (    5.09 ms per token,   196.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     838.16 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.53 ms /   118 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     640.12 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     777.06 ms /   151 tokens (    5.15 ms per token,   194.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     784.07 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     365.75 ms /    66 tokens (    5.54 ms per token,   180.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.16 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.59 ms /   172 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.41 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.30 ms /   127 tokens (    5.43 ms per token,   184.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.14 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.60 ms /   205 tokens (    5.58 ms per token,   179.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.04 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     315.07 ms /    63 tokens (    5.00 ms per token,   199.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.03 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     492.64 ms /    72 tokens (    6.84 ms per token,   146.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     498.50 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1574.15 ms /   223 tokens (    7.06 ms per token,   141.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1585.28 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1156.47 ms /   222 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1165.13 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.86 ms /   146 tokens (    5.53 ms per token,   180.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     814.01 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.06 ms /   167 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     925.67 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1843.06 ms /   323 tokens (    5.71 ms per token,   175.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1853.52 ms /   324 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.11 ms /   150 tokens (    5.13 ms per token,   195.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     775.23 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1280.70 ms /   245 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1289.41 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     127.22 ms /    25 tokens (    5.09 ms per token,   196.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     130.24 ms /    26 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     942.32 ms /   180 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     950.54 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1217.42 ms /   222 tokens (    5.48 ms per token,   182.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.57 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     514.43 ms /    90 tokens (    5.72 ms per token,   174.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     519.83 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.77 ms /   164 tokens (    6.16 ms per token,   162.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.55 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      53.76 ms /     3 tokens (   17.92 ms per token,    55.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.43 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1651.39 ms /   238 tokens (    6.94 ms per token,   144.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1659.90 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.69 ms /    66 tokens (    7.31 ms per token,   136.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     487.24 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1257.30 ms /   213 tokens (    5.90 ms per token,   169.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1267.98 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.89 ms /   176 tokens (    5.96 ms per token,   167.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1058.20 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.32 ms /   202 tokens (    5.92 ms per token,   168.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1204.29 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1276.08 ms /   187 tokens (    6.82 ms per token,   146.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.16 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1162.97 ms /   218 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1174.24 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.70 ms /   179 tokens (    5.07 ms per token,   197.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.27 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     502.58 ms /    97 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     508.22 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.36 ms /   151 tokens (    5.12 ms per token,   195.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.32 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     730.50 ms /   148 tokens (    4.94 ms per token,   202.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     736.29 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1191.72 ms /   213 tokens (    5.59 ms per token,   178.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.27 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     611.62 ms /   124 tokens (    4.93 ms per token,   202.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     618.33 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     650.39 ms /   121 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     656.59 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     545.72 ms /    97 tokens (    5.63 ms per token,   177.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     551.77 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1421.78 ms /   211 tokens (    6.74 ms per token,   148.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1429.38 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.92 ms /   158 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.40 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.98 ms /   151 tokens (    4.96 ms per token,   201.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     757.26 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.26 ms /   186 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     974.71 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.28 ms /   125 tokens (    5.55 ms per token,   180.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     700.68 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     552.24 ms /   111 tokens (    4.98 ms per token,   201.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     557.54 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.45 ms /   155 tokens (    5.44 ms per token,   183.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.60 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     393.13 ms /    72 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.18 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.16 ms /   191 tokens (    5.05 ms per token,   198.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.22 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.84 ms /   167 tokens (    5.02 ms per token,   199.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     845.55 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.61 ms /   124 tokens (    5.14 ms per token,   194.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     643.11 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     603.57 ms /   116 tokens (    5.20 ms per token,   192.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     609.00 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.99 ms /   159 tokens (    5.01 ms per token,   199.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     803.50 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.41 ms /   187 tokens (    5.02 ms per token,   199.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.72 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.63 ms /   199 tokens (    5.05 ms per token,   197.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.35 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.18 ms /   169 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.01 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1117.97 ms /   217 tokens (    5.15 ms per token,   194.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1125.73 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     325.82 ms /    60 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     330.18 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.06 ms /   160 tokens (    4.88 ms per token,   205.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     786.65 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.89 ms /   202 tokens (    5.00 ms per token,   199.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.10 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.00 ms /   114 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     620.10 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.27 ms /   141 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     754.47 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     420.72 ms /    89 tokens (    4.73 ms per token,   211.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     425.34 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.65 ms /   197 tokens (    5.14 ms per token,   194.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.76 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1102.68 ms /   214 tokens (    5.15 ms per token,   194.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.82 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.33 ms /   232 tokens (    5.19 ms per token,   192.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.44 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.79 ms /   168 tokens (    4.95 ms per token,   202.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.13 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1416.41 ms /   264 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.96 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     190.85 ms /    40 tokens (    4.77 ms per token,   209.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     196.07 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.10 ms /   184 tokens (    5.17 ms per token,   193.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.44 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     377.02 ms /    79 tokens (    4.77 ms per token,   209.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.43 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1253.47 ms /   233 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1261.92 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.00 ms /   176 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.09 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1461.58 ms /   268 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.92 ms /   269 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     274.65 ms /    57 tokens (    4.82 ms per token,   207.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     278.42 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.46 ms /   131 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     708.11 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1107.96 ms /   216 tokens (    5.13 ms per token,   194.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1115.98 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1209.31 ms /   215 tokens (    5.62 ms per token,   177.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1216.69 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.66 ms /   118 tokens (    5.92 ms per token,   168.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     704.00 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.29 ms /   121 tokens (    6.68 ms per token,   149.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     814.38 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1718.41 ms /   307 tokens (    5.60 ms per token,   178.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1730.45 ms /   308 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1294.10 ms /   245 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1315.48 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.72 ms /   116 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     615.99 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1249.82 ms /   236 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1258.91 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1286.10 ms /   192 tokens (    6.70 ms per token,   149.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1293.55 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     582.73 ms /    85 tokens (    6.86 ms per token,   145.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     589.38 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1650.01 ms /   236 tokens (    6.99 ms per token,   143.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1658.68 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.55 ms /   104 tokens (    6.02 ms per token,   165.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     632.34 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1437.03 ms /   241 tokens (    5.96 ms per token,   167.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1446.08 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     562.95 ms /    91 tokens (    6.19 ms per token,   161.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     568.21 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.71 ms /   141 tokens (    5.74 ms per token,   174.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     817.08 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1434.33 ms /   244 tokens (    5.88 ms per token,   170.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1442.29 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.27 ms /   136 tokens (    5.85 ms per token,   171.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     801.77 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1116.01 ms /   164 tokens (    6.80 ms per token,   146.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1123.58 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.76 ms /   166 tokens (    6.93 ms per token,   144.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1157.37 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     520.48 ms /    92 tokens (    5.66 ms per token,   176.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     526.47 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.04 ms /   111 tokens (    6.88 ms per token,   145.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.64 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.71 ms /   171 tokens (    6.28 ms per token,   159.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1081.72 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     944.07 ms /   164 tokens (    5.76 ms per token,   173.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     950.93 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.02 ms /   171 tokens (    5.71 ms per token,   175.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.10 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.88 ms /   167 tokens (    5.75 ms per token,   173.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     967.80 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1110.30 ms /   195 tokens (    5.69 ms per token,   175.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1117.52 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1298.51 ms /   221 tokens (    5.88 ms per token,   170.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.45 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.06 ms /   131 tokens (    5.88 ms per token,   170.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     775.67 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.36 ms /   120 tokens (    5.81 ms per token,   172.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.01 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1044.24 ms /   169 tokens (    6.18 ms per token,   161.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.60 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.75 ms /   167 tokens (    5.94 ms per token,   168.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.53 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1089.51 ms /   191 tokens (    5.70 ms per token,   175.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1096.87 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1191.31 ms /   205 tokens (    5.81 ms per token,   172.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.46 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.25 ms /    95 tokens (    6.07 ms per token,   164.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     581.00 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.63 ms /   154 tokens (    5.71 ms per token,   175.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.41 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.47 ms /   155 tokens (    5.69 ms per token,   175.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     888.85 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.45 ms /   142 tokens (    5.80 ms per token,   172.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.46 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1067.45 ms /   180 tokens (    5.93 ms per token,   168.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1074.60 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.15 ms /    99 tokens (    5.89 ms per token,   169.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     589.65 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1224.31 ms /   210 tokens (    5.83 ms per token,   171.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1234.02 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1092.65 ms /   191 tokens (    5.72 ms per token,   174.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1101.64 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1262.67 ms /   194 tokens (    6.51 ms per token,   153.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1271.11 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1156.55 ms /   198 tokens (    5.84 ms per token,   171.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.42 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     323.21 ms /    55 tokens (    5.88 ms per token,   170.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     327.25 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1113.26 ms /   194 tokens (    5.74 ms per token,   174.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.85 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.19 ms /   129 tokens (    5.97 ms per token,   167.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.67 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2501.34 ms /   409 tokens (    6.12 ms per token,   163.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2514.41 ms /   410 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     579.22 ms /    90 tokens (    6.44 ms per token,   155.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.76 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.95 ms /   193 tokens (    6.33 ms per token,   158.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1229.16 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1296.07 ms /   225 tokens (    5.76 ms per token,   173.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1303.74 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1210.18 ms /   199 tokens (    6.08 ms per token,   164.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.60 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     249.82 ms /    40 tokens (    6.25 ms per token,   160.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     253.58 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      49.57 ms /     3 tokens (   16.52 ms per token,    60.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.23 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1465.98 ms /   251 tokens (    5.84 ms per token,   171.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1475.13 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     516.10 ms /    88 tokens (    5.86 ms per token,   170.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     520.95 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1760.45 ms /   302 tokens (    5.83 ms per token,   171.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1771.89 ms /   303 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1541.75 ms /   261 tokens (    5.91 ms per token,   169.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1551.70 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.49 ms /   146 tokens (    6.18 ms per token,   161.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     908.89 ms /   147 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.03 ms /   118 tokens (    5.97 ms per token,   167.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     712.12 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1071.97 ms /   205 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1079.62 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.80 ms /   121 tokens (    5.60 ms per token,   178.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     685.22 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1083.96 ms /   210 tokens (    5.16 ms per token,   193.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.14 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1474.29 ms /   236 tokens (    6.25 ms per token,   160.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1487.93 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.11 ms /   119 tokens (    6.09 ms per token,   164.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     731.68 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.45 ms /   140 tokens (    5.68 ms per token,   176.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.30 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.46 ms /   197 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.46 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.48 ms /   152 tokens (    5.17 ms per token,   193.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     792.93 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1021.68 ms /   195 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1028.73 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1345.50 ms /   253 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1353.90 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     358.27 ms /    64 tokens (    5.60 ms per token,   178.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     365.23 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1266.38 ms /   230 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1275.06 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.37 ms /   162 tokens (    5.51 ms per token,   181.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     900.42 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.38 ms /   113 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.81 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     796.30 ms /   156 tokens (    5.10 ms per token,   195.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     803.59 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1190.06 ms /   230 tokens (    5.17 ms per token,   193.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1198.09 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.01 ms /   104 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     539.83 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     363.67 ms /    73 tokens (    4.98 ms per token,   200.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.80 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1231.80 ms /   237 tokens (    5.20 ms per token,   192.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.87 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     499.80 ms /    93 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     507.40 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.34 ms /   209 tokens (    5.21 ms per token,   192.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1095.83 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     552.28 ms /    98 tokens (    5.64 ms per token,   177.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     559.22 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.02 ms /   212 tokens (    5.59 ms per token,   178.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.06 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1161.53 ms /   160 tokens (    7.26 ms per token,   137.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1169.83 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.38 ms /   213 tokens (    5.57 ms per token,   179.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.71 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.37 ms /   146 tokens (    5.19 ms per token,   192.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     763.59 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1060.31 ms /   205 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1067.31 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1101.39 ms /   207 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1109.51 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.27 ms /   122 tokens (    5.21 ms per token,   192.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     643.25 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1157.71 ms /   223 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1165.57 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     565.33 ms /   112 tokens (    5.05 ms per token,   198.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.57 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.62 ms /   200 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.81 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1113.54 ms /   217 tokens (    5.13 ms per token,   194.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.27 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1210.52 ms /   227 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.64 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1146.70 ms /   220 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1154.98 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     296.31 ms /    60 tokens (    4.94 ms per token,   202.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.90 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1376.74 ms /   249 tokens (    5.53 ms per token,   180.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1385.63 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     341.71 ms /    68 tokens (    5.03 ms per token,   199.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.82 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1342.69 ms /   259 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1351.82 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1319.97 ms /   251 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1328.60 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     590.56 ms /   113 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.09 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1320.42 ms /   250 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1329.53 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     603.30 ms /   111 tokens (    5.44 ms per token,   183.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     609.20 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      98.95 ms /    17 tokens (    5.82 ms per token,   171.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     102.04 ms /    18 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1119.58 ms /   217 tokens (    5.16 ms per token,   193.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1128.37 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.86 ms /   232 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1269.57 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     606.91 ms /   119 tokens (    5.10 ms per token,   196.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     612.46 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1123.60 ms /   217 tokens (    5.18 ms per token,   193.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.65 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.43 ms /   178 tokens (    5.12 ms per token,   195.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     919.31 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      37.96 ms /     3 tokens (   12.65 ms per token,    79.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.21 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.77 ms /   206 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1089.14 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.44 ms /    65 tokens (    5.39 ms per token,   185.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.41 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1186.22 ms /   229 tokens (    5.18 ms per token,   193.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.69 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1368.69 ms /   255 tokens (    5.37 ms per token,   186.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1377.59 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1331.85 ms /   256 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1341.38 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1389.93 ms /   262 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1398.06 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.20 ms /    71 tokens (    4.93 ms per token,   202.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.58 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1152.58 ms /   222 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.45 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.66 ms /   135 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     708.54 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.39 ms /   149 tokens (    5.10 ms per token,   195.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.51 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1651.15 ms /   319 tokens (    5.18 ms per token,   193.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1660.71 ms /   320 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1302.75 ms /   245 tokens (    5.32 ms per token,   188.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1311.09 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.85 ms /   162 tokens (    5.08 ms per token,   196.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.62 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.76 ms /   110 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     579.65 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1267.68 ms /   246 tokens (    5.15 ms per token,   194.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1275.83 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1187.17 ms /   223 tokens (    5.32 ms per token,   187.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.55 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1262.81 ms /   241 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1271.25 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.83 ms /   101 tokens (    6.95 ms per token,   143.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     707.98 ms /   102 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     712.22 ms /   116 tokens (    6.14 ms per token,   162.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     718.75 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1142.85 ms /   214 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1151.31 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     371.69 ms /    64 tokens (    5.81 ms per token,   172.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     375.91 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.80 ms /   195 tokens (    5.15 ms per token,   194.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.79 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.40 ms /   133 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.59 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.73 ms /   134 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.31 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1092.37 ms /   210 tokens (    5.20 ms per token,   192.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.83 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.33 ms /   179 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.89 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.49 ms /   194 tokens (    5.12 ms per token,   195.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.01 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     541.46 ms /   104 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.65 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.66 ms /   183 tokens (    5.02 ms per token,   199.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     926.36 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     616.87 ms /   118 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.16 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.42 ms /   141 tokens (    4.98 ms per token,   200.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     708.60 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.96 ms /   209 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1098.43 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.16 ms /   151 tokens (    4.88 ms per token,   205.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     742.36 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1383.21 ms /   266 tokens (    5.20 ms per token,   192.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1391.82 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     345.56 ms /    71 tokens (    4.87 ms per token,   205.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     350.64 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     355.67 ms /    73 tokens (    4.87 ms per token,   205.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     359.96 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.60 ms /   218 tokens (    5.10 ms per token,   195.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.43 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.22 ms /    63 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.17 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.83 ms /   123 tokens (    5.67 ms per token,   176.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.89 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.00 ms /   112 tokens (    6.45 ms per token,   155.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.62 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.31 ms /   181 tokens (    5.85 ms per token,   171.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.23 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.63 ms /    88 tokens (    7.00 ms per token,   142.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     621.11 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1334.89 ms /   222 tokens (    6.01 ms per token,   166.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.93 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.82 ms /   186 tokens (    5.05 ms per token,   197.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     947.03 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     369.06 ms /    73 tokens (    5.06 ms per token,   197.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.24 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.95 ms /   143 tokens (    5.78 ms per token,   173.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     831.83 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     684.01 ms /   121 tokens (    5.65 ms per token,   176.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     690.47 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.94 ms /   179 tokens (    5.13 ms per token,   194.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     927.71 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.24 ms /   171 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     897.93 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.61 ms /   184 tokens (    5.03 ms per token,   199.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     931.51 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.35 ms /   187 tokens (    5.00 ms per token,   199.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     943.81 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.83 ms /   126 tokens (    4.86 ms per token,   205.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     618.38 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.80 ms /   178 tokens (    5.18 ms per token,   192.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     930.01 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.27 ms /   167 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     871.07 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.60 ms /     6 tokens (    7.43 ms per token,   134.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.15 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.12 ms /   179 tokens (    5.12 ms per token,   195.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.96 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     244.31 ms /    48 tokens (    5.09 ms per token,   196.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     247.98 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      49.58 ms /     8 tokens (    6.20 ms per token,   161.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.57 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.10 ms /   201 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1053.17 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     320.31 ms /    54 tokens (    5.93 ms per token,   168.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     325.86 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.04 ms /   138 tokens (    4.97 ms per token,   201.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.60 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.78 ms /   168 tokens (    5.11 ms per token,   195.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.51 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.84 ms /   173 tokens (    5.10 ms per token,   195.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     889.75 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1029.98 ms /   200 tokens (    5.15 ms per token,   194.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.53 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     220.30 ms /    43 tokens (    5.12 ms per token,   195.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     224.51 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     594.06 ms /   113 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     601.72 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.44 ms /   129 tokens (    5.02 ms per token,   199.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     653.28 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     436.55 ms /    88 tokens (    4.96 ms per token,   201.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     443.47 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1032.26 ms /   193 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.71 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     666.59 ms /   130 tokens (    5.13 ms per token,   195.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     673.02 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.04 ms /   154 tokens (    5.03 ms per token,   198.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.30 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     385.52 ms /    71 tokens (    5.43 ms per token,   184.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     390.24 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1054.93 ms /   207 tokens (    5.10 ms per token,   196.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.84 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.74 ms /    54 tokens (    5.57 ms per token,   179.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     307.24 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.36 ms /   173 tokens (    5.14 ms per token,   194.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     895.28 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.00 ms /   198 tokens (    5.11 ms per token,   195.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.28 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.37 ms /   189 tokens (    5.13 ms per token,   194.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     978.11 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.29 ms /   146 tokens (    5.04 ms per token,   198.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     743.42 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1053.27 ms /   207 tokens (    5.09 ms per token,   196.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.43 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     500.79 ms /   103 tokens (    4.86 ms per token,   205.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     505.91 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.72 ms /   128 tokens (    5.06 ms per token,   197.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     654.37 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     594.17 ms /   120 tokens (    4.95 ms per token,   201.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     600.11 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.94 ms /   139 tokens (    5.03 ms per token,   198.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     704.90 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.95 ms /   168 tokens (    5.14 ms per token,   194.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     871.26 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     557.03 ms /   112 tokens (    4.97 ms per token,   201.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     563.67 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     602.71 ms /   120 tokens (    5.02 ms per token,   199.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     609.35 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.20 ms /   200 tokens (    5.12 ms per token,   195.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1031.27 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.51 ms /   158 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     845.24 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.33 ms /   150 tokens (    5.08 ms per token,   197.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     767.27 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.50 ms /   180 tokens (    5.01 ms per token,   199.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     908.70 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     956.26 ms /   190 tokens (    5.03 ms per token,   198.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.46 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.96 ms /   148 tokens (    5.11 ms per token,   195.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.02 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.18 ms /   156 tokens (    5.00 ms per token,   199.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     787.60 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     489.60 ms /    87 tokens (    5.63 ms per token,   177.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     494.01 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.64 ms /   157 tokens (    5.03 ms per token,   198.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.99 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.70 ms /   220 tokens (    5.05 ms per token,   197.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.55 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1413.89 ms /   205 tokens (    6.90 ms per token,   144.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1422.33 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.50 ms /   180 tokens (    4.99 ms per token,   200.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.80 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.43 ms /   193 tokens (    5.23 ms per token,   191.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1015.35 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.65 ms /   156 tokens (    5.03 ms per token,   198.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.77 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     602.09 ms /   118 tokens (    5.10 ms per token,   195.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     607.46 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1035.89 ms /   201 tokens (    5.15 ms per token,   194.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1043.28 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     343.70 ms /    68 tokens (    5.05 ms per token,   197.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     347.95 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.21 ms /   114 tokens (    5.05 ms per token,   197.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     582.46 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.05 ms /   175 tokens (    5.97 ms per token,   167.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.59 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.96 ms /   212 tokens (    5.68 ms per token,   176.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.32 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      31.05 ms /     3 tokens (   10.35 ms per token,    96.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      33.76 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.13 ms /   213 tokens (    5.14 ms per token,   194.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.01 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     327.59 ms /    62 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.94 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.42 ms /   141 tokens (    4.97 ms per token,   201.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     708.03 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.37 ms /   203 tokens (    5.06 ms per token,   197.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1035.37 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.90 ms /   136 tokens (    5.07 ms per token,   197.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.23 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.75 ms /   103 tokens (    5.03 ms per token,   198.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     523.14 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.72 ms /   206 tokens (    5.08 ms per token,   196.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1053.40 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.78 ms /   135 tokens (    5.18 ms per token,   193.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.63 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     289.29 ms /    55 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     293.83 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.88 ms /   206 tokens (    5.08 ms per token,   196.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1056.03 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1421.21 ms /   206 tokens (    6.90 ms per token,   144.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1428.92 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     557.49 ms /   103 tokens (    5.41 ms per token,   184.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     563.24 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     975.59 ms /   181 tokens (    5.39 ms per token,   185.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     983.76 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1361.29 ms /   205 tokens (    6.64 ms per token,   150.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1369.13 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.72 ms /   132 tokens (    7.26 ms per token,   137.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     966.09 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.83 ms /   119 tokens (    6.02 ms per token,   166.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     723.16 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1201.60 ms /   191 tokens (    6.29 ms per token,   158.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.91 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.13 ms /   121 tokens (    5.98 ms per token,   167.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     730.46 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.86 ms /   193 tokens (    6.03 ms per token,   165.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1170.90 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1169.39 ms /   201 tokens (    5.82 ms per token,   171.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1179.76 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     449.91 ms /    82 tokens (    5.49 ms per token,   182.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     454.91 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.81 ms /   216 tokens (    5.43 ms per token,   184.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.09 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     252.87 ms /    47 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     257.89 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.32 ms /   180 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.60 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.18 ms /   140 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.94 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1078.42 ms /   194 tokens (    5.56 ms per token,   179.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1088.15 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.63 ms /   112 tokens (    5.93 ms per token,   168.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.80 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.86 ms /   162 tokens (    5.47 ms per token,   182.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.40 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.08 ms /   172 tokens (    6.10 ms per token,   163.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.06 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.70 ms /   136 tokens (    6.11 ms per token,   163.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.19 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.19 ms /   153 tokens (    5.55 ms per token,   180.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     858.45 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.60 ms /   112 tokens (    5.59 ms per token,   179.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     630.90 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1225.31 ms /   213 tokens (    5.75 ms per token,   173.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.82 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     400.05 ms /    72 tokens (    5.56 ms per token,   179.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     405.08 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.61 ms /   166 tokens (    5.47 ms per token,   182.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.29 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1188.30 ms /   210 tokens (    5.66 ms per token,   176.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1196.25 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     414.22 ms /    77 tokens (    5.38 ms per token,   185.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     418.71 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1213.99 ms /   194 tokens (    6.26 ms per token,   159.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1221.23 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1159.57 ms /   173 tokens (    6.70 ms per token,   149.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1167.81 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1298.31 ms /   188 tokens (    6.91 ms per token,   144.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.26 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1509.81 ms /   229 tokens (    6.59 ms per token,   151.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1521.12 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.05 ms /    90 tokens (    6.49 ms per token,   154.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.57 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.27 ms /   186 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.16 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1103.74 ms /   204 tokens (    5.41 ms per token,   184.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1112.86 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.40 ms /   146 tokens (    5.13 ms per token,   194.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     755.40 ms /   147 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 6/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     545.23 ms /   102 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     551.26 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.42 ms /   137 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     716.67 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.45 ms /    87 tokens (    5.13 ms per token,   194.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     451.13 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1195.76 ms /   196 tokens (    6.10 ms per token,   163.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1202.93 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.65 ms /    78 tokens (    6.35 ms per token,   157.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     500.41 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1075.91 ms /   177 tokens (    6.08 ms per token,   164.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.97 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1334.85 ms /   225 tokens (    5.93 ms per token,   168.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.79 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.72 ms /    94 tokens (    6.36 ms per token,   157.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.99 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1180.55 ms /   224 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1190.04 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     366.47 ms /    67 tokens (    5.47 ms per token,   182.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.45 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.17 ms /   142 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     787.47 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1251.65 ms /   214 tokens (    5.85 ms per token,   170.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.13 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1119.07 ms /   192 tokens (    5.83 ms per token,   171.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1129.26 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1215.95 ms /   146 tokens (    8.33 ms per token,   120.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.22 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.17 ms /   103 tokens (    5.94 ms per token,   168.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     619.01 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1211.62 ms /   185 tokens (    6.55 ms per token,   152.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.92 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.40 ms /    86 tokens (    7.83 ms per token,   127.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     678.07 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1155.81 ms /   206 tokens (    5.61 ms per token,   178.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1163.43 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     474.85 ms /    79 tokens (    6.01 ms per token,   166.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     481.01 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.56 ms /    90 tokens (    5.75 ms per token,   173.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     523.58 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1516.42 ms /   225 tokens (    6.74 ms per token,   148.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1526.97 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     492.34 ms /    88 tokens (    5.59 ms per token,   178.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     498.05 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.96 ms /   156 tokens (    5.67 ms per token,   176.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.10 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     459.54 ms /    87 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     466.21 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.54 ms /   192 tokens (    5.89 ms per token,   169.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1138.08 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.07 ms /    97 tokens (    6.63 ms per token,   150.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.47 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.12 ms /   211 tokens (    5.87 ms per token,   170.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1247.88 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1502.79 ms /   189 tokens (    7.95 ms per token,   125.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1512.92 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.42 ms /   139 tokens (    6.50 ms per token,   153.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     912.24 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.13 ms /    92 tokens (    6.93 ms per token,   144.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     642.19 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.58 ms /   106 tokens (    9.01 ms per token,   110.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.41 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1242.99 ms /   139 tokens (    8.94 ms per token,   111.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1251.70 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1110.43 ms /   151 tokens (    7.35 ms per token,   135.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1117.98 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     541.70 ms /    77 tokens (    7.04 ms per token,   142.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     549.04 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.06 ms /   160 tokens (    6.09 ms per token,   164.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     980.82 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.46 ms /   118 tokens (    5.73 ms per token,   174.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.44 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1578.62 ms /   204 tokens (    7.74 ms per token,   129.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1587.64 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.24 ms /   151 tokens (    6.01 ms per token,   166.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.30 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.96 ms /   123 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     665.76 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1581.03 ms /   207 tokens (    7.64 ms per token,   130.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1588.92 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     484.29 ms /    57 tokens (    8.50 ms per token,   117.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     491.57 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1118.06 ms /   165 tokens (    6.78 ms per token,   147.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1127.24 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.32 ms /   146 tokens (    5.77 ms per token,   173.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.28 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.89 ms /   220 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1187.48 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.45 ms /   132 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.72 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.11 ms /   127 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     697.08 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.87 ms /   129 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.94 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.44 ms /   174 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.37 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.18 ms /   128 tokens (    5.55 ms per token,   180.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.26 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     591.42 ms /    96 tokens (    6.16 ms per token,   162.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     597.30 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.85 ms /   169 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     895.46 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     232.22 ms /    42 tokens (    5.53 ms per token,   180.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     236.82 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     536.84 ms /   104 tokens (    5.16 ms per token,   193.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     543.70 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.43 ms /   108 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     589.12 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.34 ms /   191 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.12 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.63 ms /   179 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.36 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.22 ms /   181 tokens (    5.14 ms per token,   194.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.26 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     533.24 ms /    78 tokens (    6.84 ms per token,   146.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     540.36 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.96 ms /   171 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.42 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.34 ms /   109 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.34 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.93 ms /   160 tokens (    5.53 ms per token,   180.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.28 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.64 ms /   186 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.80 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     592.82 ms /   118 tokens (    5.02 ms per token,   199.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     598.45 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.51 ms /   167 tokens (    5.78 ms per token,   173.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     970.96 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.04 ms /   170 tokens (    5.57 ms per token,   179.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     954.57 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.86 ms /   112 tokens (    5.11 ms per token,   195.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.05 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.16 ms /   127 tokens (    5.06 ms per token,   197.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.35 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.74 ms /   140 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     761.66 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.17 ms /   210 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.89 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.24 ms /    89 tokens (    6.33 ms per token,   158.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     570.88 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1077.02 ms /   205 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1084.76 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     361.17 ms /    70 tokens (    5.16 ms per token,   193.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     365.27 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     384.41 ms /    75 tokens (    5.13 ms per token,   195.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     390.41 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.99 ms /   192 tokens (    5.14 ms per token,   194.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     993.53 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.55 ms /   119 tokens (    5.17 ms per token,   193.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.02 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1106.40 ms /   211 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1114.00 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1070.66 ms /   205 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.24 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.17 ms /   168 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     925.88 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.51 ms /   166 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     912.28 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     623.60 ms /   102 tokens (    6.11 ms per token,   163.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     629.33 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     543.47 ms /   109 tokens (    4.99 ms per token,   200.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     548.87 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     469.47 ms /    94 tokens (    4.99 ms per token,   200.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     474.42 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.33 ms /   187 tokens (    5.06 ms per token,   197.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     956.04 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     588.76 ms /   117 tokens (    5.03 ms per token,   198.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     594.52 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1423.29 ms /   213 tokens (    6.68 ms per token,   149.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1431.47 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     627.81 ms /   121 tokens (    5.19 ms per token,   192.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     633.88 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1050.57 ms /   201 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1058.72 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     381.86 ms /    67 tokens (    5.70 ms per token,   175.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     388.83 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.48 ms /   182 tokens (    5.09 ms per token,   196.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.09 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.90 ms /   121 tokens (    5.14 ms per token,   194.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.14 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.34 ms /   182 tokens (    5.19 ms per token,   192.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.44 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     605.94 ms /   119 tokens (    5.09 ms per token,   196.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     612.05 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1327.17 ms /   251 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1337.28 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1384.67 ms /   248 tokens (    5.58 ms per token,   179.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1393.09 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1534.82 ms /   238 tokens (    6.45 ms per token,   155.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1545.48 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.28 ms /    99 tokens (    6.39 ms per token,   156.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     637.93 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1379.42 ms /   228 tokens (    6.05 ms per token,   165.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1387.67 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.41 ms /   148 tokens (    5.13 ms per token,   194.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.28 ms /   149 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1093.22 ms /   212 tokens (    5.16 ms per token,   193.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1101.96 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.58 ms /   218 tokens (    6.46 ms per token,   154.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.62 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1305.39 ms /   227 tokens (    5.75 ms per token,   173.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1313.79 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     627.47 ms /   123 tokens (    5.10 ms per token,   196.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.66 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1225.84 ms /   239 tokens (    5.13 ms per token,   194.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.91 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     324.27 ms /    54 tokens (    6.01 ms per token,   166.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     330.90 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.62 ms /   151 tokens (    5.04 ms per token,   198.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.50 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1533.78 ms /   247 tokens (    6.21 ms per token,   161.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1543.25 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.23 ms /   191 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.80 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.57 ms /   159 tokens (    6.52 ms per token,   153.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1043.67 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1280.26 ms /   189 tokens (    6.77 ms per token,   147.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1288.02 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.30 ms /   179 tokens (    5.15 ms per token,   194.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.58 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.40 ms /   168 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     878.74 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1266.11 ms /   240 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1275.66 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.31 ms /   116 tokens (    5.14 ms per token,   194.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.22 ms /   117 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1416.70 ms /   264 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.93 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1372.50 ms /   227 tokens (    6.05 ms per token,   165.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1380.12 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.66 ms /   161 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     867.31 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     519.53 ms /   103 tokens (    5.04 ms per token,   198.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     524.91 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.93 ms /   162 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.34 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1459.67 ms /   227 tokens (    6.43 ms per token,   155.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1467.75 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1182.88 ms /   200 tokens (    5.91 ms per token,   169.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1190.34 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.83 ms /   170 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.84 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.13 ms /   194 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1030.23 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.08 ms /   157 tokens (    5.41 ms per token,   184.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     856.34 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1098.31 ms /   202 tokens (    5.44 ms per token,   183.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1106.60 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.38 ms /   132 tokens (    5.16 ms per token,   193.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.36 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1239.77 ms /   233 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1248.01 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1285.95 ms /   234 tokens (    5.50 ms per token,   181.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.70 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1110.72 ms /   212 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.31 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     650.66 ms /   130 tokens (    5.01 ms per token,   199.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     658.16 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     634.10 ms /   121 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     639.61 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.87 ms /   143 tokens (    5.19 ms per token,   192.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     747.86 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.97 ms /   166 tokens (    4.99 ms per token,   200.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     834.48 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1302.58 ms /   249 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1311.10 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.60 ms /   241 tokens (    5.14 ms per token,   194.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.90 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     367.51 ms /    66 tokens (    5.57 ms per token,   179.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     371.62 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     656.72 ms /   128 tokens (    5.13 ms per token,   194.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     663.41 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.87 ms /   163 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.61 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     668.03 ms /   132 tokens (    5.06 ms per token,   197.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     674.04 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.75 ms /   144 tokens (    5.12 ms per token,   195.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     742.89 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.33 ms /   169 tokens (    5.11 ms per token,   195.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     871.83 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     528.77 ms /   101 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     534.02 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1068.05 ms /   209 tokens (    5.11 ms per token,   195.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.08 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.39 ms /   158 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     833.48 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.31 ms /    66 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     356.60 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.93 ms /   180 tokens (    5.07 ms per token,   197.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.30 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     573.12 ms /   116 tokens (    4.94 ms per token,   202.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     579.16 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.19 ms /   154 tokens (    5.07 ms per token,   197.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     787.98 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     318.11 ms /    64 tokens (    4.97 ms per token,   201.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.26 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.89 ms /   146 tokens (    6.70 ms per token,   149.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.94 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.12 ms /   162 tokens (    5.40 ms per token,   185.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     883.11 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.07 ms /   129 tokens (    5.11 ms per token,   195.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     665.72 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.94 ms /   163 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.96 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1084.30 ms /   211 tokens (    5.14 ms per token,   194.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.79 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     451.13 ms /    90 tokens (    5.01 ms per token,   199.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     456.34 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.91 ms /   200 tokens (    5.08 ms per token,   196.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1024.86 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.73 ms /   109 tokens (    5.48 ms per token,   182.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     603.71 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.76 ms /   217 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1148.65 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.22 ms /    80 tokens (    4.95 ms per token,   201.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     401.04 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     424.26 ms /    81 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     429.02 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.54 ms /   143 tokens (    5.49 ms per token,   182.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.80 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1179.76 ms /   220 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1189.15 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     582.29 ms /   115 tokens (    5.06 ms per token,   197.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     587.58 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.94 ms /   171 tokens (    5.13 ms per token,   195.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     883.83 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1268.20 ms /   245 tokens (    5.18 ms per token,   193.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1277.12 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.78 ms /   173 tokens (    5.14 ms per token,   194.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.34 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1437.50 ms /   224 tokens (    6.42 ms per token,   155.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1445.14 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1294.85 ms /   252 tokens (    5.14 ms per token,   194.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1303.25 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.16 ms /   164 tokens (    5.07 ms per token,   197.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.73 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     998.71 ms /   196 tokens (    5.10 ms per token,   196.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.54 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     819.69 ms /   165 tokens (    4.97 ms per token,   201.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     826.08 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.73 ms /   158 tokens (    4.99 ms per token,   200.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     794.28 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     507.07 ms /    98 tokens (    5.17 ms per token,   193.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     512.68 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     763.39 ms /   153 tokens (    4.99 ms per token,   200.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.83 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      59.01 ms /     9 tokens (    6.56 ms per token,   152.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.47 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1138.81 ms /   214 tokens (    5.32 ms per token,   187.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1147.06 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.13 ms /   119 tokens (    4.90 ms per token,   204.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     589.04 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      47.27 ms /     6 tokens (    7.88 ms per token,   126.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.65 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1127.86 ms /   205 tokens (    5.50 ms per token,   181.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1136.05 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     512.64 ms /    73 tokens (    7.02 ms per token,   142.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     518.99 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.22 ms /    76 tokens (    6.91 ms per token,   144.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     529.66 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.44 ms /   127 tokens (    7.63 ms per token,   131.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     976.06 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.23 ms /   113 tokens (    5.66 ms per token,   176.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     646.03 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     962.62 ms /   178 tokens (    5.41 ms per token,   184.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     969.39 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.19 ms /   164 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     879.01 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.60 ms /   126 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     665.57 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.57 ms /   174 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.66 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.63 ms /   184 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     983.60 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     706.08 ms /   133 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     712.51 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1161.27 ms /   213 tokens (    5.45 ms per token,   183.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1168.94 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     619.29 ms /   111 tokens (    5.58 ms per token,   179.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     624.64 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.21 ms /   179 tokens (    5.18 ms per token,   193.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.11 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.62 ms /   147 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.75 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1035.30 ms /   195 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1043.66 ms /   196 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1076.92 ms /   209 tokens (    5.15 ms per token,   194.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1086.11 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.95 ms /   112 tokens (    5.90 ms per token,   169.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     666.26 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.46 ms /   181 tokens (    5.57 ms per token,   179.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.49 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.76 ms /   168 tokens (    5.10 ms per token,   196.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.60 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1122.72 ms /   213 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.89 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1528.82 ms /   231 tokens (    6.62 ms per token,   151.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1538.89 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     574.78 ms /   112 tokens (    5.13 ms per token,   194.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     581.11 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1187.55 ms /   203 tokens (    5.85 ms per token,   170.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.43 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     944.50 ms /   177 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     951.56 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     661.39 ms /   128 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     667.21 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.72 ms /   126 tokens (    5.46 ms per token,   183.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.56 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.97 ms /   108 tokens (    5.06 ms per token,   197.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     552.17 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.00 ms /   149 tokens (    5.16 ms per token,   193.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     775.61 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.34 ms /   180 tokens (    5.09 ms per token,   196.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     922.12 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.06 ms /   173 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.71 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1067.47 ms /   206 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1075.34 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     963.86 ms /   189 tokens (    5.10 ms per token,   196.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     972.91 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.84 ms /   101 tokens (    5.11 ms per token,   195.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.83 ms /   102 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 13/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.55 ms /   185 tokens (    5.09 ms per token,   196.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.77 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.48 ms /   175 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.54 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1034.51 ms /   200 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1042.08 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.31 ms /   142 tokens (    5.56 ms per token,   179.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     796.82 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.22 ms /   164 tokens (    5.11 ms per token,   195.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     844.87 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.51 ms /   150 tokens (    5.02 ms per token,   199.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     759.89 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     531.93 ms /   107 tokens (    4.97 ms per token,   201.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     537.20 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.46 ms /   142 tokens (    5.07 ms per token,   197.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     727.17 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.09 ms /   170 tokens (    6.02 ms per token,   166.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1032.00 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     508.96 ms /    78 tokens (    6.53 ms per token,   153.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     515.95 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.74 ms /   135 tokens (    5.10 ms per token,   196.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.66 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     383.00 ms /    77 tokens (    4.97 ms per token,   201.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.68 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.09 ms /   182 tokens (    5.10 ms per token,   196.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.39 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     227.68 ms /    42 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     231.05 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.12 ms /   137 tokens (    4.98 ms per token,   200.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     688.01 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     730.93 ms /   140 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     736.94 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.83 ms /   161 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.98 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.18 ms /   153 tokens (    5.06 ms per token,   197.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.05 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     575.96 ms /   116 tokens (    4.97 ms per token,   201.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     581.58 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.58 ms /   149 tokens (    5.11 ms per token,   195.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.36 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     316.14 ms /    59 tokens (    5.36 ms per token,   186.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     320.17 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      34.95 ms /     4 tokens (    8.74 ms per token,   114.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.16 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.80 ms /   188 tokens (    5.06 ms per token,   197.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     960.12 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.67 ms /    69 tokens (    5.07 ms per token,   197.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.19 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.69 ms /   167 tokens (    4.98 ms per token,   200.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     841.53 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.16 ms /   183 tokens (    4.98 ms per token,   200.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     919.28 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.22 ms /   176 tokens (    5.02 ms per token,   199.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.40 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.59 ms /   143 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     747.24 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.88 ms /   195 tokens (    5.02 ms per token,   199.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.75 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.22 ms /   105 tokens (    6.54 ms per token,   152.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.36 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.10 ms /   179 tokens (    5.55 ms per token,   180.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.72 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     384.14 ms /    73 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     389.94 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.84 ms /   138 tokens (    5.05 ms per token,   198.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.40 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.98 ms /   157 tokens (    5.01 ms per token,   199.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     794.19 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.94 ms /   154 tokens (    4.99 ms per token,   200.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     775.37 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.18 ms /   112 tokens (    5.09 ms per token,   196.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     576.93 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     554.57 ms /   111 tokens (    5.00 ms per token,   200.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     560.17 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     614.75 ms /   123 tokens (    5.00 ms per token,   200.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     621.18 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1057.72 ms /   203 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.50 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     376.12 ms /    77 tokens (    4.88 ms per token,   204.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.30 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.21 ms /   119 tokens (    4.91 ms per token,   203.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.23 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.14 ms /   147 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     761.88 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.52 ms /   145 tokens (    5.07 ms per token,   197.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     740.68 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.61 ms /   199 tokens (    5.07 ms per token,   197.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.96 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.57 ms /   134 tokens (    5.08 ms per token,   196.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.81 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1027.90 ms /   201 tokens (    5.11 ms per token,   195.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1035.26 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1099.23 ms /   160 tokens (    6.87 ms per token,   145.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1106.50 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.56 ms /   176 tokens (    6.44 ms per token,   155.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1140.77 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.18 ms /   156 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.35 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.23 ms /   179 tokens (    5.10 ms per token,   196.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     920.99 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.48 ms /   117 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     615.02 ms /   118 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.33 ms /   174 tokens (    5.11 ms per token,   195.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     897.59 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     590.41 ms /   113 tokens (    5.22 ms per token,   191.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     595.75 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     521.34 ms /   104 tokens (    5.01 ms per token,   199.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     526.59 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.97 ms /   170 tokens (    5.18 ms per token,   193.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.11 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.80 ms /   177 tokens (    5.09 ms per token,   196.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.23 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.76 ms /   190 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.14 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     605.45 ms /   119 tokens (    5.09 ms per token,   196.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     613.18 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.53 ms /   114 tokens (    5.45 ms per token,   183.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.01 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.76 ms /   139 tokens (    5.11 ms per token,   195.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     716.65 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.61 ms /   179 tokens (    5.09 ms per token,   196.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     918.56 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.83 ms /   171 tokens (    5.10 ms per token,   196.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.21 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1059.20 ms /   206 tokens (    5.14 ms per token,   194.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1067.00 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     258.41 ms /    49 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     263.93 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     318.42 ms /    60 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.90 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.87 ms /   161 tokens (    5.01 ms per token,   199.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     812.54 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.33 ms /   186 tokens (    5.03 ms per token,   198.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     943.77 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.36 ms /    59 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     317.78 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.73 ms /   204 tokens (    5.03 ms per token,   198.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1035.20 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     377.69 ms /    69 tokens (    5.47 ms per token,   182.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     383.06 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.73 ms /   192 tokens (    5.02 ms per token,   199.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     972.73 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.72 ms /   125 tokens (    5.10 ms per token,   196.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     643.59 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.45 ms /   152 tokens (    4.86 ms per token,   205.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.49 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.50 ms /   164 tokens (    5.02 ms per token,   199.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.89 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.56 ms /   175 tokens (    5.06 ms per token,   197.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     892.23 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.10 ms /   148 tokens (    5.00 ms per token,   199.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.58 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     368.89 ms /    72 tokens (    5.12 ms per token,   195.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.83 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     565.12 ms /   112 tokens (    5.05 ms per token,   198.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.60 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.28 ms /   123 tokens (    4.95 ms per token,   201.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     614.96 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.72 ms /   160 tokens (    5.08 ms per token,   196.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     819.96 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     528.74 ms /   101 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     534.44 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      45.45 ms /     8 tokens (    5.68 ms per token,   176.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.40 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1066.12 ms /   211 tokens (    5.05 ms per token,   197.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1074.94 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     252.70 ms /    47 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.36 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.61 ms /   133 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.15 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     441.44 ms /    91 tokens (    4.85 ms per token,   206.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     446.36 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.40 ms /   135 tokens (    5.01 ms per token,   199.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.66 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     419.31 ms /    76 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     424.86 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.30 ms /   147 tokens (    4.99 ms per token,   200.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     740.43 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     454.14 ms /    87 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     458.95 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.94 ms /   168 tokens (    4.94 ms per token,   202.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.02 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     444.86 ms /    88 tokens (    5.06 ms per token,   197.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     449.95 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     568.22 ms /   117 tokens (    4.86 ms per token,   205.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     573.59 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.80 ms /   199 tokens (    5.08 ms per token,   196.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.56 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     456.91 ms /    56 tokens (    8.16 ms per token,   122.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     462.38 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.63 ms /   166 tokens (    6.01 ms per token,   166.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.78 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      35.27 ms /     4 tokens (    8.82 ms per token,   113.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.41 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1116.39 ms /   217 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.96 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     275.93 ms /    58 tokens (    4.76 ms per token,   210.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     280.82 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.13 ms /   133 tokens (    5.19 ms per token,   192.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     696.29 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.68 ms /   197 tokens (    5.09 ms per token,   196.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1010.61 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     640.66 ms /   112 tokens (    5.72 ms per token,   174.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     647.69 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1350.75 ms /   221 tokens (    6.11 ms per token,   163.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1360.49 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.45 ms /    87 tokens (    8.58 ms per token,   116.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.69 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1525.88 ms /   194 tokens (    7.87 ms per token,   127.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1534.95 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.76 ms /    98 tokens (    5.98 ms per token,   167.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.89 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1297.19 ms /   227 tokens (    5.71 ms per token,   174.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1305.46 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     333.88 ms /    62 tokens (    5.39 ms per token,   185.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.25 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.50 ms /   109 tokens (    5.90 ms per token,   169.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.26 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.79 ms /   155 tokens (    5.64 ms per token,   177.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.89 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.76 ms /   154 tokens (    6.36 ms per token,   157.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.19 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1310.92 ms /   209 tokens (    6.27 ms per token,   159.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1320.40 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.28 ms /   210 tokens (    5.40 ms per token,   185.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.47 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1796.58 ms /   320 tokens (    5.61 ms per token,   178.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1807.34 ms /   321 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.99 ms /    73 tokens (    5.44 ms per token,   183.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     402.33 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1221.33 ms /   211 tokens (    5.79 ms per token,   172.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1228.97 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.85 ms /   160 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     848.52 ms /   161 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.45 ms /   201 tokens (    5.59 ms per token,   178.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1135.32 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1420.00 ms /   254 tokens (    5.59 ms per token,   178.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1428.53 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1441.73 ms /   257 tokens (    5.61 ms per token,   178.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1450.67 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.81 ms /   127 tokens (    5.89 ms per token,   169.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.53 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1104.08 ms /   197 tokens (    5.60 ms per token,   178.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1111.96 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1416.51 ms /   254 tokens (    5.58 ms per token,   179.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.36 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.58 ms /   185 tokens (    6.82 ms per token,   146.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1269.94 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1222.44 ms /   176 tokens (    6.95 ms per token,   143.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1230.00 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     866.15 ms /   145 tokens (    5.97 ms per token,   167.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     873.85 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.96 ms /   149 tokens (    6.73 ms per token,   148.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1010.18 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1315.18 ms /   220 tokens (    5.98 ms per token,   167.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1324.14 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1248.22 ms /   218 tokens (    5.73 ms per token,   174.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.03 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.33 ms /    98 tokens (    5.96 ms per token,   167.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.14 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2413.84 ms /   395 tokens (    6.11 ms per token,   163.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2427.40 ms /   396 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2757.37 ms /   413 tokens (    6.68 ms per token,   149.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2781.47 ms /   414 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2567.68 ms /   414 tokens (    6.20 ms per token,   161.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2580.07 ms /   415 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1341.58 ms /   227 tokens (    5.91 ms per token,   169.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1349.11 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1223.09 ms /   204 tokens (    6.00 ms per token,   166.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1230.36 ms /   205 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 17/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1172.83 ms /   207 tokens (    5.67 ms per token,   176.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1182.04 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.82 ms /   119 tokens (    5.91 ms per token,   169.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     710.71 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.05 ms /   208 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1096.67 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     289.92 ms /    55 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     294.96 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1201.23 ms /   217 tokens (    5.54 ms per token,   180.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1210.37 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.54 ms /   258 tokens (    7.11 ms per token,   140.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1843.98 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.33 ms /   151 tokens (    6.25 ms per token,   160.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.80 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     542.70 ms /    94 tokens (    5.77 ms per token,   173.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     550.54 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.84 ms /   166 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.68 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.72 ms /   164 tokens (    6.26 ms per token,   159.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.96 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.26 ms /   123 tokens (    6.99 ms per token,   142.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.39 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1235.54 ms /   201 tokens (    6.15 ms per token,   162.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1245.58 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1433.89 ms /   224 tokens (    6.40 ms per token,   156.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1446.19 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.89 ms /   137 tokens (    6.46 ms per token,   154.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.47 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.03 ms /   127 tokens (    7.37 ms per token,   135.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.01 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1235.96 ms /   193 tokens (    6.40 ms per token,   156.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1244.96 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1530.50 ms /   270 tokens (    5.67 ms per token,   176.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1541.00 ms /   271 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1523.71 ms /   252 tokens (    6.05 ms per token,   165.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1532.52 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     502.79 ms /    88 tokens (    5.71 ms per token,   175.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     507.67 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1553.80 ms /   232 tokens (    6.70 ms per token,   149.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1563.49 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     623.08 ms /    89 tokens (    7.00 ms per token,   142.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     630.78 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.49 ms /   174 tokens (    9.70 ms per token,   103.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1699.19 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.91 ms /   125 tokens (    5.87 ms per token,   170.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     740.29 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     684.56 ms /   122 tokens (    5.61 ms per token,   178.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.07 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1199.17 ms /   164 tokens (    7.31 ms per token,   136.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1207.27 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.93 ms /   147 tokens (    6.47 ms per token,   154.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     959.77 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1449.05 ms /   223 tokens (    6.50 ms per token,   153.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1457.95 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1033.60 ms /   197 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1041.34 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1281.77 ms /   212 tokens (    6.05 ms per token,   165.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.17 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1027.56 ms /   191 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.94 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     393.21 ms /    80 tokens (    4.92 ms per token,   203.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     399.09 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1350.33 ms /   235 tokens (    5.75 ms per token,   174.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1358.50 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     347.03 ms /    63 tokens (    5.51 ms per token,   181.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     351.63 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     479.88 ms /    96 tokens (    5.00 ms per token,   200.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     485.88 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.15 ms /   185 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.20 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1037.57 ms /   189 tokens (    5.49 ms per token,   182.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1044.89 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1901.59 ms /   223 tokens (    8.53 ms per token,   117.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1912.59 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.93 ms /   135 tokens (    5.73 ms per token,   174.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.41 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1406.99 ms /   261 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.77 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     501.15 ms /    97 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     506.28 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     395.24 ms /    79 tokens (    5.00 ms per token,   199.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     402.11 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.45 ms /   153 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     832.81 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.89 ms /   136 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.22 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1451.55 ms /   218 tokens (    6.66 ms per token,   150.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1459.80 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.79 ms /   174 tokens (    6.50 ms per token,   153.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.92 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     475.10 ms /    88 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     480.62 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.00 ms /   152 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     821.48 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.91 ms /   171 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.42 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1070.67 ms /   201 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.18 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.64 ms /   147 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     772.49 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     530.52 ms /   100 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     539.50 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.47 ms /   124 tokens (    5.10 ms per token,   196.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     638.61 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.26 ms /   157 tokens (    5.11 ms per token,   195.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.09 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.83 ms /   158 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     831.03 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     648.93 ms /   129 tokens (    5.03 ms per token,   198.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     655.46 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1209.34 ms /   232 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1217.71 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     509.92 ms /   104 tokens (    4.90 ms per token,   203.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     515.36 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     735.44 ms /   141 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     741.51 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     441.51 ms /    86 tokens (    5.13 ms per token,   194.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     446.20 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     962.67 ms /   188 tokens (    5.12 ms per token,   195.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     970.35 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.01 ms /   191 tokens (    5.11 ms per token,   195.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     983.51 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.04 ms /   184 tokens (    5.17 ms per token,   193.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.95 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.75 ms /   196 tokens (    5.13 ms per token,   194.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1013.92 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.41 ms /   191 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1013.24 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.76 ms /   162 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     848.86 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.61 ms /   202 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.94 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1184.52 ms /   220 tokens (    5.38 ms per token,   185.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.55 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.84 ms /   183 tokens (    5.06 ms per token,   197.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.09 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     727.26 ms /   138 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     734.32 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.85 ms /   189 tokens (    5.12 ms per token,   195.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.46 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1072.86 ms /   209 tokens (    5.13 ms per token,   194.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.58 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.13 ms /   226 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1204.67 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.89 ms /   180 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.22 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.77 ms /   195 tokens (    5.22 ms per token,   191.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.86 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.01 ms /   139 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.42 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.88 ms /   161 tokens (    5.13 ms per token,   194.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     832.41 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     518.87 ms /   106 tokens (    4.89 ms per token,   204.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     524.57 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.45 ms /   140 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     739.81 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1655.19 ms /   252 tokens (    6.57 ms per token,   152.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1664.22 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.71 ms /   147 tokens (    5.06 ms per token,   197.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     751.05 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.15 ms /   176 tokens (    5.18 ms per token,   193.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     918.23 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.56 ms /   175 tokens (    5.20 ms per token,   192.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.42 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.20 ms /   224 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1204.55 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1210.79 ms /   221 tokens (    5.48 ms per token,   182.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.68 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1357.28 ms /   257 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1365.61 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1370.42 ms /   250 tokens (    5.48 ms per token,   182.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1379.22 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     223.85 ms /    38 tokens (    5.89 ms per token,   169.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.02 ms /    39 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.86 ms /   216 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1171.85 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.95 ms /    88 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     471.72 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.71 ms /   197 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.99 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.27 ms /   138 tokens (    6.66 ms per token,   150.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     926.29 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1349.39 ms /   242 tokens (    5.58 ms per token,   179.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1359.02 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     281.56 ms /    51 tokens (    5.52 ms per token,   181.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     285.48 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.45 ms /   179 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.62 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.82 ms /   178 tokens (    5.58 ms per token,   179.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     999.64 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1284.18 ms /   236 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1292.12 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.62 ms /   124 tokens (    5.14 ms per token,   194.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     643.69 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     590.79 ms /   112 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.78 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.00 ms /   184 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     965.44 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.34 ms /   111 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     603.05 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1429.16 ms /   271 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.44 ms /   272 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1262.63 ms /   240 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1271.50 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.69 ms /   213 tokens (    5.40 ms per token,   185.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1157.54 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.81 ms /   180 tokens (    5.15 ms per token,   194.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.91 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.42 ms /   180 tokens (    5.09 ms per token,   196.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.67 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1756.97 ms /   323 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1766.73 ms /   324 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     622.56 ms /   124 tokens (    5.02 ms per token,   199.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     628.21 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.61 ms /   178 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.15 ms /   179 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 18/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     527.67 ms /    97 tokens (    5.44 ms per token,   183.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     532.88 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     998.92 ms /   192 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.22 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.12 ms /    93 tokens (    6.72 ms per token,   148.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     630.07 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.65 ms /   126 tokens (    6.84 ms per token,   146.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     869.06 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.70 ms /   120 tokens (    6.33 ms per token,   157.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.39 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.11 ms /   120 tokens (    5.48 ms per token,   182.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     665.59 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1240.24 ms /   197 tokens (    6.30 ms per token,   158.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.70 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.76 ms /   134 tokens (    6.10 ms per token,   164.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.60 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.51 ms /   156 tokens (    6.08 ms per token,   164.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.37 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.69 ms /   104 tokens (    6.38 ms per token,   156.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     670.61 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.64 ms /   184 tokens (    6.25 ms per token,   159.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.73 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1296.27 ms /   220 tokens (    5.89 ms per token,   169.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.06 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.50 ms /   165 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     862.71 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.90 ms /   174 tokens (    5.08 ms per token,   196.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     892.19 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.53 ms /   208 tokens (    5.11 ms per token,   195.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.40 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     321.14 ms /    60 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     325.25 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.87 ms /   212 tokens (    5.13 ms per token,   194.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1095.65 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.47 ms /   209 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.56 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.78 ms /   151 tokens (    5.05 ms per token,   197.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     770.05 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.63 ms /   184 tokens (    5.07 ms per token,   197.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.08 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1170.36 ms /   227 tokens (    5.16 ms per token,   193.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1178.85 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.56 ms /   158 tokens (    4.97 ms per token,   201.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     794.02 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.46 ms /   193 tokens (    5.14 ms per token,   194.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.11 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.65 ms /   196 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.18 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1184.62 ms /   223 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.62 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.20 ms /   144 tokens (    5.00 ms per token,   199.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     726.34 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.58 ms /   161 tokens (    5.11 ms per token,   195.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.73 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.14 ms /   131 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.85 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.41 ms /   201 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.50 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.72 ms /   195 tokens (    5.13 ms per token,   195.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1007.64 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.36 ms /   183 tokens (    5.06 ms per token,   197.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.72 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.66 ms /   185 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     964.69 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     301.50 ms /    58 tokens (    5.20 ms per token,   192.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     306.72 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.50 ms /   185 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     990.06 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.63 ms /   165 tokens (    6.94 ms per token,   144.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1154.16 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.17 ms /   179 tokens (    5.07 ms per token,   197.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.21 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.81 ms /   163 tokens (    5.12 ms per token,   195.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     841.53 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     223.80 ms /    45 tokens (    4.97 ms per token,   201.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     229.24 ms /    46 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 19/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.58 ms /   162 tokens (    5.19 ms per token,   192.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.65 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.78 ms /   144 tokens (    5.05 ms per token,   198.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     734.17 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.37 ms /   215 tokens (    5.10 ms per token,   196.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.62 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     472.38 ms /    86 tokens (    5.49 ms per token,   182.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     477.18 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.56 ms /   128 tokens (    5.06 ms per token,   197.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     653.66 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.67 ms /   136 tokens (    4.95 ms per token,   201.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     680.57 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.91 ms /   146 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.23 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.39 ms /   131 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.20 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.97 ms /   174 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     907.56 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     654.52 ms /   131 tokens (    5.00 ms per token,   200.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     661.72 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.75 ms /   106 tokens (    5.62 ms per token,   177.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.08 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      86.63 ms /    10 tokens (    8.66 ms per token,   115.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      89.42 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1061.36 ms /   171 tokens (    6.21 ms per token,   161.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1069.29 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     970.20 ms /   185 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     977.57 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.31 ms /   140 tokens (    4.98 ms per token,   200.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.18 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.51 ms /   168 tokens (    4.96 ms per token,   201.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     840.90 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     706.11 ms /   138 tokens (    5.12 ms per token,   195.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     712.33 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     819.19 ms /   161 tokens (    5.09 ms per token,   196.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     826.00 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.66 ms /   169 tokens (    5.01 ms per token,   199.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     854.22 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.48 ms /   156 tokens (    5.00 ms per token,   199.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     787.89 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.31 ms /    74 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     400.83 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     553.40 ms /   114 tokens (    4.85 ms per token,   206.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     559.04 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.46 ms /   177 tokens (    5.13 ms per token,   194.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.18 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.30 ms /    97 tokens (    5.11 ms per token,   195.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     500.33 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.14 ms /   196 tokens (    5.13 ms per token,   195.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.76 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.32 ms /   174 tokens (    5.36 ms per token,   186.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.33 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.31 ms /   153 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     807.94 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.36 ms /   138 tokens (    4.91 ms per token,   203.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     684.58 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.68 ms /   181 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.70 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.76 ms /   182 tokens (    5.10 ms per token,   195.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     936.80 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     254.30 ms /    49 tokens (    5.19 ms per token,   192.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     258.41 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.81 ms /   105 tokens (    5.01 ms per token,   199.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     531.97 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     540.43 ms /   110 tokens (    4.91 ms per token,   203.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.66 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.16 ms /   203 tokens (    5.08 ms per token,   196.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.63 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.96 ms /   146 tokens (    5.08 ms per token,   196.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.09 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.40 ms /   163 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     878.99 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.23 ms /   169 tokens (    5.17 ms per token,   193.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.94 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.92 ms /   190 tokens (    5.02 ms per token,   199.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.22 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.94 ms /   119 tokens (    4.91 ms per token,   203.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.56 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.46 ms /   108 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     572.11 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.35 ms /   103 tokens (    6.32 ms per token,   158.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     657.50 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     619.88 ms /    90 tokens (    6.89 ms per token,   145.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     625.05 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.73 ms /   166 tokens (    6.47 ms per token,   154.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.89 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     367.36 ms /    68 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.13 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.67 ms /   136 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.64 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.82 ms /   129 tokens (    5.12 ms per token,   195.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     668.75 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     450.13 ms /    88 tokens (    5.12 ms per token,   195.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     455.02 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.98 ms /   176 tokens (    4.98 ms per token,   200.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.68 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     394.57 ms /    73 tokens (    5.41 ms per token,   185.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     399.09 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.75 ms /   153 tokens (    5.04 ms per token,   198.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     778.20 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.92 ms /   162 tokens (    5.26 ms per token,   189.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.23 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.19 ms /   123 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     644.39 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.57 ms /   115 tokens (    5.05 ms per token,   198.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     586.19 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     324.20 ms /    66 tokens (    4.91 ms per token,   203.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.69 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.03 ms /   194 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.41 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.65 ms /   123 tokens (    5.13 ms per token,   195.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     637.38 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     427.71 ms /    87 tokens (    4.92 ms per token,   203.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     433.27 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     669.85 ms /   129 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     676.37 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.41 ms /   183 tokens (    4.90 ms per token,   203.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     904.94 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.82 ms /   136 tokens (    5.01 ms per token,   199.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     689.12 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.97 ms /   189 tokens (    5.12 ms per token,   195.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     976.27 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     377.72 ms /    74 tokens (    5.10 ms per token,   195.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.68 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.65 ms /   190 tokens (    4.98 ms per token,   200.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     953.25 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.03 ms /   164 tokens (    5.20 ms per token,   192.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     859.00 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     593.55 ms /   113 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     599.59 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.14 ms /   175 tokens (    5.11 ms per token,   195.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.34 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.59 ms /   140 tokens (    5.00 ms per token,   199.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     706.82 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.24 ms /   185 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.93 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.90 ms /   174 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.64 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     588.04 ms /   105 tokens (    5.60 ms per token,   178.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     593.55 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.99 ms /   153 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.01 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     492.68 ms /    97 tokens (    5.08 ms per token,   196.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     497.76 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.02 ms /   162 tokens (    5.19 ms per token,   192.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     848.06 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.78 ms /   172 tokens (    5.05 ms per token,   198.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     875.06 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     509.27 ms /   101 tokens (    5.04 ms per token,   198.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     514.64 ms /   102 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.66 ms /   137 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     733.99 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.21 ms /   158 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.93 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1117.35 ms /   190 tokens (    5.88 ms per token,   170.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1125.35 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.20 ms /   150 tokens (    6.23 ms per token,   160.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     945.11 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.38 ms /   124 tokens (    5.01 ms per token,   199.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.37 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     518.33 ms /   104 tokens (    4.98 ms per token,   200.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     524.39 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.66 ms /    95 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     501.07 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1526.45 ms /   294 tokens (    5.19 ms per token,   192.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.15 ms /   295 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     195.60 ms /    39 tokens (    5.02 ms per token,   199.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.08 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     562.06 ms /   109 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     567.82 ms /   110 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 21/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.93 ms /   211 tokens (    5.17 ms per token,   193.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.36 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     669.31 ms /   132 tokens (    5.07 ms per token,   197.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     676.98 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.66 ms /   126 tokens (    5.07 ms per token,   197.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     644.56 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     963.83 ms /   183 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.71 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.73 ms /   156 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     845.80 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.89 ms /   182 tokens (    5.16 ms per token,   193.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     946.07 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     109.42 ms /     5 tokens (   21.88 ms per token,    45.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     115.04 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1429.25 ms /   227 tokens (    6.30 ms per token,   158.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.67 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     299.99 ms /    55 tokens (    5.45 ms per token,   183.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.39 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.73 ms /   207 tokens (    5.13 ms per token,   194.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.32 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     262.75 ms /    44 tokens (    5.97 ms per token,   167.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     266.38 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.39 ms /    96 tokens (    5.16 ms per token,   193.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     501.11 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.14 ms /   133 tokens (    5.08 ms per token,   196.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.20 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1018.56 ms /   198 tokens (    5.14 ms per token,   194.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.42 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.56 ms /   204 tokens (    5.10 ms per token,   196.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.14 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     256.69 ms /    41 tokens (    6.26 ms per token,   159.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     261.87 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1132.01 ms /   219 tokens (    5.17 ms per token,   193.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1140.83 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.07 ms /   188 tokens (    4.99 ms per token,   200.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     945.73 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.28 ms /   198 tokens (    5.08 ms per token,   196.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.47 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.81 ms /   152 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     819.34 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.13 ms /   186 tokens (    5.09 ms per token,   196.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     954.46 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.88 ms /   181 tokens (    5.11 ms per token,   195.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.67 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     366.49 ms /    65 tokens (    5.64 ms per token,   177.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     372.43 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.71 ms /   193 tokens (    5.19 ms per token,   192.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.54 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.90 ms /   158 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     859.77 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.36 ms /   112 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.63 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.07 ms /   173 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.48 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.57 ms /   101 tokens (    6.66 ms per token,   150.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     680.13 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1309.74 ms /   208 tokens (    6.30 ms per token,   158.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1319.02 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     522.32 ms /    91 tokens (    5.74 ms per token,   174.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     528.25 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1131.85 ms /   197 tokens (    5.75 ms per token,   174.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1139.42 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     352.27 ms /    54 tokens (    6.52 ms per token,   153.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     356.72 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.54 ms /   124 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     661.88 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     712.58 ms /   138 tokens (    5.16 ms per token,   193.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     719.96 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1101.19 ms /   212 tokens (    5.19 ms per token,   192.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1109.99 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.32 ms /   159 tokens (    5.17 ms per token,   193.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.77 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1151.41 ms /   212 tokens (    5.43 ms per token,   184.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1159.13 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.46 ms /    62 tokens (    7.78 ms per token,   128.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     487.21 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1239.09 ms /   188 tokens (    6.59 ms per token,   151.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1247.40 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.35 ms /    95 tokens (    5.08 ms per token,   196.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     487.57 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1078.95 ms /   206 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1086.86 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     578.08 ms /   111 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     583.68 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.73 ms /   223 tokens (    5.40 ms per token,   185.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.76 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.10 ms /   133 tokens (    5.10 ms per token,   196.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     684.06 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.44 ms /   198 tokens (    5.11 ms per token,   195.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.68 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.10 ms /   167 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.74 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1224.94 ms /   232 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.08 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.90 ms /   103 tokens (    5.03 ms per token,   198.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     523.29 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.55 ms /   172 tokens (    5.11 ms per token,   195.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.37 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     934.74 ms /   183 tokens (    5.11 ms per token,   195.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.25 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     450.87 ms /    87 tokens (    5.18 ms per token,   192.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     455.96 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1243.16 ms /   237 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1251.81 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     467.45 ms /    93 tokens (    5.03 ms per token,   198.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     472.49 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.07 ms /   173 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.13 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     592.58 ms /   115 tokens (    5.15 ms per token,   194.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     598.20 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.68 ms /   165 tokens (    5.12 ms per token,   195.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.81 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.42 ms /   144 tokens (    5.04 ms per token,   198.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     732.24 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.66 ms /   207 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.16 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.95 ms /   145 tokens (    5.15 ms per token,   194.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.88 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.63 ms /   204 tokens (    5.34 ms per token,   187.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.83 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1070.32 ms /   205 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.27 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.76 ms /   170 tokens (    5.11 ms per token,   195.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     877.21 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.66 ms /   221 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.56 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     956.70 ms /   186 tokens (    5.14 ms per token,   194.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.96 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     194.69 ms /    34 tokens (    5.73 ms per token,   174.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     197.93 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.08 ms /   186 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     996.76 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.55 ms /   154 tokens (    6.66 ms per token,   150.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.55 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     416.14 ms /    73 tokens (    5.70 ms per token,   175.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     422.74 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.95 ms /   173 tokens (    5.13 ms per token,   195.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.99 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.69 ms /   159 tokens (    5.15 ms per token,   194.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     825.54 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.26 ms /   199 tokens (    5.13 ms per token,   195.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.83 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.10 ms /   127 tokens (    5.02 ms per token,   199.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     644.67 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     173.80 ms /    34 tokens (    5.11 ms per token,   195.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     177.11 ms /    35 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      42.65 ms /     3 tokens (   14.22 ms per token,    70.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.23 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.08 ms /   192 tokens (    5.07 ms per token,   197.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.46 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.78 ms /   172 tokens (    5.14 ms per token,   194.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.83 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.46 ms /   169 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     882.36 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.79 ms /   151 tokens (    5.20 ms per token,   192.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     792.47 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1145.57 ms /   214 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1153.81 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2130.48 ms /   350 tokens (    6.09 ms per token,   164.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2141.33 ms /   351 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1256.58 ms /   240 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1264.79 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2123.47 ms /   394 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2135.63 ms /   395 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1718.40 ms /   321 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1729.64 ms /   322 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.63 ms /   310 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1635.57 ms /   311 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1449.28 ms /   279 tokens (    5.19 ms per token,   192.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1458.28 ms /   280 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1415.22 ms /   267 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1423.78 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     268.20 ms /    54 tokens (    4.97 ms per token,   201.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     271.92 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     527.04 ms /   102 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     532.36 ms /   103 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.17 ms /   157 tokens (    5.20 ms per token,   192.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.30 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1494.38 ms /   280 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1503.61 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1551.03 ms /   297 tokens (    5.22 ms per token,   191.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1570.10 ms /   298 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1769.24 ms /   334 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1779.56 ms /   335 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.45 ms /   161 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     858.93 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1394.41 ms /   264 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1403.47 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.73 ms /   125 tokens (    5.14 ms per token,   194.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.86 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     526.47 ms /   103 tokens (    5.11 ms per token,   195.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     531.67 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.90 ms /   139 tokens (    5.19 ms per token,   192.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     727.36 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.15 ms /   148 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.59 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     457.56 ms /    90 tokens (    5.08 ms per token,   196.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     462.38 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.39 ms /   169 tokens (    5.91 ms per token,   169.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.95 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.75 ms /    54 tokens (    6.22 ms per token,   160.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     342.61 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.91 ms /   152 tokens (    5.68 ms per token,   175.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     871.06 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     513.32 ms /    89 tokens (    5.77 ms per token,   173.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     519.20 ms /    90 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 24/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.26 ms /   137 tokens (    7.26 ms per token,   137.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.03 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1391.14 ms /   199 tokens (    6.99 ms per token,   143.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1400.26 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.26 ms /   194 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1036.19 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1027.66 ms /   195 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1035.83 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.52 ms /   205 tokens (    5.49 ms per token,   182.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1133.85 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1737.53 ms /   315 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1748.46 ms /   316 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     318.26 ms /    56 tokens (    5.68 ms per token,   175.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.47 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1193.44 ms /   226 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1203.44 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.47 ms /   139 tokens (    5.00 ms per token,   199.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.37 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.63 ms /   122 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     654.64 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      34.35 ms /     3 tokens (   11.45 ms per token,    87.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.68 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1145.88 ms /   210 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1155.80 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.03 ms /    97 tokens (    5.41 ms per token,   184.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     529.94 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1409.59 ms /   248 tokens (    5.68 ms per token,   175.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1418.66 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     426.35 ms /    82 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     431.78 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.74 ms /   169 tokens (    5.06 ms per token,   197.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     863.95 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.02 ms /   188 tokens (    4.98 ms per token,   200.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     944.42 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.90 ms /   200 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.21 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.97 ms /   161 tokens (    5.60 ms per token,   178.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.50 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1233.49 ms /   239 tokens (    5.16 ms per token,   193.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.40 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     361.27 ms /    63 tokens (    5.73 ms per token,   174.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     366.04 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.85 ms /   194 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.67 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1037.33 ms /   202 tokens (    5.14 ms per token,   194.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.44 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     529.65 ms /   101 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     538.59 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     556.99 ms /   104 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     562.35 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.30 ms /   146 tokens (    5.07 ms per token,   197.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.95 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.75 ms /   154 tokens (    4.88 ms per token,   204.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.59 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1517.97 ms /   231 tokens (    6.57 ms per token,   152.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1529.72 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.14 ms /   152 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     803.87 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.20 ms /   188 tokens (    5.07 ms per token,   197.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.01 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     382.71 ms /    73 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.82 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.76 ms /   201 tokens (    5.19 ms per token,   192.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.52 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1117.95 ms /   207 tokens (    5.40 ms per token,   185.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1125.93 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1054.19 ms /   204 tokens (    5.17 ms per token,   193.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.63 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.68 ms /   172 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.67 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.87 ms /   160 tokens (    5.15 ms per token,   194.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     831.60 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.55 ms /   190 tokens (    5.30 ms per token,   188.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1015.25 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.14 ms /   149 tokens (    6.39 ms per token,   156.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.12 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1027.44 ms /   204 tokens (    5.04 ms per token,   198.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1036.39 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1305.14 ms /   247 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1315.35 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1018.21 ms /   197 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1026.00 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.14 ms /   173 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.95 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.20 ms /   140 tokens (    5.27 ms per token,   189.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     744.29 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.55 ms /   176 tokens (    5.07 ms per token,   197.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.94 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.98 ms /   172 tokens (    5.01 ms per token,   199.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     869.18 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1139.92 ms /   215 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1149.03 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     298.69 ms /    57 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.82 ms /    58 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1067.45 ms /   204 tokens (    5.23 ms per token,   191.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.45 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     980.77 ms /   184 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.53 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.69 ms /    72 tokens (    4.86 ms per token,   205.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.03 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.04 ms /   168 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     890.03 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.18 ms /   166 tokens (    5.59 ms per token,   178.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     937.81 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.59 ms /   123 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     664.49 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.70 ms /   178 tokens (    5.15 ms per token,   194.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.62 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1091.85 ms /   203 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1100.25 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.63 ms /   179 tokens (    5.10 ms per token,   196.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     920.77 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.70 ms /   157 tokens (    5.09 ms per token,   196.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     806.57 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.09 ms /   296 tokens (    5.50 ms per token,   181.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1638.88 ms /   297 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.76 ms /   121 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     635.44 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1097.36 ms /   215 tokens (    5.10 ms per token,   195.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.33 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.59 ms /   142 tokens (    4.99 ms per token,   200.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.05 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      33.54 ms /     3 tokens (   11.18 ms per token,    89.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.83 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1216.03 ms /   224 tokens (    5.43 ms per token,   184.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1224.39 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     490.26 ms /    98 tokens (    5.00 ms per token,   199.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     495.92 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1160.42 ms /   220 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1168.73 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.33 ms /   197 tokens (    5.21 ms per token,   191.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1035.02 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.44 ms /   154 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     826.47 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     961.02 ms /   182 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     968.54 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.74 ms /   129 tokens (    5.16 ms per token,   193.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     672.28 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.77 ms /   166 tokens (    6.18 ms per token,   161.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1035.12 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1034.86 ms /   162 tokens (    6.39 ms per token,   156.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1042.68 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.55 ms /   168 tokens (    5.92 ms per token,   168.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1002.62 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.20 ms /   188 tokens (    4.96 ms per token,   201.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.65 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     322.93 ms /    63 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     329.04 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.65 ms /   134 tokens (    5.14 ms per token,   194.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.77 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.17 ms /   174 tokens (    5.14 ms per token,   194.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.18 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.93 ms /   134 tokens (    5.13 ms per token,   194.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.86 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.78 ms /   150 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.29 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.62 ms /   160 tokens (    5.06 ms per token,   197.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     816.27 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.90 ms /   185 tokens (    5.04 ms per token,   198.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.25 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.52 ms /   170 tokens (    5.17 ms per token,   193.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.39 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.33 ms /   147 tokens (    5.12 ms per token,   195.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     758.40 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.21 ms /   157 tokens (    5.02 ms per token,   199.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     794.95 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     445.66 ms /    86 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     451.65 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.12 ms /   171 tokens (    5.09 ms per token,   196.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     878.39 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1284.79 ms /   243 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1293.39 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1243.26 ms /   230 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.81 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.65 ms /   152 tokens (    4.95 ms per token,   202.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     759.11 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.14 ms /   171 tokens (    5.13 ms per token,   194.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.99 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.46 ms /   125 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     657.16 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.64 ms /   164 tokens (    5.07 ms per token,   197.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.15 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.51 ms /   197 tokens (    5.17 ms per token,   193.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.74 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     258.85 ms /    43 tokens (    6.02 ms per token,   166.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     263.85 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1290.66 ms /   250 tokens (    5.16 ms per token,   193.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.20 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     573.83 ms /   111 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     579.36 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.68 ms /   145 tokens (    7.00 ms per token,   142.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.23 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.74 ms /   143 tokens (    5.86 ms per token,   170.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.95 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      36.47 ms /     2 tokens (   18.23 ms per token,    54.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.71 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.50 ms /   156 tokens (    5.07 ms per token,   197.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.41 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     544.41 ms /   108 tokens (    5.04 ms per token,   198.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     550.76 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.04 ms /   141 tokens (    5.10 ms per token,   196.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     727.45 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.71 ms /   146 tokens (    5.09 ms per token,   196.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.25 ms /   147 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 27/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.29 ms /   224 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1187.16 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     433.24 ms /    87 tokens (    4.98 ms per token,   200.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     438.04 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.49 ms /   145 tokens (    5.13 ms per token,   194.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     751.31 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1021.23 ms /   197 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1029.38 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.62 ms /   128 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     681.54 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.28 ms /   181 tokens (    6.55 ms per token,   152.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.29 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.28 ms /   196 tokens (    5.15 ms per token,   194.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.98 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1488.41 ms /   277 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1498.54 ms /   278 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1770.22 ms /   325 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1780.75 ms /   326 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1510.76 ms /   285 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1520.13 ms /   286 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.92 ms /   163 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.55 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1501.20 ms /   276 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1510.38 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1077.82 ms /   193 tokens (    5.58 ms per token,   179.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1085.05 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1457.04 ms /   281 tokens (    5.19 ms per token,   192.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.49 ms /   282 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.36 ms /   105 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.03 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1255.78 ms /   239 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1264.52 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.15 ms /   183 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.38 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.40 ms /   208 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.46 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.14 ms /   174 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     903.00 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     562.67 ms /   112 tokens (    5.02 ms per token,   199.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     568.62 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.24 ms /   176 tokens (    5.10 ms per token,   195.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.59 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     475.44 ms /    90 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     480.42 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.75 ms /   161 tokens (    5.12 ms per token,   195.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     830.78 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.56 ms /   180 tokens (    5.01 ms per token,   199.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     910.30 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     627.59 ms /   124 tokens (    5.06 ms per token,   197.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.62 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.85 ms /   168 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.60 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     455.84 ms /    84 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     460.82 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1205.42 ms /   203 tokens (    5.94 ms per token,   168.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1214.83 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     504.25 ms /   100 tokens (    5.04 ms per token,   198.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     509.69 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1462.03 ms /   238 tokens (    6.14 ms per token,   162.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1471.85 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     404.77 ms /    63 tokens (    6.42 ms per token,   155.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.69 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     487.26 ms /    78 tokens (    6.25 ms per token,   160.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     493.52 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1394.60 ms /   240 tokens (    5.81 ms per token,   172.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1404.80 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     507.72 ms /   104 tokens (    4.88 ms per token,   204.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     513.38 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.08 ms /    87 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     470.87 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.71 ms /   186 tokens (    5.01 ms per token,   199.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.80 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     413.27 ms /    80 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     417.97 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     501.28 ms /    99 tokens (    5.06 ms per token,   197.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     506.42 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.11 ms /   125 tokens (    5.00 ms per token,   199.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     631.57 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1270.16 ms /   185 tokens (    6.87 ms per token,   145.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1278.63 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.01 ms /   184 tokens (    6.11 ms per token,   163.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.40 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1468.39 ms /   273 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1477.66 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.36 ms /   121 tokens (    5.04 ms per token,   198.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     615.19 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.63 ms /   183 tokens (    5.00 ms per token,   200.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.79 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.50 ms /   197 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1040.40 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1314.86 ms /   238 tokens (    5.52 ms per token,   181.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1324.74 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.06 ms /   200 tokens (    5.02 ms per token,   199.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1010.68 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1091.91 ms /   206 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1100.17 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1286.85 ms /   249 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.61 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     547.86 ms /   111 tokens (    4.94 ms per token,   202.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     553.89 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.95 ms /   157 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     847.90 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1248.07 ms /   236 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.82 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.77 ms /   165 tokens (    4.95 ms per token,   202.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     823.63 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     582.71 ms /   109 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     588.05 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.71 ms /   195 tokens (    5.16 ms per token,   193.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.46 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1249.43 ms /   235 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1258.98 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.37 ms /   132 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.62 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.33 ms /   145 tokens (    5.03 ms per token,   198.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     735.75 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1066.67 ms /   204 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.40 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1162.73 ms /   176 tokens (    6.61 ms per token,   151.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1171.67 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.74 ms /   189 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     999.36 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.13 ms /   155 tokens (    4.95 ms per token,   202.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.69 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.14 ms /   169 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.51 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.56 ms /   158 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.98 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     494.71 ms /    88 tokens (    5.62 ms per token,   177.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     500.48 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     972.38 ms /   167 tokens (    5.82 ms per token,   171.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     980.50 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.20 ms /   184 tokens (    5.10 ms per token,   196.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     947.76 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.22 ms /   184 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     966.20 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1366.45 ms /   201 tokens (    6.80 ms per token,   147.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1374.80 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     379.76 ms /    78 tokens (    4.87 ms per token,   205.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.33 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.66 ms /   203 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1053.64 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.14 ms /   112 tokens (    5.00 ms per token,   199.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     566.49 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1160.64 ms /   228 tokens (    5.09 ms per token,   196.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1169.00 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.06 ms /   231 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1228.72 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     627.11 ms /   128 tokens (    4.90 ms per token,   204.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.85 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.94 ms /   200 tokens (    5.09 ms per token,   196.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.97 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.90 ms /   216 tokens (    5.24 ms per token,   191.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.96 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.44 ms /   143 tokens (    4.87 ms per token,   205.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.94 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.89 ms /   156 tokens (    5.12 ms per token,   195.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     805.54 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1165.48 ms /   226 tokens (    5.16 ms per token,   193.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1173.72 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.69 ms /   167 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.75 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.64 ms /   165 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     874.06 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.34 ms /   172 tokens (    5.16 ms per token,   193.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.28 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.96 ms /   195 tokens (    5.39 ms per token,   185.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.64 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.99 ms /   198 tokens (    5.12 ms per token,   195.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.18 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.97 ms /   117 tokens (    5.44 ms per token,   183.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     643.40 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1115.59 ms /   217 tokens (    5.14 ms per token,   194.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1125.17 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     263.96 ms /    54 tokens (    4.89 ms per token,   204.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     267.96 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.37 ms /   149 tokens (    5.13 ms per token,   194.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     770.75 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.31 ms /   174 tokens (    4.96 ms per token,   201.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     869.32 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.34 ms /   210 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1117.84 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.51 ms /   155 tokens (    4.89 ms per token,   204.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.14 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.39 ms /   211 tokens (    5.13 ms per token,   195.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1090.83 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.60 ms /   178 tokens (    5.12 ms per token,   195.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     918.80 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     453.71 ms /    87 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     458.72 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1135.81 ms /   211 tokens (    5.38 ms per token,   185.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1144.22 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.00 ms /   182 tokens (    5.03 ms per token,   198.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.69 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.39 ms /   207 tokens (    5.11 ms per token,   195.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.35 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.39 ms /   180 tokens (    5.04 ms per token,   198.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.63 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     516.57 ms /   104 tokens (    4.97 ms per token,   201.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     522.96 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     781.95 ms /   146 tokens (    5.36 ms per token,   186.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     790.07 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1179.04 ms /   224 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1187.95 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1043.49 ms /   204 tokens (    5.12 ms per token,   195.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.24 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.89 ms /   171 tokens (    5.20 ms per token,   192.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.23 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     540.47 ms /   106 tokens (    5.10 ms per token,   196.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.77 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.56 ms /   190 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.07 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1148.29 ms /   168 tokens (    6.84 ms per token,   146.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1157.36 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1131.74 ms /   190 tokens (    5.96 ms per token,   167.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.34 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.52 ms /   123 tokens (    5.09 ms per token,   196.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     631.17 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1186.67 ms /   219 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1196.20 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     588.88 ms /   117 tokens (    5.03 ms per token,   198.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     595.05 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.14 ms /   192 tokens (    5.09 ms per token,   196.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.13 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.71 ms /   134 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     711.93 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.02 ms /   188 tokens (    5.04 ms per token,   198.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.22 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     542.63 ms /   107 tokens (    5.07 ms per token,   197.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     549.27 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1246.24 ms /   244 tokens (    5.11 ms per token,   195.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.18 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1106.40 ms /   203 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1117.63 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.95 ms /   180 tokens (    4.95 ms per token,   202.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     898.08 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1201.81 ms /   227 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1210.39 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.56 ms /   169 tokens (    4.99 ms per token,   200.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.59 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.36 ms /   149 tokens (    5.09 ms per token,   196.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.18 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.02 ms /   104 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     540.72 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.15 ms /   198 tokens (    5.15 ms per token,   194.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.96 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.76 ms /   142 tokens (    5.10 ms per token,   196.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     731.61 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1241.69 ms /   233 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1250.77 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.26 ms /   157 tokens (    6.25 ms per token,   160.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.74 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1438.23 ms /   249 tokens (    5.78 ms per token,   173.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1449.92 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.53 ms /   197 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.34 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     984.09 ms /   193 tokens (    5.10 ms per token,   196.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     992.81 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1188.09 ms /   226 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1198.48 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.84 ms /   201 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.51 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.65 ms /   162 tokens (    5.39 ms per token,   185.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.35 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1443.75 ms /   225 tokens (    6.42 ms per token,   155.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1451.80 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.31 ms /   167 tokens (    5.10 ms per token,   195.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     860.13 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.06 ms /   122 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     636.89 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.14 ms /   195 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.73 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1230.46 ms /   229 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1239.69 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.81 ms /   208 tokens (    5.14 ms per token,   194.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.27 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     536.42 ms /    94 tokens (    5.71 ms per token,   175.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     541.48 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     781.52 ms /   153 tokens (    5.11 ms per token,   195.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     788.30 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.86 ms /   162 tokens (    5.12 ms per token,   195.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.33 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     731.03 ms /   142 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     738.18 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     666.88 ms /   129 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     672.69 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.40 ms /   109 tokens (    5.06 ms per token,   197.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     557.04 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1032.84 ms /   202 tokens (    5.11 ms per token,   195.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1040.60 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.33 ms /   176 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     943.65 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1237.86 ms /   236 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.44 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1240.51 ms /   226 tokens (    5.49 ms per token,   182.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1250.33 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1286.58 ms /   249 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.27 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.47 ms /   149 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.87 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.34 ms /   193 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.86 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1427.06 ms /   262 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1436.57 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1373.76 ms /   256 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1382.80 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1206.29 ms /   232 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1214.49 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1332.13 ms /   252 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1341.49 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1354.70 ms /   260 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1363.65 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1468.34 ms /   269 tokens (    5.46 ms per token,   183.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1477.54 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1416.08 ms /   273 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.54 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1350.00 ms /   253 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1360.42 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.30 ms /   111 tokens (    6.87 ms per token,   145.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     770.05 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      32.11 ms /     3 tokens (   10.70 ms per token,    93.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      34.42 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1325.53 ms /   254 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1335.14 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1640.83 ms /   306 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1652.75 ms /   307 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1275.48 ms /   246 tokens (    5.18 ms per token,   192.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.85 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1135.98 ms /   214 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1143.65 ms /   215 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 28/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.52 ms /   151 tokens (    5.14 ms per token,   194.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.36 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1453.20 ms /   208 tokens (    6.99 ms per token,   143.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.02 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.72 ms /   151 tokens (    6.06 ms per token,   164.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     922.82 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.08 ms /   199 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.63 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.66 ms /   117 tokens (    5.10 ms per token,   196.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.63 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1312.39 ms /   248 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1321.20 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     389.28 ms /    75 tokens (    5.19 ms per token,   192.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     395.61 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     578.53 ms /   113 tokens (    5.12 ms per token,   195.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.17 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1212.20 ms /   236 tokens (    5.14 ms per token,   194.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1221.83 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     514.35 ms /   103 tokens (    4.99 ms per token,   200.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     520.03 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.03 ms /   133 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     716.27 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1145.82 ms /   219 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1154.17 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     511.32 ms /    99 tokens (    5.16 ms per token,   193.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     516.46 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.42 ms /   146 tokens (    5.07 ms per token,   197.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.71 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.67 ms /   209 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.99 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.31 ms /   127 tokens (    5.06 ms per token,   197.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.92 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.87 ms /   163 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.53 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.12 ms /   211 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1098.30 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1253.75 ms /   241 tokens (    5.20 ms per token,   192.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1262.37 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1249.46 ms /   210 tokens (    5.95 ms per token,   168.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1259.06 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1175.85 ms /   195 tokens (    6.03 ms per token,   165.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1185.60 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.10 ms /   219 tokens (    5.17 ms per token,   193.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.13 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     998.79 ms /   195 tokens (    5.12 ms per token,   195.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.28 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1297.15 ms /   242 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1307.26 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1579.38 ms /   293 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1589.97 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     465.63 ms /    76 tokens (    6.13 ms per token,   163.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     470.28 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1493.83 ms /   258 tokens (    5.79 ms per token,   172.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1505.62 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     451.08 ms /    90 tokens (    5.01 ms per token,   199.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     456.85 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.22 ms /   210 tokens (    5.93 ms per token,   168.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1253.92 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1320.48 ms /   211 tokens (    6.26 ms per token,   159.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1329.82 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     317.83 ms /    47 tokens (    6.76 ms per token,   147.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     322.87 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.50 ms /   156 tokens (    6.11 ms per token,   163.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.57 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     620.50 ms /   102 tokens (    6.08 ms per token,   164.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     626.55 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1345.73 ms /   208 tokens (    6.47 ms per token,   154.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1354.06 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1324.60 ms /   214 tokens (    6.19 ms per token,   161.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1335.46 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1125.56 ms /   170 tokens (    6.62 ms per token,   151.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1134.94 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.71 ms /   159 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     840.23 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.41 ms /   135 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     709.35 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.17 ms /   133 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     723.53 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1199.80 ms /   228 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1209.69 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      54.26 ms /     6 tokens (    9.04 ms per token,   110.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.58 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1399.65 ms /   249 tokens (    5.62 ms per token,   177.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1410.73 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     387.00 ms /    76 tokens (    5.09 ms per token,   196.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.35 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1297.38 ms /   241 tokens (    5.38 ms per token,   185.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1307.16 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      56.25 ms /     7 tokens (    8.04 ms per token,   124.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.97 ms /     8 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1364.13 ms /   249 tokens (    5.48 ms per token,   182.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1373.90 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.95 ms /   118 tokens (    6.23 ms per token,   160.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     741.36 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     845.45 ms /   139 tokens (    6.08 ms per token,   164.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.81 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.39 ms /   169 tokens (    5.06 ms per token,   197.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.47 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.08 ms /   113 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.45 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1209.27 ms /   231 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.03 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     246.39 ms /    46 tokens (    5.36 ms per token,   186.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.31 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.01 ms /   236 tokens (    5.11 ms per token,   195.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1217.39 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.95 ms /   176 tokens (    5.11 ms per token,   195.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.90 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.51 ms /   208 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1090.83 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1213.20 ms /   238 tokens (    5.10 ms per token,   196.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.64 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1317.19 ms /   252 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1326.34 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1192.13 ms /   223 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1200.30 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.27 ms /   180 tokens (    5.00 ms per token,   200.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.63 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.52 ms /   176 tokens (    5.12 ms per token,   195.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     907.68 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1327.05 ms /   251 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1336.41 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     311.29 ms /    62 tokens (    5.02 ms per token,   199.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     315.47 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1161.39 ms /   226 tokens (    5.14 ms per token,   194.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1169.66 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.90 ms /   236 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.24 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.37 ms /   130 tokens (    5.04 ms per token,   198.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     661.74 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.77 ms /   134 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.42 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.58 ms /   197 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.16 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.17 ms /   150 tokens (    6.77 ms per token,   147.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.03 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1280.48 ms /   206 tokens (    6.22 ms per token,   160.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1289.48 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.24 ms /   145 tokens (    5.05 ms per token,   198.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     739.92 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1044.04 ms /   198 tokens (    5.27 ms per token,   189.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1053.70 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1084.49 ms /   209 tokens (    5.19 ms per token,   192.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1095.35 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1602.55 ms /   283 tokens (    5.66 ms per token,   176.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1611.86 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.27 ms /   158 tokens (    6.34 ms per token,   157.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.71 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1258.53 ms /   235 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1267.84 ms /   236 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 29/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.88 ms /   197 tokens (    5.14 ms per token,   194.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.59 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     309.13 ms /    58 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.20 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.13 ms /   239 tokens (    5.21 ms per token,   191.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1253.85 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.99 ms /   161 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.62 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.05 ms /   163 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     854.84 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.86 ms /   192 tokens (    5.09 ms per token,   196.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.68 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1308.22 ms /   198 tokens (    6.61 ms per token,   151.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1316.02 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1368.71 ms /   256 tokens (    5.35 ms per token,   187.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1379.31 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1682.46 ms /   274 tokens (    6.14 ms per token,   162.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1691.59 ms /   275 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1365.98 ms /   259 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1374.71 ms /   260 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.03 ms /   202 tokens (    5.40 ms per token,   185.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.43 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1332.58 ms /   241 tokens (    5.53 ms per token,   180.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.83 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1283.18 ms /   229 tokens (    5.60 ms per token,   178.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1292.30 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.87 ms /   184 tokens (    5.10 ms per token,   196.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     945.20 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1294.67 ms /   252 tokens (    5.14 ms per token,   194.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1304.84 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.71 ms /   144 tokens (    5.15 ms per token,   194.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     747.83 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.15 ms /   206 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1095.91 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.32 ms /   134 tokens (    5.18 ms per token,   192.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.90 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.90 ms /   194 tokens (    5.19 ms per token,   192.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1013.35 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.53 ms /   134 tokens (    5.15 ms per token,   194.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.25 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.28 ms /   166 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.28 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1296.86 ms /   240 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1305.17 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.97 ms /   202 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.88 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1223.06 ms /   229 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1231.25 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.61 ms /   175 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.70 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.55 ms /   176 tokens (    5.11 ms per token,   195.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.56 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.75 ms /   121 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.87 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1219.99 ms /   233 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1228.58 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     616.31 ms /   122 tokens (    5.05 ms per token,   197.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.43 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1271.44 ms /   238 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1280.37 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     340.95 ms /    67 tokens (    5.09 ms per token,   196.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.43 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     824.37 ms /   163 tokens (    5.06 ms per token,   197.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     831.49 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1479.60 ms /   277 tokens (    5.34 ms per token,   187.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1488.91 ms /   278 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1311.34 ms /   253 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1320.70 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.75 ms /   144 tokens (    5.01 ms per token,   199.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.07 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.55 ms /   195 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1055.12 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.60 ms /   172 tokens (    5.10 ms per token,   195.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.67 ms /   173 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.95 ms /   168 tokens (    5.19 ms per token,   192.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.93 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1137.37 ms /   218 tokens (    5.22 ms per token,   191.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1146.57 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.30 ms /   167 tokens (    5.47 ms per token,   182.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.90 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1043.70 ms /   202 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.46 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     594.18 ms /   115 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     600.41 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     352.38 ms /    72 tokens (    4.89 ms per token,   204.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     357.29 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1143.71 ms /   222 tokens (    5.15 ms per token,   194.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1153.65 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.61 ms /   184 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.18 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1029.91 ms /   199 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1038.31 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.65 ms /   189 tokens (    5.17 ms per token,   193.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.93 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.79 ms /   175 tokens (    5.09 ms per token,   196.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     898.95 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     600.06 ms /   115 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     606.24 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     550.96 ms /   110 tokens (    5.01 ms per token,   199.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     556.78 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.50 ms /   176 tokens (    5.09 ms per token,   196.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     904.38 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.45 ms /   196 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1056.36 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.27 ms /   216 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1161.75 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     365.03 ms /    68 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.46 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1354.63 ms /   193 tokens (    7.02 ms per token,   142.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1363.58 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.25 ms /   110 tokens (    6.56 ms per token,   152.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.34 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.06 ms /   119 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     620.82 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.36 ms /   198 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.08 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     380.35 ms /    66 tokens (    5.76 ms per token,   173.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     386.92 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.48 ms /   219 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1205.34 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.90 ms /    52 tokens (    5.11 ms per token,   195.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.97 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1178.39 ms /   161 tokens (    7.32 ms per token,   136.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1188.11 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.99 ms /   141 tokens (    6.40 ms per token,   156.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.60 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      38.59 ms /     3 tokens (   12.86 ms per token,    77.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      42.89 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1463.26 ms /   253 tokens (    5.78 ms per token,   172.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1472.66 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.46 ms /   207 tokens (    5.69 ms per token,   175.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1186.21 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1230.30 ms /   219 tokens (    5.62 ms per token,   178.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.48 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     488.38 ms /    84 tokens (    5.81 ms per token,   172.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     493.42 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1634.81 ms /   225 tokens (    7.27 ms per token,   137.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1646.80 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     727.49 ms /   109 tokens (    6.67 ms per token,   149.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     734.61 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.17 ms /   195 tokens (    6.01 ms per token,   166.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1178.87 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1175.86 ms /   199 tokens (    5.91 ms per token,   169.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1185.29 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1345.10 ms /   202 tokens (    6.66 ms per token,   150.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1355.41 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.10 ms /   136 tokens (    6.66 ms per token,   150.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     913.07 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1284.29 ms /   203 tokens (    6.33 ms per token,   158.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1293.50 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.58 ms /   161 tokens (    6.14 ms per token,   162.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.42 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.14 ms /   121 tokens (    5.83 ms per token,   171.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     710.76 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1310.23 ms /   224 tokens (    5.85 ms per token,   170.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1319.89 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1113.40 ms /   208 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.30 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.82 ms /   190 tokens (    6.43 ms per token,   155.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1231.34 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.50 ms /   187 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1020.19 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.69 ms /   149 tokens (    6.39 ms per token,   156.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.95 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.24 ms /   153 tokens (    6.08 ms per token,   164.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.33 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.10 ms /   147 tokens (    5.18 ms per token,   193.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.16 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.46 ms /   175 tokens (    6.27 ms per token,   159.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.23 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.28 ms /   150 tokens (    6.34 ms per token,   157.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     959.97 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1548.95 ms /   217 tokens (    7.14 ms per token,   140.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1558.70 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1226.94 ms /   184 tokens (    6.67 ms per token,   149.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1234.75 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1018.33 ms /   179 tokens (    5.69 ms per token,   175.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1026.88 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.84 ms /   158 tokens (    5.95 ms per token,   168.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.33 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.41 ms /   169 tokens (    5.40 ms per token,   185.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     922.13 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1320.48 ms /   225 tokens (    5.87 ms per token,   170.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1331.57 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     385.30 ms /    68 tokens (    5.67 ms per token,   176.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     390.78 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1228.50 ms /   201 tokens (    6.11 ms per token,   163.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1237.86 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.74 ms /   137 tokens (    6.60 ms per token,   151.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.45 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1428.02 ms /   171 tokens (    8.35 ms per token,   119.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1439.08 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1649.33 ms /   203 tokens (    8.12 ms per token,   123.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1661.60 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2977.67 ms /   206 tokens (   14.45 ms per token,    69.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2994.62 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1435.27 ms /   188 tokens (    7.63 ms per token,   130.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1446.94 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1400.75 ms /   177 tokens (    7.91 ms per token,   126.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1411.19 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1246.28 ms /   189 tokens (    6.59 ms per token,   151.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.98 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     136.01 ms /     4 tokens (   34.00 ms per token,    29.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     141.97 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1457.82 ms /   212 tokens (    6.88 ms per token,   145.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.52 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     476.97 ms /    68 tokens (    7.01 ms per token,   142.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     483.43 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1729.70 ms /   236 tokens (    7.33 ms per token,   136.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1742.19 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.90 ms /    93 tokens (    8.10 ms per token,   123.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     761.20 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.11 ms /   109 tokens (    7.88 ms per token,   126.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.53 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1484.01 ms /   210 tokens (    7.07 ms per token,   141.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1493.49 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1703.40 ms /   294 tokens (    5.79 ms per token,   172.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1712.98 ms /   295 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.73 ms /   135 tokens (    5.72 ms per token,   174.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     778.89 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     153.61 ms /    21 tokens (    7.31 ms per token,   136.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     156.45 ms /    22 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 31/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.16 ms /   141 tokens (    6.24 ms per token,   160.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.67 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.25 ms /   157 tokens (    6.52 ms per token,   153.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.08 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1395.02 ms /   212 tokens (    6.58 ms per token,   151.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1406.23 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.46 ms /   183 tokens (    5.69 ms per token,   175.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.75 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.79 ms /   158 tokens (    6.13 ms per token,   163.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.60 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.39 ms /   166 tokens (    6.17 ms per token,   162.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.65 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1109.83 ms /   163 tokens (    6.81 ms per token,   146.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.90 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1676.04 ms /   189 tokens (    8.87 ms per token,   112.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1687.68 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1221.97 ms /   171 tokens (    7.15 ms per token,   139.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.09 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1366.92 ms /   240 tokens (    5.70 ms per token,   175.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1377.11 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1253.30 ms /   179 tokens (    7.00 ms per token,   142.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1261.35 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1093.84 ms /   188 tokens (    5.82 ms per token,   171.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1102.52 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1054.88 ms /   179 tokens (    5.89 ms per token,   169.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.54 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.26 ms /   222 tokens (    5.50 ms per token,   181.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.04 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1294.24 ms /   223 tokens (    5.80 ms per token,   172.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1302.84 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     824.42 ms /   155 tokens (    5.32 ms per token,   188.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     832.93 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.91 ms /   194 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1022.35 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1276.35 ms /   236 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.88 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.53 ms /   142 tokens (    4.99 ms per token,   200.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     716.22 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1247.11 ms /   225 tokens (    5.54 ms per token,   180.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.86 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     320.14 ms /    63 tokens (    5.08 ms per token,   196.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     324.92 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.14 ms /   173 tokens (    6.06 ms per token,   165.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.13 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.48 ms /   202 tokens (    5.49 ms per token,   182.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.10 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1239.28 ms /   230 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1248.34 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     538.44 ms /    93 tokens (    5.79 ms per token,   172.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     543.98 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.94 ms /   197 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.83 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     328.17 ms /    62 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     333.13 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.15 ms /   152 tokens (    5.06 ms per token,   197.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.97 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1251.87 ms /   236 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.93 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.10 ms /   124 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     670.87 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1034.68 ms /   179 tokens (    5.78 ms per token,   173.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1043.12 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1193.58 ms /   214 tokens (    5.58 ms per token,   179.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1203.06 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.90 ms /   202 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.72 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.61 ms /   101 tokens (    5.67 ms per token,   176.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.59 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.65 ms /   194 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.54 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.65 ms /   180 tokens (    5.09 ms per token,   196.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     925.95 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.16 ms /   125 tokens (    5.15 ms per token,   194.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.24 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.62 ms /   217 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.87 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     484.39 ms /    89 tokens (    5.44 ms per token,   183.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     489.20 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     970.25 ms /   181 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     977.90 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     187.91 ms /    39 tokens (    4.82 ms per token,   207.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.83 ms /    40 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.87 ms /   186 tokens (    5.16 ms per token,   193.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     967.37 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.16 ms /   194 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.88 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.14 ms /   169 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     907.78 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1110.81 ms /   209 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.99 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1293.12 ms /   245 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1302.03 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.91 ms /   171 tokens (    5.17 ms per token,   193.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     892.34 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.53 ms /   168 tokens (    5.95 ms per token,   168.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.65 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1129.17 ms /   206 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1138.10 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1129.28 ms /   218 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.74 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.43 ms /   129 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     683.94 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1172.76 ms /   213 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1181.06 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.71 ms /   182 tokens (    5.06 ms per token,   197.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     929.22 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.82 ms /   141 tokens (    5.59 ms per token,   178.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.70 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.99 ms /   144 tokens (    5.14 ms per token,   194.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.58 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     460.38 ms /    95 tokens (    4.85 ms per token,   206.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     465.51 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.76 ms /   129 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.10 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.64 ms /   196 tokens (    5.19 ms per token,   192.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.92 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1125.94 ms /   205 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1135.76 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1415.70 ms /   227 tokens (    6.24 ms per token,   160.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1426.01 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.96 ms /   161 tokens (    5.53 ms per token,   180.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     897.64 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1408.12 ms /   257 tokens (    5.48 ms per token,   182.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1417.07 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1072.06 ms /   203 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1079.63 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1232.73 ms /   203 tokens (    6.07 ms per token,   164.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.90 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.21 ms /   167 tokens (    7.01 ms per token,   142.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1179.71 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.06 ms /   128 tokens (    5.51 ms per token,   181.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     711.30 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.98 ms /   191 tokens (    5.18 ms per token,   193.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     996.38 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.97 ms /   211 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.88 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.74 ms /   147 tokens (    5.14 ms per token,   194.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.36 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1601.74 ms /   293 tokens (    5.47 ms per token,   182.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1611.49 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.96 ms /   184 tokens (    5.12 ms per token,   195.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.12 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.43 ms /   214 tokens (    5.19 ms per token,   192.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.81 ms /   215 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1043.62 ms /   143 tokens (    7.30 ms per token,   137.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.94 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.77 ms /   128 tokens (    5.40 ms per token,   185.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     699.60 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.06 ms /   149 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.09 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.02 ms /   196 tokens (    5.06 ms per token,   197.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     999.84 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.89 ms /   197 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1040.88 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.05 ms /   107 tokens (    6.17 ms per token,   162.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     668.45 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.33 ms /   195 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1020.20 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1060.27 ms /   186 tokens (    5.70 ms per token,   175.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1070.04 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.51 ms /   180 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     970.04 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.81 ms /   175 tokens (    5.12 ms per token,   195.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     904.41 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1141.32 ms /   217 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1149.97 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.34 ms /   110 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     587.09 ms /   111 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 33/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     983.64 ms /   181 tokens (    5.43 ms per token,   184.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     993.46 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.09 ms /   181 tokens (    5.17 ms per token,   193.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.84 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.43 ms /   152 tokens (    5.02 ms per token,   199.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.82 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     371.57 ms /    69 tokens (    5.39 ms per token,   185.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.67 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1214.20 ms /   231 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.51 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     319.54 ms /    60 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     323.70 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.59 ms /   198 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.01 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.72 ms /   144 tokens (    5.39 ms per token,   185.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.40 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1309.08 ms /   250 tokens (    5.24 ms per token,   190.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1318.55 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.13 ms /   166 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.08 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.19 ms /   170 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     895.31 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1759.76 ms /   322 tokens (    5.47 ms per token,   182.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1772.51 ms /   323 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.73 ms /    47 tokens (    5.65 ms per token,   176.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.55 ms /    48 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 34/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     579.25 ms /   107 tokens (    5.41 ms per token,   184.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     586.86 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.57 ms /   172 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     903.78 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.07 ms /   108 tokens (    4.97 ms per token,   201.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     543.19 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1092.20 ms /   209 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1101.88 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      64.05 ms /     3 tokens (   21.35 ms per token,    46.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      69.83 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.54 ms /   211 tokens (    5.16 ms per token,   193.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.16 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.20 ms /   130 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     680.97 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1085.02 ms /   207 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1093.78 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.32 ms /   153 tokens (    5.44 ms per token,   183.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     840.50 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1035.60 ms /   195 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1044.48 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.12 ms /   215 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1158.90 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     330.96 ms /    63 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     336.68 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.60 ms /   116 tokens (    5.01 ms per token,   199.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     586.61 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.25 ms /   169 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.10 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.83 ms /   199 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.71 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.10 ms /   142 tokens (    5.45 ms per token,   183.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.10 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1050.99 ms /   202 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.15 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.77 ms /   166 tokens (    5.29 ms per token,   188.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.02 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.77 ms /   157 tokens (    4.99 ms per token,   200.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     789.62 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1157.24 ms /   207 tokens (    5.59 ms per token,   178.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1165.54 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     502.65 ms /    93 tokens (    5.40 ms per token,   185.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     507.77 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.64 ms /   187 tokens (    5.16 ms per token,   193.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     973.80 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     536.73 ms /   106 tokens (    5.06 ms per token,   197.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     541.98 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.98 ms /   212 tokens (    5.13 ms per token,   194.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.97 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     706.79 ms /   144 tokens (    4.91 ms per token,   203.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     713.89 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.65 ms /   152 tokens (    5.08 ms per token,   196.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.81 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.54 ms /   174 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     908.09 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.04 ms /   170 tokens (    5.54 ms per token,   180.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.71 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.57 ms /   132 tokens (    4.98 ms per token,   200.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     664.67 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.99 ms /   156 tokens (    5.03 ms per token,   198.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.22 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.50 ms /   124 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.66 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.92 ms /   121 tokens (    5.04 ms per token,   198.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     616.45 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1157.34 ms /   222 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1166.21 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.70 ms /   121 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     651.12 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.29 ms /   205 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.82 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.89 ms /   114 tokens (    5.64 ms per token,   177.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     648.47 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.97 ms /   188 tokens (    5.06 ms per token,   197.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.64 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.82 ms /   142 tokens (    6.43 ms per token,   155.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     919.88 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.51 ms /   132 tokens (    6.40 ms per token,   156.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.31 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.85 ms /   155 tokens (    5.65 ms per token,   176.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     882.85 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.70 ms /   203 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.92 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.67 ms /   162 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     871.78 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1072.28 ms /   207 tokens (    5.18 ms per token,   193.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.21 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     444.35 ms /    73 tokens (    6.09 ms per token,   164.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     451.18 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1269.40 ms /   225 tokens (    5.64 ms per token,   177.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.61 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1257.63 ms /   197 tokens (    6.38 ms per token,   156.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1267.61 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.32 ms /   190 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.83 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.70 ms /   188 tokens (    5.90 ms per token,   169.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.16 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1273.52 ms /   212 tokens (    6.01 ms per token,   166.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1281.82 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.13 ms /   108 tokens (    6.47 ms per token,   154.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.58 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.87 ms /   168 tokens (    5.99 ms per token,   166.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.45 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.22 ms /   187 tokens (    5.39 ms per token,   185.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.98 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.61 ms /   167 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.54 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.55 ms /   195 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.99 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     567.51 ms /    98 tokens (    5.79 ms per token,   172.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     574.03 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.81 ms /   158 tokens (    5.01 ms per token,   199.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.53 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1214.09 ms /   231 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.40 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1316.28 ms /   246 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1325.85 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     603.50 ms /   118 tokens (    5.11 ms per token,   195.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     610.75 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.39 ms /   152 tokens (    4.99 ms per token,   200.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.40 ms /   153 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 35/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1018.63 ms /   195 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.63 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.94 ms /   120 tokens (    5.30 ms per token,   188.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     642.69 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.88 ms /   147 tokens (    5.22 ms per token,   191.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.25 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1000.87 ms /   192 tokens (    5.21 ms per token,   191.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1008.82 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.48 ms /   103 tokens (    5.02 ms per token,   199.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     526.02 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1141.12 ms /   212 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1150.65 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.66 ms /   191 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.72 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.57 ms /   136 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.36 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.42 ms /   125 tokens (    5.59 ms per token,   178.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     704.55 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1136.82 ms /   221 tokens (    5.14 ms per token,   194.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1146.33 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     463.32 ms /    89 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     468.51 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1230.54 ms /   234 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.54 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     326.48 ms /    57 tokens (    5.73 ms per token,   174.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     330.60 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.83 ms /   112 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     615.45 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1056.42 ms /   204 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.71 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.37 ms /   214 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1132.99 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     284.63 ms /    56 tokens (    5.08 ms per token,   196.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.01 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1154.87 ms /   218 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.82 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.85 ms /   159 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     845.10 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1000.55 ms /   187 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1008.61 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1121.43 ms /   214 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.63 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.35 ms /   120 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     661.12 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.25 ms /   174 tokens (    4.92 ms per token,   203.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.26 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.20 ms /   158 tokens (    5.11 ms per token,   195.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     814.20 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.13 ms /   208 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.18 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     318.81 ms /    49 tokens (    6.51 ms per token,   153.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     324.42 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.11 ms /   161 tokens (    4.80 ms per token,   208.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.54 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1054.09 ms /   207 tokens (    5.09 ms per token,   196.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1064.43 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.03 ms /   133 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     709.21 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1139.73 ms /   219 tokens (    5.20 ms per token,   192.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1149.59 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1231.42 ms /   224 tokens (    5.50 ms per token,   181.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.05 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      61.96 ms /     4 tokens (   15.49 ms per token,    64.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      64.36 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1317.42 ms /   223 tokens (    5.91 ms per token,   169.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1327.54 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.62 ms /   148 tokens (    5.71 ms per token,   175.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.41 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.10 ms /   182 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.93 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.01 ms /   155 tokens (    4.97 ms per token,   201.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     778.82 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.97 ms /   132 tokens (    5.11 ms per token,   195.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     681.72 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1179.18 ms /   228 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1187.90 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.99 ms /    98 tokens (    5.85 ms per token,   171.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.18 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.32 ms /   195 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.35 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1076.10 ms /   179 tokens (    6.01 ms per token,   166.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1085.68 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.72 ms /   153 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.51 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.26 ms /   164 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     889.94 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.67 ms /   121 tokens (    4.95 ms per token,   202.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     605.34 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1190.51 ms /   222 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.01 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     530.03 ms /    97 tokens (    5.46 ms per token,   183.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     536.64 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     504.36 ms /   105 tokens (    4.80 ms per token,   208.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     510.02 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1199.68 ms /   179 tokens (    6.70 ms per token,   149.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1207.98 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.81 ms /   114 tokens (    6.55 ms per token,   152.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.92 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1083.58 ms /   203 tokens (    5.34 ms per token,   187.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.32 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     313.79 ms /    52 tokens (    6.03 ms per token,   165.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.14 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     549.83 ms /   101 tokens (    5.44 ms per token,   183.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.77 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.49 ms /   152 tokens (    5.77 ms per token,   173.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.03 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.85 ms /    96 tokens (    7.14 ms per token,   139.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.66 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.56 ms /   125 tokens (    6.85 ms per token,   145.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.70 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1072.41 ms /   204 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1081.12 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     395.35 ms /    69 tokens (    5.73 ms per token,   174.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     399.68 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.39 ms /   106 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     569.56 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.60 ms /   137 tokens (    5.83 ms per token,   171.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     804.71 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1075.00 ms /   190 tokens (    5.66 ms per token,   176.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1084.16 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1233.88 ms /   223 tokens (    5.53 ms per token,   180.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1245.48 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1179.87 ms /   217 tokens (    5.44 ms per token,   183.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1189.01 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     365.78 ms /    69 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     370.15 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     984.97 ms /   191 tokens (    5.16 ms per token,   193.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.55 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     252.95 ms /    45 tokens (    5.62 ms per token,   177.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     256.67 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     370.72 ms /    68 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     376.95 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      33.88 ms /     3 tokens (   11.29 ms per token,    88.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.68 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.16 ms /   201 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1070.74 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.95 ms /    58 tokens (    5.79 ms per token,   172.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     344.79 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.64 ms /   159 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     870.60 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.53 ms /   159 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     862.22 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.77 ms /   227 tokens (    5.22 ms per token,   191.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1196.39 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     646.56 ms /   102 tokens (    6.34 ms per token,   157.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     655.62 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      34.32 ms /     4 tokens (    8.58 ms per token,   116.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      36.88 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.58 ms /   220 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.36 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     280.03 ms /    59 tokens (    4.75 ms per token,   210.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     284.04 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     392.80 ms /    70 tokens (    5.61 ms per token,   178.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     398.23 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1077.55 ms /   201 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1085.10 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     711.57 ms /   138 tokens (    5.16 ms per token,   193.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.72 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1170.38 ms /   219 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1178.79 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     472.46 ms /    93 tokens (    5.08 ms per token,   196.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     478.88 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     622.33 ms /   112 tokens (    5.56 ms per token,   179.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     628.47 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.73 ms /   218 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1175.06 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     387.36 ms /    67 tokens (    5.78 ms per token,   172.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.74 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1153.75 ms /   206 tokens (    5.60 ms per token,   178.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1162.09 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1119.92 ms /   211 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.49 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1055.59 ms /   197 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1065.56 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.03 ms /   140 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     740.67 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1273.04 ms /   231 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1282.24 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.37 ms /   197 tokens (    5.11 ms per token,   195.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.54 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1234.19 ms /   212 tokens (    5.82 ms per token,   171.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.08 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     579.10 ms /   108 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.65 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.33 ms /   155 tokens (    5.61 ms per token,   178.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     876.18 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.26 ms /   144 tokens (    5.37 ms per token,   186.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.92 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.98 ms /   135 tokens (    5.18 ms per token,   193.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.17 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.98 ms /   192 tokens (    4.98 ms per token,   200.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     964.32 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.74 ms /   169 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.75 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.53 ms /   117 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     636.14 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1078.83 ms /   201 tokens (    5.37 ms per token,   186.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1087.02 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.20 ms /   117 tokens (    5.78 ms per token,   173.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.97 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.57 ms /   112 tokens (    5.01 ms per token,   199.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     567.80 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.73 ms /   194 tokens (    5.17 ms per token,   193.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1010.45 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     564.25 ms /   100 tokens (    5.64 ms per token,   177.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.05 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.77 ms /   193 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.06 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      40.83 ms /     4 tokens (   10.21 ms per token,    97.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.65 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.97 ms /   219 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.97 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     674.95 ms /   126 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     681.29 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     675.42 ms /   134 tokens (    5.04 ms per token,   198.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     682.53 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     819.70 ms /   149 tokens (    5.50 ms per token,   181.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     826.78 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.16 ms /   183 tokens (    5.84 ms per token,   171.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.99 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     728.38 ms /   128 tokens (    5.69 ms per token,   175.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     734.42 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.22 ms /   171 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.52 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1136.02 ms /   222 tokens (    5.12 ms per token,   195.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1144.93 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.62 ms /   107 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     576.61 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     290.61 ms /    50 tokens (    5.81 ms per token,   172.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     294.41 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1119.50 ms /   202 tokens (    5.54 ms per token,   180.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1127.35 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1164.24 ms /   207 tokens (    5.62 ms per token,   177.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1172.31 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.40 ms /    62 tokens (    5.65 ms per token,   176.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     355.46 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.54 ms /   173 tokens (    5.14 ms per token,   194.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     898.54 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.96 ms /   133 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.40 ms /   134 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 36/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.85 ms /   105 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     576.58 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.73 ms /   176 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.34 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.12 ms /   179 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     929.06 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.00 ms /   159 tokens (    5.06 ms per token,   197.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     815.11 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     359.17 ms /    65 tokens (    5.53 ms per token,   180.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.54 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.74 ms /   151 tokens (    5.00 ms per token,   199.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.62 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1266.64 ms /   180 tokens (    7.04 ms per token,   142.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.69 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.13 ms /   129 tokens (    6.50 ms per token,   153.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     844.85 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.44 ms /   139 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.89 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.39 ms /   175 tokens (    7.12 ms per token,   140.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.63 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.05 ms /   184 tokens (    5.81 ms per token,   172.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.53 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1199.37 ms /   196 tokens (    6.12 ms per token,   163.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.54 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.26 ms /   146 tokens (    5.36 ms per token,   186.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     790.31 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.37 ms /   126 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     679.66 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.02 ms /   183 tokens (    5.15 ms per token,   194.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     950.53 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     668.67 ms /   130 tokens (    5.14 ms per token,   194.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     675.13 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.58 ms /   132 tokens (    5.10 ms per token,   195.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     680.66 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1014.34 ms /   194 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.48 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     271.32 ms /    49 tokens (    5.54 ms per token,   180.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     276.09 ms /    50 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.24 ms /   157 tokens (    5.14 ms per token,   194.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     815.51 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.86 ms /   186 tokens (    5.04 ms per token,   198.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     945.71 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.26 ms /   196 tokens (    5.16 ms per token,   193.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1020.00 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.59 ms /   157 tokens (    5.64 ms per token,   177.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.83 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.11 ms /   198 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1036.53 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.48 ms /   116 tokens (    5.58 ms per token,   179.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     653.86 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.03 ms /   225 tokens (    5.07 ms per token,   197.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1149.19 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.60 ms /   158 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.24 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1099.29 ms /   214 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.60 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.62 ms /   163 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     862.63 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.74 ms /   194 tokens (    5.13 ms per token,   195.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.84 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.76 ms /   148 tokens (    5.12 ms per token,   195.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     767.08 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     987.07 ms /   196 tokens (    5.04 ms per token,   198.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     995.37 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     541.02 ms /   101 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     550.35 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     661.39 ms /   132 tokens (    5.01 ms per token,   199.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     667.94 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     553.24 ms /   109 tokens (    5.08 ms per token,   197.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     560.93 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.40 ms /   104 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     552.14 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.45 ms /   185 tokens (    5.18 ms per token,   193.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     966.72 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.40 ms /   105 tokens (    4.91 ms per token,   203.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.19 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     728.68 ms /   134 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     736.41 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.46 ms /   211 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1122.27 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.92 ms /   155 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     835.77 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.98 ms /   124 tokens (    4.71 ms per token,   212.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.27 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.90 ms /   196 tokens (    5.14 ms per token,   194.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.35 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1378.85 ms /   222 tokens (    6.21 ms per token,   161.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1389.66 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     296.00 ms /    53 tokens (    5.58 ms per token,   179.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.76 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.61 ms /   134 tokens (    5.58 ms per token,   179.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     754.52 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.42 ms /   204 tokens (    6.18 ms per token,   161.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1271.09 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1233.80 ms /   209 tokens (    5.90 ms per token,   169.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1243.69 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.83 ms /   143 tokens (    6.24 ms per token,   160.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     901.46 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1593.52 ms /   280 tokens (    5.69 ms per token,   175.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1604.56 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.59 ms /   227 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1213.79 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1247.45 ms /   231 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.27 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.25 ms /   183 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.19 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.06 ms /   105 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     565.56 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1356.58 ms /   252 tokens (    5.38 ms per token,   185.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1366.02 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.33 ms /   155 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     822.40 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1382.25 ms /   260 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1391.53 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     375.46 ms /    72 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.97 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.55 ms /   195 tokens (    5.10 ms per token,   196.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.00 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1176.91 ms /   223 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1185.22 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1279.18 ms /   240 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.38 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.02 ms /   123 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     644.13 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     980.28 ms /   185 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     989.59 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.53 ms /   125 tokens (    5.12 ms per token,   195.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     646.93 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.03 ms /   145 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.88 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.49 ms /   147 tokens (    5.25 ms per token,   190.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.00 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     589.34 ms /   123 tokens (    4.79 ms per token,   208.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.60 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1231.70 ms /   226 tokens (    5.45 ms per token,   183.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.60 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.01 ms /   139 tokens (    4.99 ms per token,   200.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     700.94 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.61 ms /   127 tokens (    5.33 ms per token,   187.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     683.22 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     513.67 ms /   105 tokens (    4.89 ms per token,   204.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     519.84 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.68 ms /   187 tokens (    5.05 ms per token,   198.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.64 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.20 ms /   182 tokens (    5.16 ms per token,   193.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     947.30 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.19 ms /   206 tokens (    5.09 ms per token,   196.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.36 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     352.15 ms /    54 tokens (    6.52 ms per token,   153.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     357.26 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.26 ms /   150 tokens (    6.44 ms per token,   155.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     972.55 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.51 ms /    92 tokens (    6.95 ms per token,   143.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     646.03 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1487.84 ms /   147 tokens (   10.12 ms per token,    98.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1496.16 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.88 ms /   159 tokens (    5.91 ms per token,   169.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.20 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1101.24 ms /   182 tokens (    6.05 ms per token,   165.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1111.57 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1235.18 ms /   189 tokens (    6.54 ms per token,   153.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.97 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.71 ms /   187 tokens (    5.38 ms per token,   185.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.32 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.53 ms /   139 tokens (    5.47 ms per token,   182.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.20 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.02 ms /   174 tokens (    5.05 ms per token,   197.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.60 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     594.02 ms /   124 tokens (    4.79 ms per token,   208.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     600.35 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.39 ms /   102 tokens (    5.59 ms per token,   178.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     575.92 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1055.42 ms /   205 tokens (    5.15 ms per token,   194.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1063.33 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.93 ms /   192 tokens (    5.21 ms per token,   192.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.29 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.79 ms /   160 tokens (    5.00 ms per token,   199.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.54 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.82 ms /   147 tokens (    4.91 ms per token,   203.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     729.58 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.29 ms /   195 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.91 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.12 ms /   107 tokens (    5.69 ms per token,   175.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     617.03 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     568.51 ms /   113 tokens (    5.03 ms per token,   198.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     575.44 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.09 ms /   195 tokens (    5.09 ms per token,   196.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.47 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1123.01 ms /   217 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1132.71 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.83 ms /   169 tokens (    5.18 ms per token,   192.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.42 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.52 ms /   165 tokens (    5.05 ms per token,   198.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.97 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.11 ms /   135 tokens (    5.33 ms per token,   187.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     726.58 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     799.99 ms /   155 tokens (    5.16 ms per token,   193.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     806.81 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.89 ms /   185 tokens (    5.02 ms per token,   199.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     936.54 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.47 ms /   144 tokens (    4.98 ms per token,   200.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     724.27 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.53 ms /   115 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     611.95 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.62 ms /   132 tokens (    5.19 ms per token,   192.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     692.01 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1322.10 ms /   250 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.11 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.38 ms /   173 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.72 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1115.94 ms /   207 tokens (    5.39 ms per token,   185.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.31 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.59 ms /   185 tokens (    5.50 ms per token,   181.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1024.45 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     524.33 ms /   103 tokens (    5.09 ms per token,   196.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     532.47 ms /   104 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 37/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.12 ms /   150 tokens (    5.15 ms per token,   194.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.12 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.15 ms /   137 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     739.43 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     558.91 ms /   103 tokens (    5.43 ms per token,   184.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     564.44 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.67 ms /   145 tokens (    6.05 ms per token,   165.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.02 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.25 ms /   169 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.32 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1381.11 ms /   256 tokens (    5.39 ms per token,   185.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1397.08 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1094.96 ms /   212 tokens (    5.16 ms per token,   193.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1103.45 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     423.75 ms /    83 tokens (    5.11 ms per token,   195.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     428.85 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      37.72 ms /     3 tokens (   12.57 ms per token,    79.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.47 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1397.85 ms /   260 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1408.26 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.47 ms /   170 tokens (    5.03 ms per token,   198.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     863.14 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     297.42 ms /    53 tokens (    5.61 ms per token,   178.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     303.99 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.22 ms /   210 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1157.61 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.31 ms /    90 tokens (    4.96 ms per token,   201.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.11 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.58 ms /   174 tokens (    5.17 ms per token,   193.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     908.19 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.82 ms /   181 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     947.98 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.94 ms /   176 tokens (    5.32 ms per token,   188.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     943.85 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.51 ms /   157 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     820.40 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     558.82 ms /   115 tokens (    4.86 ms per token,   205.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     564.72 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.78 ms /   177 tokens (    5.02 ms per token,   199.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     897.49 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     334.75 ms /    60 tokens (    5.58 ms per token,   179.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.25 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.38 ms /   188 tokens (    5.07 ms per token,   197.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.65 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     423.51 ms /    87 tokens (    4.87 ms per token,   205.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     429.05 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.07 ms /   146 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     770.68 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.10 ms /   141 tokens (    4.89 ms per token,   204.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     696.94 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.26 ms /   134 tokens (    5.14 ms per token,   194.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.80 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.95 ms /   183 tokens (    5.41 ms per token,   184.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     999.27 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.94 ms /   117 tokens (    5.65 ms per token,   177.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     666.85 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.99 ms /   154 tokens (    4.92 ms per token,   203.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.15 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.15 ms /   127 tokens (    5.06 ms per token,   197.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     648.40 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.53 ms /   180 tokens (    5.19 ms per token,   192.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.50 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.23 ms /   149 tokens (    5.16 ms per token,   193.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     775.41 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1101.50 ms /   211 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.38 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     385.28 ms /    75 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     391.92 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.98 ms /   134 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     707.77 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.10 ms /   162 tokens (    5.15 ms per token,   194.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     841.46 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.07 ms /   187 tokens (    5.11 ms per token,   195.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.37 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     548.82 ms /   113 tokens (    4.86 ms per token,   205.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     554.58 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.25 ms /   148 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.80 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.72 ms /   139 tokens (    5.16 ms per token,   193.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     723.56 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.09 ms /   171 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     901.03 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.27 ms /   159 tokens (    6.62 ms per token,   151.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.51 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     966.56 ms /   134 tokens (    7.21 ms per token,   138.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.85 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.66 ms /   165 tokens (    6.13 ms per token,   163.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.87 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     468.54 ms /    90 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     475.09 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.40 ms /   128 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     686.13 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.29 ms /   151 tokens (    4.99 ms per token,   200.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.75 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     662.54 ms /   129 tokens (    5.14 ms per token,   194.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     668.83 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1249.17 ms /   234 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1258.71 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.91 ms /   162 tokens (    4.99 ms per token,   200.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     815.61 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.39 ms /   145 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.34 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     679.88 ms /   129 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     685.96 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.89 ms /   151 tokens (    5.00 ms per token,   200.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.24 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.01 ms /   175 tokens (    5.01 ms per token,   199.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.84 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.00 ms /   195 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.23 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1277.50 ms /   231 tokens (    5.53 ms per token,   180.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.02 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     394.42 ms /    76 tokens (    5.19 ms per token,   192.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     399.11 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.39 ms /   143 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.94 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.59 ms /   135 tokens (    4.83 ms per token,   207.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     658.51 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.76 ms /   181 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     936.48 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     493.39 ms /    91 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     499.60 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     507.73 ms /   105 tokens (    4.84 ms per token,   206.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     513.90 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.01 ms /   136 tokens (    5.15 ms per token,   194.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     708.40 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     442.04 ms /    92 tokens (    4.80 ms per token,   208.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     447.30 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     607.01 ms /   116 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     613.03 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     730.06 ms /   140 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     736.94 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     627.22 ms /   128 tokens (    4.90 ms per token,   204.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.44 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.71 ms /   113 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     603.23 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.43 ms /   183 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.03 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.46 ms /   130 tokens (    5.08 ms per token,   196.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     666.66 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.74 ms /   132 tokens (    5.03 ms per token,   198.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.72 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.62 ms /   177 tokens (    5.14 ms per token,   194.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     918.20 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.61 ms /   190 tokens (    5.20 ms per token,   192.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     996.41 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     238.04 ms /    47 tokens (    5.06 ms per token,   197.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     245.28 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      71.20 ms /     9 tokens (    7.91 ms per token,   126.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      76.66 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.80 ms /   181 tokens (    5.11 ms per token,   195.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.86 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     506.00 ms /    95 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     512.39 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     648.31 ms /   125 tokens (    5.19 ms per token,   192.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     654.86 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.60 ms /   185 tokens (    5.04 ms per token,   198.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.30 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     536.88 ms /    99 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     542.44 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.41 ms /   199 tokens (    5.14 ms per token,   194.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1031.03 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.96 ms /   156 tokens (    5.37 ms per token,   186.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.02 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     246.81 ms /    50 tokens (    4.94 ms per token,   202.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.71 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.08 ms /    71 tokens (    4.93 ms per token,   202.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     355.03 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.81 ms /   171 tokens (    5.08 ms per token,   196.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     876.84 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     375.79 ms /    71 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.95 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.96 ms /   141 tokens (    4.93 ms per token,   202.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.15 ms /   142 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 38/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1056.18 ms /   203 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.54 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     513.63 ms /    96 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     518.88 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.07 ms /   190 tokens (    5.12 ms per token,   195.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.51 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.17 ms /    65 tokens (    4.80 ms per token,   208.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     316.83 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1159.17 ms /   218 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1168.21 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.17 ms /   173 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.41 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.39 ms /   137 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.78 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1372.69 ms /   256 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1382.00 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.73 ms /   151 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     803.89 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.39 ms /   150 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.05 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.41 ms /   213 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.50 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     468.46 ms /    96 tokens (    4.88 ms per token,   204.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     473.90 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1371.39 ms /   255 tokens (    5.38 ms per token,   185.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1381.25 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     282.94 ms /    58 tokens (    4.88 ms per token,   204.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     287.27 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1264.01 ms /   235 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1273.78 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.53 ms /   175 tokens (    5.16 ms per token,   193.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     910.08 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      57.77 ms /     5 tokens (   11.55 ms per token,    86.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      60.10 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1059.79 ms /   199 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.70 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.28 ms /    56 tokens (    6.24 ms per token,   160.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.64 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.99 ms /   164 tokens (    4.95 ms per token,   202.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     819.06 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.98 ms /   198 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1031.75 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     452.86 ms /    82 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     458.28 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     944.25 ms /   180 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.08 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.03 ms /   138 tokens (    5.10 ms per token,   196.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     710.25 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1213.07 ms /   227 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.67 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.71 ms /   158 tokens (    5.04 ms per token,   198.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.94 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.19 ms /   178 tokens (    4.97 ms per token,   201.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.57 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1290.82 ms /   240 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.47 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.83 ms /   178 tokens (    4.97 ms per token,   201.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.82 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1332.56 ms /   244 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.85 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1129.62 ms /   210 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1138.55 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1401.78 ms /   191 tokens (    7.34 ms per token,   136.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1411.85 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1869.01 ms /   281 tokens (    6.65 ms per token,   150.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1878.98 ms /   282 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1734.96 ms /   299 tokens (    5.80 ms per token,   172.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1745.53 ms /   300 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1409.45 ms /   261 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1418.74 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     370.35 ms /    77 tokens (    4.81 ms per token,   207.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     375.05 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     330.22 ms /    60 tokens (    5.50 ms per token,   181.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     336.46 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1517.81 ms /   285 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1528.98 ms /   286 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.78 ms /   292 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1614.31 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.39 ms /   164 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     860.76 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1444.30 ms /   269 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1453.68 ms /   270 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1213.68 ms /   232 tokens (    5.23 ms per token,   191.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.04 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     374.08 ms /    59 tokens (    6.34 ms per token,   157.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.12 ms /    60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 39/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1307.29 ms /   250 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1316.78 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1279.91 ms /   229 tokens (    5.59 ms per token,   178.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1288.25 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.21 ms /   148 tokens (    5.14 ms per token,   194.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.61 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1190.83 ms /   226 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1203.11 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1120.85 ms /   215 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1132.63 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1064.96 ms /   197 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1073.05 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.47 ms /   233 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.05 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.53 ms /   202 tokens (    5.35 ms per token,   186.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1088.58 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.29 ms /   168 tokens (    5.14 ms per token,   194.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     873.94 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.87 ms /   116 tokens (    4.97 ms per token,   201.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.09 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     599.68 ms /   115 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     607.12 ms /   116 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 41/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.73 ms /   195 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1031.83 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.28 ms /   113 tokens (    5.01 ms per token,   199.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.93 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1290.69 ms /   219 tokens (    5.89 ms per token,   169.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1299.23 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     478.35 ms /    85 tokens (    5.63 ms per token,   177.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     484.98 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.60 ms /   131 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     696.10 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1047.49 ms /   201 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1055.80 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     616.97 ms /   116 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     623.28 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.03 ms /   151 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.17 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.11 ms /   175 tokens (    5.11 ms per token,   195.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.88 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.89 ms /   196 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.95 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1561.79 ms /   286 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1573.75 ms /   287 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     400.22 ms /    77 tokens (    5.20 ms per token,   192.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     405.35 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1141.82 ms /   218 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1151.17 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     450.69 ms /    80 tokens (    5.63 ms per token,   177.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     455.50 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.61 ms /   162 tokens (    5.16 ms per token,   193.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.46 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.38 ms /   142 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.97 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.22 ms /   130 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     686.56 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.31 ms /   185 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.79 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     452.22 ms /    93 tokens (    4.86 ms per token,   205.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     458.14 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.31 ms /   145 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     764.15 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1211.03 ms /   225 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1219.63 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     234.53 ms /    46 tokens (    5.10 ms per token,   196.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     239.15 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     414.16 ms /    74 tokens (    5.60 ms per token,   178.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     418.92 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.84 ms /   195 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.94 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     382.00 ms /    78 tokens (    4.90 ms per token,   204.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     388.94 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1064.35 ms /   205 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.75 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     340.03 ms /    50 tokens (    6.80 ms per token,   147.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     344.76 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.89 ms /   169 tokens (    5.48 ms per token,   182.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.27 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1089.97 ms /   211 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1098.83 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.62 ms /   147 tokens (    5.41 ms per token,   184.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     801.40 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.87 ms /    91 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     488.46 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.35 ms /   176 tokens (    5.05 ms per token,   197.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     897.50 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.86 ms /   195 tokens (    5.11 ms per token,   195.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.80 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.42 ms /   183 tokens (    5.03 ms per token,   198.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     929.17 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     799.50 ms /   155 tokens (    5.16 ms per token,   193.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     806.24 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.99 ms /   177 tokens (    5.06 ms per token,   197.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     904.12 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.66 ms /   167 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.06 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     653.07 ms /   125 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     659.01 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     586.53 ms /   118 tokens (    4.97 ms per token,   201.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.53 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.69 ms /   150 tokens (    5.30 ms per token,   188.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     801.81 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.35 ms /   102 tokens (    5.52 ms per token,   181.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     570.26 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.40 ms /   195 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.49 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     483.48 ms /    89 tokens (    5.43 ms per token,   184.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     490.57 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1281.54 ms /   196 tokens (    6.54 ms per token,   152.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1290.58 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.28 ms /   107 tokens (    6.02 ms per token,   166.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.08 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1190.26 ms /   219 tokens (    5.43 ms per token,   183.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.20 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.34 ms /   150 tokens (    5.80 ms per token,   172.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     876.71 ms /   151 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 42/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.84 ms /   136 tokens (    6.90 ms per token,   144.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     946.54 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.71 ms /   175 tokens (    6.09 ms per token,   164.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1074.77 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     470.03 ms /    83 tokens (    5.66 ms per token,   176.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     476.49 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.02 ms /   184 tokens (    5.15 ms per token,   194.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     956.45 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.83 ms /   194 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1013.35 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.95 ms /   174 tokens (    5.14 ms per token,   194.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     903.33 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.50 ms /   129 tokens (    5.37 ms per token,   186.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     700.04 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.52 ms /   139 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.91 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.80 ms /   166 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     872.88 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     652.14 ms /   125 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     658.60 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.77 ms /   179 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     960.79 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.74 ms /   169 tokens (    5.48 ms per token,   182.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.72 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.16 ms /   165 tokens (    5.18 ms per token,   192.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     863.10 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.41 ms /   159 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.61 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.85 ms /   163 tokens (    5.13 ms per token,   195.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.14 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.29 ms /   167 tokens (    5.11 ms per token,   195.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.71 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.97 ms /   149 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     820.61 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.27 ms /   141 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     745.90 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     420.70 ms /    82 tokens (    5.13 ms per token,   194.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     426.42 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.78 ms /   159 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.32 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.88 ms /   167 tokens (    5.13 ms per token,   194.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     864.00 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.97 ms /   142 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.98 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     634.14 ms /   125 tokens (    5.07 ms per token,   197.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     640.33 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.89 ms /   142 tokens (    5.06 ms per token,   197.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     725.04 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.85 ms /   159 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     830.73 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.04 ms /   186 tokens (    5.15 ms per token,   194.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     965.31 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.01 ms /   168 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.27 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     339.61 ms /    70 tokens (    4.85 ms per token,   206.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     344.53 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.81 ms /   138 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     724.78 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.28 ms /   128 tokens (    5.03 ms per token,   198.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.13 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.41 ms /   167 tokens (    5.05 ms per token,   198.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     851.95 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.06 ms /   151 tokens (    5.13 ms per token,   195.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.23 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.84 ms /   141 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.32 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.14 ms /   176 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.83 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.32 ms /   190 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.06 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.02 ms /   154 tokens (    5.38 ms per token,   185.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     834.93 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1208.56 ms /   229 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.04 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.54 ms /    62 tokens (    5.41 ms per token,   184.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     340.87 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.42 ms /   183 tokens (    5.13 ms per token,   194.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.32 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.99 ms /   143 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     758.67 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.08 ms /   175 tokens (    5.15 ms per token,   194.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.65 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.60 ms /   170 tokens (    5.12 ms per token,   195.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     879.12 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.14 ms /   190 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.21 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1232.93 ms /   228 tokens (    5.41 ms per token,   184.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.51 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.45 ms /   100 tokens (    4.95 ms per token,   201.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     501.92 ms /   101 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 43/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.62 ms /   141 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.43 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.49 ms /   188 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.00 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1175.13 ms /   219 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.71 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.19 ms /   145 tokens (    5.45 ms per token,   183.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     800.13 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1431.52 ms /   266 tokens (    5.38 ms per token,   185.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1440.77 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1677.71 ms /   302 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1687.69 ms /   303 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1094.94 ms /   207 tokens (    5.29 ms per token,   189.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1103.07 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1800.57 ms /   258 tokens (    6.98 ms per token,   143.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1811.86 ms /   259 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2008.75 ms /   289 tokens (    6.95 ms per token,   143.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2021.34 ms /   290 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1525.45 ms /   223 tokens (    6.84 ms per token,   146.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1535.81 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1551.69 ms /   225 tokens (    6.90 ms per token,   145.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1561.07 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1591.12 ms /   234 tokens (    6.80 ms per token,   147.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1601.46 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1091.48 ms /   157 tokens (    6.95 ms per token,   143.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1100.60 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1701.60 ms /   238 tokens (    7.15 ms per token,   139.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1711.16 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     292.30 ms /    40 tokens (    7.31 ms per token,   136.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     297.68 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1616.18 ms /   206 tokens (    7.85 ms per token,   127.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1626.82 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1330.58 ms /   195 tokens (    6.82 ms per token,   146.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.68 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     562.73 ms /    83 tokens (    6.78 ms per token,   147.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     568.08 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1419.79 ms /   214 tokens (    6.63 ms per token,   150.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1430.47 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1251.30 ms /   182 tokens (    6.88 ms per token,   145.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.25 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.89 ms /    77 tokens (    7.96 ms per token,   125.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     618.40 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1431.04 ms /   216 tokens (    6.63 ms per token,   150.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1441.72 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.70 ms /   146 tokens (    6.35 ms per token,   157.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.39 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.49 ms /   185 tokens (    5.78 ms per token,   172.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.22 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.13 ms /   148 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     801.71 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.66 ms /   160 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     835.86 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.82 ms /   120 tokens (    5.13 ms per token,   194.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.14 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1247.64 ms /   230 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.34 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     391.00 ms /    78 tokens (    5.01 ms per token,   199.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     396.08 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.99 ms /   189 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.96 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     303.55 ms /    58 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.67 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1217.43 ms /   230 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1228.04 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     324.49 ms /    55 tokens (    5.90 ms per token,   169.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     329.15 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.95 ms /   334 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1847.50 ms /   335 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.47 ms /   164 tokens (    5.09 ms per token,   196.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.30 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     414.05 ms /    79 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     419.50 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1047.37 ms /   201 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1056.70 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.74 ms /   163 tokens (    5.46 ms per token,   182.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     898.31 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.09 ms /   170 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.47 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1340.69 ms /   248 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1349.62 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1060.57 ms /   199 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1069.35 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1175.19 ms /   178 tokens (    6.60 ms per token,   151.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.32 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.38 ms /   141 tokens (    5.59 ms per token,   178.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.39 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1407.86 ms /   229 tokens (    6.15 ms per token,   162.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1417.89 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.75 ms /   140 tokens (    6.03 ms per token,   165.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.50 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.31 ms /   211 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.56 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1725.85 ms /   310 tokens (    5.57 ms per token,   179.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1736.44 ms /   311 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1291.77 ms /   244 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1301.04 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      87.02 ms /    16 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      90.95 ms /    17 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.74 ms /   198 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.83 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1299.95 ms /   235 tokens (    5.53 ms per token,   180.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1308.74 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1164.41 ms /   222 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1173.75 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1188.44 ms /   204 tokens (    5.83 ms per token,   171.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.67 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     489.92 ms /    75 tokens (    6.53 ms per token,   153.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     496.07 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.98 ms /   159 tokens (    5.95 ms per token,   168.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.15 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1209.75 ms /   197 tokens (    6.14 ms per token,   162.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1219.02 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.09 ms /   169 tokens (    5.88 ms per token,   170.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1002.93 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1319.15 ms /   218 tokens (    6.05 ms per token,   165.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1328.84 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     386.38 ms /    59 tokens (    6.55 ms per token,   152.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     392.27 ms /    60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 44/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.72 ms /    98 tokens (    5.96 ms per token,   167.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.16 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1034.90 ms /   175 tokens (    5.91 ms per token,   169.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1044.84 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1496.45 ms /   237 tokens (    6.31 ms per token,   158.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1508.38 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.34 ms /   143 tokens (    5.98 ms per token,   167.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     863.17 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.94 ms /   120 tokens (    6.02 ms per token,   165.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     730.73 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1156.97 ms /   175 tokens (    6.61 ms per token,   151.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.74 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.47 ms /   194 tokens (    6.22 ms per token,   160.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1217.22 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.11 ms /   140 tokens (    6.29 ms per token,   159.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.56 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.33 ms /   115 tokens (    5.99 ms per token,   167.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.79 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1285.55 ms /   206 tokens (    6.24 ms per token,   160.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.19 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.34 ms /   153 tokens (    5.92 ms per token,   169.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     912.61 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.29 ms /   154 tokens (    5.92 ms per token,   168.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.30 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.04 ms /   164 tokens (    5.68 ms per token,   176.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.67 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1223.49 ms /   202 tokens (    6.06 ms per token,   165.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.06 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1269.96 ms /   197 tokens (    6.45 ms per token,   155.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.00 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1289.66 ms /   192 tokens (    6.72 ms per token,   148.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1298.77 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1231.38 ms /   188 tokens (    6.55 ms per token,   152.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.63 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.22 ms /   180 tokens (    5.91 ms per token,   169.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.81 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     548.41 ms /    86 tokens (    6.38 ms per token,   156.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.10 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.92 ms /   180 tokens (    5.79 ms per token,   172.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1052.52 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1198.28 ms /   195 tokens (    6.15 ms per token,   162.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.45 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1165.69 ms /   191 tokens (    6.10 ms per token,   163.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1175.68 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     628.61 ms /    85 tokens (    7.40 ms per token,   135.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.68 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.31 ms /   122 tokens (    7.17 ms per token,   139.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.99 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1085.22 ms /   166 tokens (    6.54 ms per token,   152.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1093.72 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.17 ms /   122 tokens (    6.35 ms per token,   157.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.97 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.44 ms /   122 tokens (    6.00 ms per token,   166.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     739.23 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.13 ms /   164 tokens (    5.81 ms per token,   172.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     959.50 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.35 ms /   110 tokens (    6.12 ms per token,   163.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     680.95 ms /   111 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 45/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.32 ms /   135 tokens (    6.13 ms per token,   163.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     836.17 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.16 ms /   188 tokens (    6.19 ms per token,   161.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1172.61 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.67 ms /   141 tokens (    6.04 ms per token,   165.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     860.67 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1230.95 ms /   203 tokens (    6.06 ms per token,   164.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.26 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     298.95 ms /    48 tokens (    6.23 ms per token,   160.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.28 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.23 ms /   158 tokens (    5.98 ms per token,   167.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.85 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.01 ms /   173 tokens (    5.96 ms per token,   167.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1040.25 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.71 ms /   145 tokens (    6.26 ms per token,   159.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.87 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.22 ms /   171 tokens (    5.86 ms per token,   170.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1010.04 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     959.32 ms /   165 tokens (    5.81 ms per token,   172.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     969.11 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.43 ms /   136 tokens (    5.90 ms per token,   169.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.14 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.35 ms /   127 tokens (    6.08 ms per token,   164.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.91 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     671.67 ms /   112 tokens (    6.00 ms per token,   166.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     678.64 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     668.90 ms /   131 tokens (    5.11 ms per token,   195.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     675.54 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.88 ms /   162 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     847.16 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.98 ms /   124 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     666.45 ms /   125 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 47/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1091.98 ms /   203 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1101.71 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.32 ms /   160 tokens (    5.42 ms per token,   184.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     875.00 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1037.64 ms /   202 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.53 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.66 ms /   167 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.09 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.18 ms /   164 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.37 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.89 ms /   209 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.15 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     671.78 ms /   126 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     679.40 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.51 ms /   142 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     745.83 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.82 ms /   197 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1052.15 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     186.10 ms /    32 tokens (    5.82 ms per token,   171.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     193.34 ms /    33 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 48/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1059.37 ms /   199 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.09 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1131.32 ms /   210 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1145.37 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1085.89 ms /   203 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1094.72 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     374.91 ms /    63 tokens (    5.95 ms per token,   168.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.03 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.59 ms /   209 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.20 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     440.75 ms /    76 tokens (    5.80 ms per token,   172.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     445.42 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.89 ms /   176 tokens (    5.08 ms per token,   196.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.52 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1402.02 ms /   257 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1412.09 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.79 ms /   213 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1139.92 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.12 ms /   187 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1010.12 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     683.14 ms /   133 tokens (    5.14 ms per token,   194.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     691.28 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.93 ms /   216 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.46 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.05 ms /   180 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     993.28 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1205.17 ms /   223 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1213.96 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.05 ms /   124 tokens (    5.04 ms per token,   198.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     633.30 ms /   125 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 49/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.68 ms /   188 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.33 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.76 ms /   139 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     734.13 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     539.28 ms /   103 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.56 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      47.60 ms /     4 tokens (   11.90 ms per token,    84.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      51.48 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.71 ms /   179 tokens (    5.11 ms per token,   195.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     923.69 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     984.58 ms /   188 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     992.74 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     497.55 ms /    96 tokens (    5.18 ms per token,   192.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     503.03 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.81 ms /   176 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.78 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.61 ms /   128 tokens (    5.14 ms per token,   194.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     666.05 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     464.53 ms /    85 tokens (    5.47 ms per token,   182.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     472.01 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.46 ms /   160 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.83 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.73 ms /   174 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.16 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.19 ms /   156 tokens (    5.14 ms per token,   194.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     810.96 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1060.97 ms /   187 tokens (    5.67 ms per token,   176.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.48 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.51 ms /   114 tokens (    6.35 ms per token,   157.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     729.91 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.26 ms /   176 tokens (    6.10 ms per token,   163.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1084.66 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.38 ms /   182 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     978.11 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.30 ms /   202 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1082.44 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.30 ms /   112 tokens (    5.48 ms per token,   182.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     619.24 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.56 ms /   110 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     583.43 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     504.69 ms /    95 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     510.30 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.30 ms /   170 tokens (    5.37 ms per token,   186.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.53 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     323.20 ms /    65 tokens (    4.97 ms per token,   201.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     329.05 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.17 ms /   150 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     787.44 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.48 ms /   180 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.72 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.16 ms /   157 tokens (    6.22 ms per token,   160.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.05 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.70 ms /   132 tokens (    6.85 ms per token,   145.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     910.99 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.37 ms /   153 tokens (    6.07 ms per token,   164.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     937.29 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     667.72 ms /   130 tokens (    5.14 ms per token,   194.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     674.27 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.15 ms /   110 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     576.06 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.68 ms /   146 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     773.45 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.51 ms /   184 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     992.82 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     357.65 ms /    62 tokens (    5.77 ms per token,   173.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.62 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.00 ms /   134 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.29 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     442.78 ms /    86 tokens (    5.15 ms per token,   194.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     448.18 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.38 ms /   140 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.42 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      35.76 ms /     3 tokens (   11.92 ms per token,    83.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.39 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1101.27 ms /   205 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1109.70 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     378.04 ms /    66 tokens (    5.73 ms per token,   174.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     383.38 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.34 ms /    83 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     440.65 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.09 ms /   172 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.56 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     186.10 ms /    35 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     189.60 ms /    36 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.77 ms /    66 tokens (    5.09 ms per token,   196.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     340.69 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     183.85 ms /    37 tokens (    4.97 ms per token,   201.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     188.31 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.51 ms /   153 tokens (    5.11 ms per token,   195.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     790.98 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.20 ms /   116 tokens (    5.03 ms per token,   198.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.11 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.44 ms /   164 tokens (    5.11 ms per token,   195.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.90 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.99 ms /   158 tokens (    5.01 ms per token,   199.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.25 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.62 ms /   127 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     696.41 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.77 ms /    79 tokens (    5.02 ms per token,   199.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     402.27 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.96 ms /   157 tokens (    5.08 ms per token,   196.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     806.39 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.10 ms /   142 tokens (    5.16 ms per token,   193.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     738.72 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     477.08 ms /    93 tokens (    5.13 ms per token,   194.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     483.24 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.72 ms /   166 tokens (    5.05 ms per token,   197.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     847.76 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.39 ms /   162 tokens (    5.37 ms per token,   186.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     876.95 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      34.53 ms /     3 tokens (   11.51 ms per token,    86.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.45 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.60 ms /   185 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.88 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     506.52 ms /    98 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     512.22 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     429.93 ms /    77 tokens (    5.58 ms per token,   179.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     435.16 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.06 ms /   155 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     816.84 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.21 ms /   119 tokens (    5.03 ms per token,   198.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     604.73 ms /   120 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.12 ms /   115 tokens (    5.25 ms per token,   190.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     612.29 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.19 ms /   188 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.84 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.50 ms /   148 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     793.38 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1228.53 ms /   230 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1237.43 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.68 ms /   161 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     858.50 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.71 ms /   157 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.79 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.15 ms /   180 tokens (    5.12 ms per token,   195.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     931.01 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.01 ms /   229 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.35 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     293.66 ms /    53 tokens (    5.54 ms per token,   180.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     299.96 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.68 ms /   229 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1206.19 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.26 ms /   124 tokens (    5.62 ms per token,   178.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.31 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1094.82 ms /   208 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.12 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1114.25 ms /   208 tokens (    5.36 ms per token,   186.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1122.65 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.30 ms /   166 tokens (    5.48 ms per token,   182.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.58 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     445.35 ms /    89 tokens (    5.00 ms per token,   199.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     451.11 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1389.89 ms /   255 tokens (    5.45 ms per token,   183.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1400.11 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.33 ms /   186 tokens (    5.44 ms per token,   183.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.11 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1227.37 ms /   225 tokens (    5.45 ms per token,   183.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1236.96 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1420.24 ms /   261 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1431.05 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1018.59 ms /   198 tokens (    5.14 ms per token,   194.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.30 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1053.06 ms /   198 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1063.36 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.63 ms /   174 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.56 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.81 ms /   184 tokens (    5.13 ms per token,   194.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     953.91 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.67 ms /   149 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     784.50 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1068.36 ms /   203 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.25 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1429.66 ms /   253 tokens (    5.65 ms per token,   176.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1439.08 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.15 ms /   136 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     716.04 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.15 ms /   167 tokens (    5.86 ms per token,   170.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.68 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.95 ms /   168 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     898.69 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1084.84 ms /   172 tokens (    6.31 ms per token,   158.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.28 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     652.39 ms /    99 tokens (    6.59 ms per token,   151.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     658.93 ms /   100 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 51/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.90 ms /   159 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     855.90 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     781.03 ms /   151 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     787.96 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     693.99 ms /   133 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.00 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1209.11 ms /   222 tokens (    5.45 ms per token,   183.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1217.69 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.11 ms /   156 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.67 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1353.32 ms /   245 tokens (    5.52 ms per token,   181.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1363.10 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.29 ms /   144 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.59 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.08 ms /   148 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     805.95 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.04 ms /   126 tokens (    5.92 ms per token,   168.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.56 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1616.90 ms /   244 tokens (    6.63 ms per token,   150.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1626.43 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.02 ms /   122 tokens (    7.07 ms per token,   141.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     870.36 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1496.04 ms /   220 tokens (    6.80 ms per token,   147.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1505.06 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.28 ms /   163 tokens (    6.12 ms per token,   163.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.54 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     403.19 ms /    63 tokens (    6.40 ms per token,   156.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.07 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.81 ms /   190 tokens (    5.82 ms per token,   171.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1115.03 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1166.94 ms /   218 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1178.12 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     343.00 ms /    55 tokens (    6.24 ms per token,   160.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     347.77 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1305.99 ms /   243 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1314.97 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1242.09 ms /   235 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1250.81 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.51 ms /   180 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     989.48 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1132.66 ms /   217 tokens (    5.22 ms per token,   191.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.74 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1424.04 ms /   250 tokens (    5.70 ms per token,   175.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1434.80 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.73 ms /   192 tokens (    5.14 ms per token,   194.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     996.60 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     962.32 ms /   185 tokens (    5.20 ms per token,   192.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.15 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.72 ms /   154 tokens (    5.02 ms per token,   199.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.61 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.80 ms /   191 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.31 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.55 ms /   171 tokens (    5.23 ms per token,   191.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     901.78 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1121.13 ms /   207 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1128.97 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.27 ms /   104 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     565.84 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.49 ms /   162 tokens (    5.13 ms per token,   194.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     838.50 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.63 ms /   104 tokens (    4.96 ms per token,   201.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     522.30 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.54 ms /   204 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.22 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     711.03 ms /   127 tokens (    5.60 ms per token,   178.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.65 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.80 ms /   135 tokens (    5.15 ms per token,   194.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.63 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.66 ms /   180 tokens (    5.11 ms per token,   195.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     929.15 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.48 ms /    89 tokens (    5.02 ms per token,   199.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.20 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1254.20 ms /   230 tokens (    5.45 ms per token,   183.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.95 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     611.15 ms /   113 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     618.09 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.42 ms /   177 tokens (    5.53 ms per token,   180.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.88 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.00 ms /   158 tokens (    5.20 ms per token,   192.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     828.36 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.18 ms /   208 tokens (    5.23 ms per token,   191.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1098.42 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     272.24 ms /    54 tokens (    5.04 ms per token,   198.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.85 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1175.46 ms /   222 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1184.94 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1781.21 ms /   313 tokens (    5.69 ms per token,   175.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1793.30 ms /   314 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.55 ms /   203 tokens (    5.59 ms per token,   178.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.37 ms /   204 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 52/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.84 ms /   153 tokens (    5.59 ms per token,   178.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     864.46 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.74 ms /    72 tokens (    5.51 ms per token,   181.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     401.98 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.00 ms /   174 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     910.54 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.76 ms /   122 tokens (    5.46 ms per token,   183.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.82 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.97 ms /   189 tokens (    5.15 ms per token,   194.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     982.07 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1169.34 ms /   222 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1178.46 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.04 ms /   215 tokens (    5.47 ms per token,   182.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1185.58 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.83 ms /   160 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.81 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.99 ms /   177 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.15 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     516.40 ms /   103 tokens (    5.01 ms per token,   199.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     522.62 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.28 ms /   169 tokens (    5.12 ms per token,   195.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     872.94 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.90 ms /   182 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.33 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.95 ms /   143 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     773.81 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.64 ms /   197 tokens (    5.46 ms per token,   183.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1082.63 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.72 ms /   121 tokens (    5.68 ms per token,   176.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.77 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1141.86 ms /   201 tokens (    5.68 ms per token,   176.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.06 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     683.92 ms /   123 tokens (    5.56 ms per token,   179.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     690.78 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.46 ms /   145 tokens (    5.11 ms per token,   195.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.28 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1363.15 ms /   195 tokens (    6.99 ms per token,   143.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1372.53 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.25 ms /   209 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.94 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1148.04 ms /   214 tokens (    5.36 ms per token,   186.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1157.35 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.98 ms /   181 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.64 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1391.70 ms /   256 tokens (    5.44 ms per token,   183.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1401.37 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.85 ms /   146 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     784.79 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1390.95 ms /   256 tokens (    5.43 ms per token,   184.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1400.46 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.73 ms /   134 tokens (    5.15 ms per token,   194.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     696.36 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.62 ms /   185 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.89 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1211.14 ms /   217 tokens (    5.58 ms per token,   179.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1219.57 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.08 ms /   173 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.14 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     491.24 ms /    92 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     496.18 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.46 ms /   151 tokens (    6.47 ms per token,   154.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.50 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1557.28 ms /   233 tokens (    6.68 ms per token,   149.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1566.76 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     488.69 ms /    90 tokens (    5.43 ms per token,   184.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     495.04 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.56 ms /   159 tokens (    5.02 ms per token,   199.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     804.61 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1226.13 ms /   228 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1235.77 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     457.58 ms /    89 tokens (    5.14 ms per token,   194.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     462.60 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.16 ms /   166 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.71 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.25 ms /   190 tokens (    5.19 ms per token,   192.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.02 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1000.38 ms /   191 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1008.93 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.40 ms /   156 tokens (    5.13 ms per token,   194.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     808.89 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1156.34 ms /   202 tokens (    5.72 ms per token,   174.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.67 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.75 ms /   190 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1022.09 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.59 ms /   154 tokens (    5.51 ms per token,   181.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     856.75 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1218.99 ms /   224 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1228.82 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.39 ms /   140 tokens (    5.43 ms per token,   184.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     767.28 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.51 ms /   204 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1134.43 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     289.39 ms /    56 tokens (    5.17 ms per token,   193.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     293.65 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1266.25 ms /   234 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1276.58 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     568.37 ms /   108 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     575.22 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.52 ms /   176 tokens (    5.58 ms per token,   179.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     990.94 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1068.75 ms /   200 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1079.59 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.16 ms /   131 tokens (    5.54 ms per token,   180.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     733.26 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.12 ms /   211 tokens (    5.21 ms per token,   191.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.91 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.31 ms /   156 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     825.91 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.32 ms /   185 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     968.50 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.73 ms /    64 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     355.59 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.75 ms /   125 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     672.46 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      63.52 ms /     7 tokens (    9.07 ms per token,   110.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      68.83 ms /     8 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.18 ms /   193 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1002.77 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1070.15 ms /   204 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.23 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.18 ms /   177 tokens (    5.14 ms per token,   194.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.57 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     611.96 ms /   119 tokens (    5.14 ms per token,   194.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     617.91 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.60 ms /   139 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     733.25 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.51 ms /   179 tokens (    5.19 ms per token,   192.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     937.27 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.91 ms /   121 tokens (    5.07 ms per token,   197.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     620.74 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.31 ms /   217 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1159.05 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     344.88 ms /    59 tokens (    5.85 ms per token,   171.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     350.30 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.22 ms /   143 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     761.10 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.98 ms /   131 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.82 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.85 ms /   203 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.31 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.18 ms /   187 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.13 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.10 ms /   181 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.95 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1067.18 ms /   201 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1075.98 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.59 ms /   172 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     923.55 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.03 ms /   167 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.35 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1186.28 ms /   227 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1196.67 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     230.70 ms /    34 tokens (    6.79 ms per token,   147.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     234.18 ms /    35 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 53/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.35 ms /   138 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     755.24 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.48 ms /   130 tokens (    5.43 ms per token,   184.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     712.91 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     523.84 ms /   102 tokens (    5.14 ms per token,   194.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     530.21 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1182.15 ms /   218 tokens (    5.42 ms per token,   184.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1190.88 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.60 ms /   162 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     862.21 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.47 ms /   145 tokens (    5.73 ms per token,   174.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.00 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     779.73 ms /   129 tokens (    6.04 ms per token,   165.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     786.13 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.02 ms /   158 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     847.27 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.89 ms /   170 tokens (    6.51 ms per token,   153.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.96 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     500.76 ms /    75 tokens (    6.68 ms per token,   149.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     509.08 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     614.18 ms /   116 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     620.29 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1054.20 ms /   198 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.91 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1582.21 ms /   273 tokens (    5.80 ms per token,   172.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1592.29 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.33 ms /   142 tokens (    5.10 ms per token,   196.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     730.88 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     669.64 ms /   126 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     676.50 ms /   127 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 54/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.32 ms /   111 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     604.24 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.03 ms /   194 tokens (    5.36 ms per token,   186.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1048.17 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.05 ms /   191 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1040.31 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.83 ms /   134 tokens (    5.48 ms per token,   182.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     742.14 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.82 ms /   135 tokens (    5.36 ms per token,   186.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     730.34 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     550.51 ms /   103 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     556.71 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1160.69 ms /   219 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1170.77 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     577.49 ms /   108 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     585.70 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.69 ms /   147 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.83 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.74 ms /   150 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.91 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.57 ms /   170 tokens (    5.93 ms per token,   168.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.43 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1523.81 ms /   222 tokens (    6.86 ms per token,   145.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1535.14 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.25 ms /   198 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.04 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.45 ms /   132 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.50 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.10 ms /   203 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.39 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.61 ms /   108 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     588.86 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.26 ms /   120 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     636.58 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.80 ms /   125 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     667.28 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.21 ms /   132 tokens (    5.60 ms per token,   178.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     748.64 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.79 ms /   134 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     697.97 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1083.57 ms /   206 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1093.05 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.16 ms /   208 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.82 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.91 ms /   166 tokens (    5.46 ms per token,   183.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     913.24 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.82 ms /   116 tokens (    6.08 ms per token,   164.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     711.30 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.95 ms /   135 tokens (    6.01 ms per token,   166.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     818.69 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.15 ms /   173 tokens (    5.80 ms per token,   172.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1013.15 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     578.76 ms /   101 tokens (    5.73 ms per token,   174.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     586.04 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.48 ms /   164 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     859.49 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.43 ms /   177 tokens (    5.64 ms per token,   177.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1005.97 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.68 ms /   132 tokens (    5.14 ms per token,   194.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     685.96 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.72 ms /   112 tokens (    5.06 ms per token,   197.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     573.21 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.73 ms /   177 tokens (    5.22 ms per token,   191.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.66 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1197.58 ms /   223 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1206.54 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1162.09 ms /   223 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1170.71 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1141.69 ms /   201 tokens (    5.68 ms per token,   176.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1150.14 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.96 ms /   153 tokens (    5.13 ms per token,   194.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.99 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.98 ms /   196 tokens (    5.14 ms per token,   194.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1015.46 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.95 ms /   150 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     801.56 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.02 ms /   208 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.06 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.37 ms /   133 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     727.62 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.55 ms /   182 tokens (    5.15 ms per token,   194.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     944.57 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.81 ms /   126 tokens (    5.01 ms per token,   199.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     637.70 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     634.94 ms /   121 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     642.62 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.86 ms /   146 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     759.79 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     422.70 ms /    87 tokens (    4.86 ms per token,   205.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     428.89 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.66 ms /   151 tokens (    5.56 ms per token,   179.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.52 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     845.42 ms /   150 tokens (    5.64 ms per token,   177.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.20 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1014.21 ms /   197 tokens (    5.15 ms per token,   194.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1022.40 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.91 ms /   113 tokens (    5.65 ms per token,   176.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     645.57 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.95 ms /   122 tokens (    5.05 ms per token,   198.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.09 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.79 ms /   170 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.05 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     343.75 ms /    66 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     348.84 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.78 ms /   176 tokens (    5.08 ms per token,   196.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.64 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     857.02 ms /   170 tokens (    5.04 ms per token,   198.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.31 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     972.83 ms /   185 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     980.57 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.46 ms /   188 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.42 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1191.77 ms /   213 tokens (    5.60 ms per token,   178.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1200.20 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     372.98 ms /    66 tokens (    5.65 ms per token,   176.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     377.42 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     472.46 ms /    90 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     478.51 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.08 ms /   163 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.87 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1067.05 ms /   188 tokens (    5.68 ms per token,   176.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.27 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1168.75 ms /   210 tokens (    5.57 ms per token,   179.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1177.79 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.34 ms /   198 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1044.72 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1135.62 ms /   163 tokens (    6.97 ms per token,   143.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1145.71 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.82 ms /   136 tokens (    5.76 ms per token,   173.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     792.08 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     542.40 ms /   100 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     547.76 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1029.14 ms /   199 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.78 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.00 ms /   163 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.24 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     590.09 ms /   113 tokens (    5.22 ms per token,   191.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     595.91 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.78 ms /   175 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.00 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.97 ms /   164 tokens (    5.59 ms per token,   178.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     925.20 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.28 ms /   156 tokens (    5.14 ms per token,   194.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     810.15 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.58 ms /   142 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     744.27 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.48 ms /   192 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.72 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.21 ms /   175 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.60 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.90 ms /   130 tokens (    5.11 ms per token,   195.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     669.94 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     970.91 ms /   187 tokens (    5.19 ms per token,   192.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     979.61 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.20 ms /   158 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     854.37 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.79 ms /   199 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.97 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.06 ms /   165 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.84 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.76 ms /    52 tokens (    5.11 ms per token,   195.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     271.26 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.51 ms /   185 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.96 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.43 ms /   120 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     637.53 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1190.66 ms /   172 tokens (    6.92 ms per token,   144.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1201.62 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.91 ms /   169 tokens (    6.44 ms per token,   155.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.64 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1056.52 ms /   190 tokens (    5.56 ms per token,   179.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1064.48 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.17 ms /   210 tokens (    5.45 ms per token,   183.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1153.33 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.17 ms /   139 tokens (    5.56 ms per token,   179.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.88 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.35 ms /   138 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     713.84 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.83 ms /   137 tokens (    6.06 ms per token,   165.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.64 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.42 ms /   110 tokens (    5.15 ms per token,   194.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     572.27 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.55 ms /   230 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.42 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.20 ms /   134 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     703.37 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1035.67 ms /   184 tokens (    5.63 ms per token,   177.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1045.21 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     961.57 ms /   170 tokens (    5.66 ms per token,   176.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.48 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.27 ms /   181 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.22 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.61 ms /   115 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     601.35 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1188.54 ms /   221 tokens (    5.38 ms per token,   185.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1198.06 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     341.55 ms /    66 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     346.01 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1353.45 ms /   254 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1363.22 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.89 ms /   194 tokens (    5.24 ms per token,   190.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1024.04 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.96 ms /   168 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     895.94 ms /   169 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 56/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.57 ms /   180 tokens (    5.15 ms per token,   194.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.12 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.97 ms /   156 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.35 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.15 ms /   195 tokens (    5.58 ms per token,   179.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1095.93 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     666.42 ms /   126 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     676.10 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.86 ms /   192 tokens (    5.16 ms per token,   193.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     999.25 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.37 ms /   133 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     697.15 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.11 ms /   191 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.06 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.54 ms /   130 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     688.79 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     998.96 ms /   191 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1007.12 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.25 ms /   168 tokens (    6.10 ms per token,   163.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.86 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     430.38 ms /    76 tokens (    5.66 ms per token,   176.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     436.67 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1497.13 ms /   265 tokens (    5.65 ms per token,   177.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1507.58 ms /   266 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.63 ms /    56 tokens (    5.37 ms per token,   186.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     304.74 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1354.37 ms /   249 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1365.55 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.35 ms /   148 tokens (    5.21 ms per token,   191.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.57 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1151.11 ms /   219 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1161.65 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     332.21 ms /    61 tokens (    5.45 ms per token,   183.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.90 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1103.36 ms /   212 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1112.39 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.72 ms /   139 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     748.39 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.84 ms /   134 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     706.92 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.15 ms /   181 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.85 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.00 ms /   105 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     565.68 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     664.57 ms /   129 tokens (    5.15 ms per token,   194.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.10 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.31 ms /   209 tokens (    5.50 ms per token,   181.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1158.94 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     731.16 ms /   138 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     738.07 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.13 ms /   113 tokens (    6.11 ms per token,   163.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.78 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.24 ms /   136 tokens (    5.50 ms per token,   181.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     754.91 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.73 ms /   128 tokens (    5.02 ms per token,   199.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.79 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.24 ms /   167 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.05 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1098.16 ms /   209 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1107.63 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     518.39 ms /    63 tokens (    8.23 ms per token,   121.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     524.90 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.08 ms /   116 tokens (    6.44 ms per token,   155.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     755.73 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.55 ms /   157 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.20 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     589.11 ms /   115 tokens (    5.12 ms per token,   195.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.43 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.37 ms /   169 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     907.84 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.76 ms /   197 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.61 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     275.84 ms /    46 tokens (    6.00 ms per token,   166.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     283.61 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.11 ms /   169 tokens (    5.23 ms per token,   191.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.55 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.00 ms /   186 tokens (    5.96 ms per token,   167.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1116.41 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     262.38 ms /    43 tokens (    6.10 ms per token,   163.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     266.10 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     532.33 ms /   102 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     539.44 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.25 ms /   131 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     706.71 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.02 ms /   136 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     722.35 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     567.31 ms /   109 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     572.94 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.88 ms /   165 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.72 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1191.05 ms /   220 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.61 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.10 ms /   104 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     552.88 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1114.83 ms /   209 tokens (    5.33 ms per token,   187.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1123.56 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.85 ms /   172 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.67 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.73 ms /   142 tokens (    5.11 ms per token,   195.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     733.35 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.02 ms /   111 tokens (    5.10 ms per token,   196.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     572.45 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.83 ms /   137 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     746.06 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     480.28 ms /    96 tokens (    5.00 ms per token,   199.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     485.84 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.56 ms /   194 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1029.47 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     409.67 ms /    71 tokens (    5.77 ms per token,   173.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     414.93 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1301.86 ms /   187 tokens (    6.96 ms per token,   143.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1311.78 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1359.27 ms /   215 tokens (    6.32 ms per token,   158.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1369.82 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.78 ms /    97 tokens (    5.34 ms per token,   187.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     523.26 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.81 ms /   181 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.22 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     355.02 ms /    71 tokens (    5.00 ms per token,   199.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     360.29 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.55 ms /   151 tokens (    5.41 ms per token,   184.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     825.00 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1050.78 ms /   204 tokens (    5.15 ms per token,   194.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.77 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.84 ms /   127 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     679.19 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.17 ms /   184 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     966.43 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     490.06 ms /    93 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     496.53 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.80 ms /   202 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1079.44 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     778.32 ms /   139 tokens (    5.60 ms per token,   178.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     788.99 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.95 ms /   143 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     758.81 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     610.04 ms /   118 tokens (    5.17 ms per token,   193.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     616.87 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.75 ms /   192 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.99 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.27 ms /   156 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.81 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1033.43 ms /   196 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1042.25 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.88 ms /   201 tokens (    5.65 ms per token,   177.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1144.23 ms /   202 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 57/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     431.09 ms /    80 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     436.88 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.30 ms /   152 tokens (    5.15 ms per token,   194.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.48 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.83 ms /   185 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     992.57 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1468.18 ms /   261 tokens (    5.63 ms per token,   177.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1479.02 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.94 ms /   159 tokens (    5.86 ms per token,   170.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.75 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1071.86 ms /   196 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.05 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.02 ms /   187 tokens (    5.55 ms per token,   180.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.13 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1214.69 ms /   215 tokens (    5.65 ms per token,   177.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.87 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     550.27 ms /   107 tokens (    5.14 ms per token,   194.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     556.25 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.32 ms /   134 tokens (    5.14 ms per token,   194.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.97 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.80 ms /   152 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     810.48 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1125.33 ms /   207 tokens (    5.44 ms per token,   183.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1135.99 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.95 ms /   128 tokens (    5.58 ms per token,   179.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.50 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     628.63 ms /   121 tokens (    5.20 ms per token,   192.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     635.79 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.13 ms /   125 tokens (    5.21 ms per token,   191.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     657.55 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     990.38 ms /   190 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.55 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1331.11 ms /   247 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1340.30 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.45 ms /   187 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.56 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.71 ms /   190 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.20 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1340.45 ms /   243 tokens (    5.52 ms per token,   181.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1349.35 ms /   244 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.61 ms /   231 tokens (    5.46 ms per token,   183.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1270.97 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     481.25 ms /    98 tokens (    4.91 ms per token,   203.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.56 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.38 ms /   163 tokens (    5.72 ms per token,   174.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.83 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.83 ms /   167 tokens (    5.56 ms per token,   179.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.75 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     552.62 ms /   103 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     558.30 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.00 ms /   233 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1269.61 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     561.74 ms /   107 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     567.66 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1068.04 ms /   198 tokens (    5.39 ms per token,   185.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.80 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1079.58 ms /   147 tokens (    7.34 ms per token,   136.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1088.19 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.93 ms /    60 tokens (    5.83 ms per token,   171.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.32 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.55 ms /   184 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.94 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.21 ms /   184 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.30 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     246.64 ms /    47 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     250.63 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.28 ms /   145 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     767.58 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.93 ms /   152 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.03 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.53 ms /   159 tokens (    5.04 ms per token,   198.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     808.81 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     489.78 ms /    89 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     495.34 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.96 ms /   160 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.05 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.41 ms /   193 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1038.67 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.78 ms /   171 tokens (    5.37 ms per token,   186.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.13 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.75 ms /   179 tokens (    5.17 ms per token,   193.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.52 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.71 ms /    81 tokens (    5.13 ms per token,   194.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.70 ms /    82 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 58/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.45 ms /   154 tokens (    5.42 ms per token,   184.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.89 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.93 ms /   154 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     815.59 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.32 ms /   136 tokens (    5.08 ms per token,   196.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.44 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.23 ms /   155 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.27 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.19 ms /   174 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     936.85 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.89 ms /   157 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.01 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.66 ms /   189 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1009.84 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     186.36 ms /    27 tokens (    6.90 ms per token,   144.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     191.03 ms /    28 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      55.53 ms /     8 tokens (    6.94 ms per token,   144.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      58.49 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1199.06 ms /   197 tokens (    6.09 ms per token,   164.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1207.71 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     362.62 ms /    66 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     367.13 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.92 ms /   183 tokens (    5.09 ms per token,   196.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.74 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.51 ms /   197 tokens (    5.98 ms per token,   167.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1185.69 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.19 ms /   115 tokens (    6.74 ms per token,   148.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.58 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.90 ms /   126 tokens (    6.55 ms per token,   152.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     834.12 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     616.23 ms /   114 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     622.08 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.62 ms /   135 tokens (    5.15 ms per token,   194.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.18 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.62 ms /   180 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.90 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1077.98 ms /   203 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1086.61 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.48 ms /   170 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.55 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1218.77 ms /   226 tokens (    5.39 ms per token,   185.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1228.04 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.88 ms /    53 tokens (    5.02 ms per token,   199.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     270.14 ms /    54 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 59/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.31 ms /   136 tokens (    5.47 ms per token,   182.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.89 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.74 ms /   152 tokens (    5.14 ms per token,   194.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     788.71 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     934.44 ms /   180 tokens (    5.19 ms per token,   192.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     943.59 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.96 ms /   143 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.59 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.55 ms /   185 tokens (    5.16 ms per token,   193.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.54 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.06 ms /   134 tokens (    5.44 ms per token,   183.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     735.89 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1325.92 ms /   244 tokens (    5.43 ms per token,   184.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1335.34 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     414.28 ms /    77 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     419.04 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.73 ms /   151 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     801.73 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.84 ms /   121 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.60 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1128.22 ms /   209 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1138.65 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1267.22 ms /   238 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1276.92 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     358.82 ms /    58 tokens (    6.19 ms per token,   161.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     363.15 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     549.76 ms /   110 tokens (    5.00 ms per token,   200.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.48 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.31 ms /   201 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1074.39 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.57 ms /   102 tokens (    5.98 ms per token,   167.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     617.81 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      76.37 ms /     8 tokens (    9.55 ms per token,   104.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      80.84 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1156.00 ms /   203 tokens (    5.69 ms per token,   175.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1166.24 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.22 ms /   104 tokens (    5.97 ms per token,   167.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     626.78 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.74 ms /   193 tokens (    5.49 ms per token,   182.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1067.14 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     480.06 ms /    88 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     487.05 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1148.03 ms /   211 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1156.79 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.50 ms /    57 tokens (    6.13 ms per token,   163.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.26 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     712.30 ms /   139 tokens (    5.12 ms per token,   195.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.44 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.87 ms /   205 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1133.21 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      52.23 ms /     4 tokens (   13.06 ms per token,    76.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.58 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1053.70 ms /   199 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.48 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     618.19 ms /   113 tokens (    5.47 ms per token,   182.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     625.49 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1120.28 ms /   201 tokens (    5.57 ms per token,   179.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.89 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     556.18 ms /    82 tokens (    6.78 ms per token,   147.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     562.37 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.43 ms /   160 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.47 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1066.00 ms /   200 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1074.64 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     520.58 ms /    90 tokens (    5.78 ms per token,   172.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     527.28 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1190.67 ms /   216 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.73 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     564.08 ms /    98 tokens (    5.76 ms per token,   173.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     569.62 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.00 ms /   206 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1109.62 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1247.38 ms /   223 tokens (    5.59 ms per token,   178.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.08 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     543.36 ms /   106 tokens (    5.13 ms per token,   195.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     551.14 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.70 ms /   135 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.46 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.14 ms /   138 tokens (    5.39 ms per token,   185.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.39 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      55.68 ms /     3 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      59.15 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1330.80 ms /   203 tokens (    6.56 ms per token,   152.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1340.19 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.85 ms /   189 tokens (    5.40 ms per token,   185.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1029.06 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.21 ms /   117 tokens (    5.63 ms per token,   177.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     665.30 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1200.59 ms /   228 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.45 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1237.03 ms /   219 tokens (    5.65 ms per token,   177.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.71 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1711.58 ms /   247 tokens (    6.93 ms per token,   144.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1721.72 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.35 ms /   129 tokens (    5.59 ms per token,   178.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.10 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     553.96 ms /   101 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     561.78 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.54 ms /   158 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     840.82 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     457.78 ms /    92 tokens (    4.98 ms per token,   200.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     463.72 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     990.82 ms /   190 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.98 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     543.96 ms /   101 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     551.15 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     226.65 ms /    41 tokens (    5.53 ms per token,   180.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     231.56 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.94 ms /   191 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1008.38 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     419.25 ms /    58 tokens (    7.23 ms per token,   138.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     426.13 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.02 ms /     5 tokens (    8.80 ms per token,   113.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.04 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.62 ms /   192 tokens (    5.10 ms per token,   195.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.13 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.21 ms /    51 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     270.25 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     519.22 ms /   101 tokens (    5.14 ms per token,   194.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     525.12 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.15 ms /   187 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     987.85 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.86 ms /    77 tokens (    5.40 ms per token,   185.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     420.92 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      32.61 ms /     2 tokens (   16.31 ms per token,    61.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      35.48 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.96 ms /   204 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.20 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     437.62 ms /    83 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     446.25 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.51 ms /   137 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.33 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.58 ms /   195 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.57 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     370.69 ms /    75 tokens (    4.94 ms per token,   202.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     378.30 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     628.64 ms /   117 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.88 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.15 ms /   151 tokens (    5.10 ms per token,   196.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     776.94 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1291.10 ms /   203 tokens (    6.36 ms per token,   157.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.22 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1372.91 ms /   204 tokens (    6.73 ms per token,   148.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1381.60 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1285.62 ms /   237 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1301.54 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     344.08 ms /    65 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     351.04 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      61.20 ms /    10 tokens (    6.12 ms per token,   163.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      65.17 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1393.99 ms /   256 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1405.14 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.10 ms /   144 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.51 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1423.96 ms /   257 tokens (    5.54 ms per token,   180.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1433.64 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1200.09 ms /   221 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.51 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.77 ms /   176 tokens (    5.21 ms per token,   191.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     926.11 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1482.28 ms /   266 tokens (    5.57 ms per token,   179.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1491.91 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.21 ms /   162 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     875.47 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.48 ms /   174 tokens (    5.20 ms per token,   192.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     913.37 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1099.26 ms /   209 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1108.84 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.85 ms /   213 tokens (    5.50 ms per token,   181.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1181.80 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     611.88 ms /   110 tokens (    5.56 ms per token,   179.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     617.63 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.24 ms /   145 tokens (    5.15 ms per token,   194.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.29 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1326.11 ms /   245 tokens (    5.41 ms per token,   184.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1335.30 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     467.31 ms /    90 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     472.64 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      88.02 ms /    13 tokens (    6.77 ms per token,   147.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.35 ms /    14 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1167.23 ms /   222 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1176.62 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     532.16 ms /    95 tokens (    5.60 ms per token,   178.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     541.17 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.25 ms /   184 tokens (    5.15 ms per token,   194.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.16 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1250.61 ms /   220 tokens (    5.68 ms per token,   175.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1259.93 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     577.01 ms /    96 tokens (    6.01 ms per token,   166.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     582.25 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      50.27 ms /     5 tokens (   10.05 ms per token,    99.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.67 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1273.73 ms /   235 tokens (    5.42 ms per token,   184.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1283.58 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.70 ms /   157 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     841.87 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      58.55 ms /     9 tokens (    6.51 ms per token,   153.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.94 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1259.30 ms /   226 tokens (    5.57 ms per token,   179.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1268.44 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.29 ms /   139 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     743.99 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.26 ms /   306 tokens (    5.53 ms per token,   180.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1703.83 ms /   307 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      49.21 ms /     6 tokens (    8.20 ms per token,   121.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      52.30 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1247.26 ms /   221 tokens (    5.64 ms per token,   177.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1257.66 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.70 ms /   140 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     741.24 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.05 ms /   147 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.06 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1424.04 ms /   239 tokens (    5.96 ms per token,   167.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1436.14 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1539.85 ms /   284 tokens (    5.42 ms per token,   184.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1550.45 ms /   285 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1845.90 ms /   332 tokens (    5.56 ms per token,   179.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1867.30 ms /   333 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1545.20 ms /   273 tokens (    5.66 ms per token,   176.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1556.04 ms /   274 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1493.72 ms /   208 tokens (    7.18 ms per token,   139.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1505.33 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.05 ms /   189 tokens (    5.42 ms per token,   184.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.79 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1455.00 ms /   244 tokens (    5.96 ms per token,   167.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.03 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     387.78 ms /    72 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     393.53 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1279.53 ms /   238 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1288.89 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.40 ms /   223 tokens (    5.58 ms per token,   179.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.40 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     305.82 ms /    48 tokens (    6.37 ms per token,   156.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     309.87 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.87 ms /   204 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.30 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     475.61 ms /    85 tokens (    5.60 ms per token,   178.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     481.26 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.22 ms /   132 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.70 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     437.30 ms /    84 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     444.24 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1192.38 ms /   214 tokens (    5.57 ms per token,   179.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1202.54 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.04 ms /   119 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     621.24 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1214.79 ms /   219 tokens (    5.55 ms per token,   180.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1223.36 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.27 ms /   189 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.54 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.53 ms /   192 tokens (    5.18 ms per token,   193.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1005.01 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.96 ms /   192 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.82 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     101.31 ms /     7 tokens (   14.47 ms per token,    69.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     105.87 ms /     8 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1347.01 ms /   246 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1356.82 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     409.64 ms /    81 tokens (    5.06 ms per token,   197.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     414.40 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      43.14 ms /     4 tokens (   10.78 ms per token,    92.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.99 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1318.04 ms /   239 tokens (    5.51 ms per token,   181.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1327.27 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1283.18 ms /   239 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.71 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     317.97 ms /    53 tokens (    6.00 ms per token,   166.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     321.94 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      50.61 ms /     8 tokens (    6.33 ms per token,   158.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      53.51 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.32 ms /   203 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.83 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     361.62 ms /    56 tokens (    6.46 ms per token,   154.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     365.98 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1136.65 ms /   208 tokens (    5.46 ms per token,   182.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1145.68 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1499.82 ms /   214 tokens (    7.01 ms per token,   142.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1508.14 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.42 ms /   177 tokens (    5.98 ms per token,   167.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.04 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      38.54 ms /     4 tokens (    9.64 ms per token,   103.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.84 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1077.97 ms /   196 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1089.43 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.77 ms /   147 tokens (    5.38 ms per token,   185.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     797.75 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     257.81 ms /    43 tokens (    6.00 ms per token,   166.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     261.53 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1068.36 ms /   205 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.59 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     282.08 ms /    47 tokens (    6.00 ms per token,   166.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.95 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     353.38 ms /    70 tokens (    5.05 ms per token,   198.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     358.46 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     623.73 ms /   116 tokens (    5.38 ms per token,   185.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     630.92 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.49 ms /   179 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.30 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1356.22 ms /   248 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1367.04 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     590.93 ms /   111 tokens (    5.32 ms per token,   187.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.89 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.07 ms /   161 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.77 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.19 ms /   129 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     691.06 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.21 ms /   131 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     714.12 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.43 ms /   201 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1089.92 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1064.65 ms /   193 tokens (    5.52 ms per token,   181.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.57 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.59 ms /   153 tokens (    5.57 ms per token,   179.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.70 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     267.22 ms /    51 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     272.20 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.71 ms /   167 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     900.64 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.46 ms /   160 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.36 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.58 ms /   170 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.78 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1288.22 ms /   222 tokens (    5.80 ms per token,   172.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1297.19 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.46 ms /   177 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.53 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1186.49 ms /   226 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1196.19 ms /   227 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 60/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     421.64 ms /    73 tokens (    5.78 ms per token,   173.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     430.09 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.33 ms /   185 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.92 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.95 ms /   116 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     639.23 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.20 ms /   191 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1013.11 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.97 ms /   105 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     574.41 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.25 ms /   171 tokens (    5.12 ms per token,   195.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     883.92 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.72 ms /   226 tokens (    5.48 ms per token,   182.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1248.56 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.40 ms /   194 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.58 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.43 ms /   132 tokens (    5.04 ms per token,   198.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     673.00 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     636.64 ms /   117 tokens (    5.44 ms per token,   183.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     643.10 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     606.96 ms /   119 tokens (    5.10 ms per token,   196.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     613.35 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.80 ms /   135 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     708.77 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.81 ms /   127 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.11 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.30 ms /   126 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     676.46 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.20 ms /   172 tokens (    5.16 ms per token,   193.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.28 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.32 ms /   198 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.67 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.42 ms /   165 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.48 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      43.23 ms /     4 tokens (   10.81 ms per token,    92.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.74 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1367.42 ms /   231 tokens (    5.92 ms per token,   168.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1377.61 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.34 ms /    42 tokens (    7.44 ms per token,   134.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     318.32 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     404.43 ms /    59 tokens (    6.85 ms per token,   145.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     410.47 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1152.98 ms /   216 tokens (    5.34 ms per token,   187.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1162.77 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.23 ms /   200 tokens (    5.40 ms per token,   185.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.38 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1197.12 ms /   224 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1207.87 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1241.37 ms /   224 tokens (    5.54 ms per token,   180.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1250.61 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     565.44 ms /   103 tokens (    5.49 ms per token,   182.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     572.00 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     208.84 ms /    42 tokens (    4.97 ms per token,   201.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     213.35 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.27 ms /     5 tokens (    8.85 ms per token,   112.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.22 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1298.81 ms /   221 tokens (    5.88 ms per token,   170.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1307.69 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     502.97 ms /    91 tokens (    5.53 ms per token,   180.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     508.86 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1141.30 ms /   217 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1150.17 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.88 ms /   197 tokens (    5.56 ms per token,   179.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1103.94 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.71 ms /   156 tokens (    5.47 ms per token,   182.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     859.88 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1267.92 ms /   237 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1276.73 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     298.86 ms /    55 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     302.97 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     378.62 ms /    68 tokens (    5.57 ms per token,   179.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     384.37 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.03 ms /   159 tokens (    5.09 ms per token,   196.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     817.93 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     284.63 ms /    48 tokens (    5.93 ms per token,   168.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.77 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.49 ms /   202 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.81 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.36 ms /   156 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.24 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     975.85 ms /   192 tokens (    5.08 ms per token,   196.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.54 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     555.37 ms /   110 tokens (    5.05 ms per token,   198.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     561.43 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.51 ms /   189 tokens (    5.48 ms per token,   182.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.50 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.79 ms /   142 tokens (    5.63 ms per token,   177.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     807.50 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1568.84 ms /   281 tokens (    5.58 ms per token,   179.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1579.11 ms /   282 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 61/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.59 ms /   208 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.41 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.14 ms /   116 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     614.77 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.90 ms /   180 tokens (    5.15 ms per token,   194.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.62 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.56 ms /   146 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     800.59 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.54 ms /   132 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     710.35 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1577.48 ms /   220 tokens (    7.17 ms per token,   139.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1587.27 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     669.93 ms /   113 tokens (    5.93 ms per token,   168.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     676.46 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.87 ms /   187 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     988.17 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.39 ms /   160 tokens (    5.16 ms per token,   193.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     832.97 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.49 ms /   181 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.74 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.53 ms /   212 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1122.80 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.38 ms /   118 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     618.37 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     645.22 ms /   121 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     651.77 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1136.95 ms /   204 tokens (    5.57 ms per token,   179.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1145.47 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     113.63 ms /    20 tokens (    5.68 ms per token,   176.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     116.59 ms /    21 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 62/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.01 ms /   141 tokens (    5.62 ms per token,   177.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.69 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.22 ms /   138 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     744.09 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     409.19 ms /    75 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     414.62 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     971.50 ms /   185 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.34 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.64 ms /   164 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     876.18 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.47 ms /   181 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.60 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     592.87 ms /   111 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     598.62 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1060.12 ms /   199 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.52 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.60 ms /   195 tokens (    5.46 ms per token,   183.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1075.16 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1263.86 ms /   218 tokens (    5.80 ms per token,   172.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.37 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     445.60 ms /    77 tokens (    5.79 ms per token,   172.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     450.88 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      47.02 ms /     4 tokens (   11.75 ms per token,    85.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.74 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.12 ms /   199 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.70 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.14 ms /    94 tokens (    5.71 ms per token,   175.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     547.32 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      48.09 ms /     5 tokens (    9.62 ms per token,   103.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.59 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.37 ms /   190 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.44 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     360.86 ms /    68 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     366.28 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.56 ms /     5 tokens (    8.91 ms per token,   112.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.31 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1223.15 ms /   226 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.86 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.21 ms /   131 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     683.37 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      36.75 ms /     3 tokens (   12.25 ms per token,    81.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.04 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.35 ms /   211 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1143.37 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     461.92 ms /    81 tokens (    5.70 ms per token,   175.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     470.55 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     750.02 ms /   142 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     758.10 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     636.51 ms /   124 tokens (    5.13 ms per token,   194.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     642.73 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1200.76 ms /   222 tokens (    5.41 ms per token,   184.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1209.77 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     346.05 ms /    66 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     352.17 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.80 ms /   137 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.69 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.80 ms /   204 tokens (    5.64 ms per token,   177.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1158.83 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     354.08 ms /    63 tokens (    5.62 ms per token,   177.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.81 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     603.11 ms /   114 tokens (    5.29 ms per token,   189.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     611.67 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.17 ms /   145 tokens (    5.21 ms per token,   192.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.30 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.79 ms /   106 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     553.24 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.14 ms /   170 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     901.15 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.82 ms /   150 tokens (    5.12 ms per token,   195.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.70 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.46 ms /   144 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.44 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.91 ms /   118 tokens (    7.16 ms per token,   139.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.79 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.07 ms /   217 tokens (    5.71 ms per token,   175.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1247.35 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     423.04 ms /    77 tokens (    5.49 ms per token,   182.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     427.73 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.97 ms /   147 tokens (    5.18 ms per token,   192.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     770.01 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     796.45 ms /   153 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     804.85 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.75 ms /   170 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.64 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.40 ms /   172 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.42 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1347.44 ms /   234 tokens (    5.76 ms per token,   173.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1358.70 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.64 ms /   115 tokens (    5.08 ms per token,   196.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.44 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.73 ms /   112 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.15 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.25 ms /   197 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.89 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.14 ms /   127 tokens (    5.51 ms per token,   181.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     710.12 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     571.45 ms /   110 tokens (    5.20 ms per token,   192.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     577.21 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.87 ms /   182 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.79 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     474.50 ms /    93 tokens (    5.10 ms per token,   196.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     479.85 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.50 ms /   190 tokens (    5.14 ms per token,   194.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.66 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.49 ms /   193 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.82 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.94 ms /   168 tokens (    5.14 ms per token,   194.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     873.24 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.69 ms /   174 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.61 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.53 ms /   131 tokens (    5.12 ms per token,   195.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     677.14 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1244.98 ms /   228 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1257.40 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.30 ms /   177 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     936.88 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.89 ms /   184 tokens (    5.11 ms per token,   195.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.12 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1109.08 ms /   211 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1122.77 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     458.15 ms /    87 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     463.53 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.94 ms /   185 tokens (    5.12 ms per token,   195.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.12 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.63 ms /   121 tokens (    5.17 ms per token,   193.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     632.30 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.71 ms /   106 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     557.84 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.79 ms /   150 tokens (    5.14 ms per token,   194.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.79 ms /   151 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 63/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1021.16 ms /   195 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1030.33 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.91 ms /   170 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.69 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1129.10 ms /   209 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.90 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1281.27 ms /   179 tokens (    7.16 ms per token,   139.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1289.85 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1197.14 ms /   192 tokens (    6.24 ms per token,   160.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1205.33 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1035.57 ms /   191 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1045.44 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.11 ms /   159 tokens (    5.55 ms per token,   180.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     892.03 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.45 ms /   185 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.17 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     479.51 ms /    91 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     485.12 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.74 ms /   196 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.62 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     675.69 ms /   129 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.76 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.46 ms /   135 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     743.77 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1255.58 ms /   231 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1264.93 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.70 ms /   129 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     691.95 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.49 ms /   171 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.98 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1194.38 ms /   220 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1203.67 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.62 ms /   146 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.57 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.89 ms /   196 tokens (    5.19 ms per token,   192.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1026.05 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.58 ms /   146 tokens (    5.19 ms per token,   192.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.15 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.41 ms /   109 tokens (    5.55 ms per token,   180.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     610.66 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.51 ms /   155 tokens (    5.18 ms per token,   193.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     810.73 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.10 ms /   180 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     946.69 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1113.82 ms /   203 tokens (    5.49 ms per token,   182.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1122.53 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     236.37 ms /    48 tokens (    4.92 ms per token,   203.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     241.26 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.86 ms /   113 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     611.86 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1290.18 ms /   238 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1299.21 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     480.18 ms /    92 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.29 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.62 ms /   173 tokens (    5.14 ms per token,   194.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     897.24 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     489.56 ms /    93 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     495.19 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.42 ms /   174 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     919.05 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1192.58 ms /   220 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1201.39 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.81 ms /   199 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1058.48 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.01 ms /   184 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.62 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.15 ms /   187 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     989.79 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1128.16 ms /   201 tokens (    5.61 ms per token,   178.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1136.78 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     397.30 ms /    58 tokens (    6.85 ms per token,   145.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     402.67 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.13 ms /   195 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.42 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.24 ms /   190 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1026.16 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.98 ms /   117 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     621.61 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.16 ms /   173 tokens (    5.88 ms per token,   170.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.50 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1283.63 ms /   201 tokens (    6.39 ms per token,   156.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.67 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     363.05 ms /    61 tokens (    5.95 ms per token,   168.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.67 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.91 ms /   196 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.80 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.78 ms /   183 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.64 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1226.59 ms /   231 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1236.10 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1337.34 ms /   224 tokens (    5.97 ms per token,   167.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1346.64 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1250.31 ms /   226 tokens (    5.53 ms per token,   180.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1259.55 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     541.19 ms /   107 tokens (    5.06 ms per token,   197.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.98 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.84 ms /   139 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     739.92 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.45 ms /   190 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.29 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.35 ms /   121 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.20 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1858.85 ms /   335 tokens (    5.55 ms per token,   180.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1871.44 ms /   336 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.02 ms /   128 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     683.56 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.77 ms /   211 tokens (    5.45 ms per token,   183.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.22 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1310.29 ms /   247 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1319.75 ms /   248 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     693.72 ms /   123 tokens (    5.64 ms per token,   177.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     699.90 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.06 ms /   200 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.37 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1150.29 ms /   211 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.87 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1187.51 ms /   213 tokens (    5.58 ms per token,   179.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.99 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.88 ms /   143 tokens (    5.64 ms per token,   177.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     813.47 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1364.41 ms /   249 tokens (    5.48 ms per token,   182.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1375.35 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      43.59 ms /     3 tokens (   14.53 ms per token,    68.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.10 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     195.94 ms /    37 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     199.91 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1366.64 ms /   252 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1377.77 ms /   253 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.78 ms /   122 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     658.41 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.00 ms /   192 tokens (    5.33 ms per token,   187.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1031.32 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1236.77 ms /   219 tokens (    5.65 ms per token,   177.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1247.11 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.76 ms /   109 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     572.67 ms /   110 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 65/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.93 ms /   137 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     727.29 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.54 ms /   166 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     889.18 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.85 ms /   149 tokens (    5.97 ms per token,   167.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     896.98 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.94 ms /   106 tokens (    6.59 ms per token,   151.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.10 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.63 ms /   147 tokens (    6.76 ms per token,   147.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.47 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1426.46 ms /   238 tokens (    5.99 ms per token,   166.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.96 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.66 ms /   181 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     978.95 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     166.64 ms /    32 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     169.91 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.07 ms /   173 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.90 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     418.21 ms /    77 tokens (    5.43 ms per token,   184.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     423.86 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      45.02 ms /     4 tokens (   11.26 ms per token,    88.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.68 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1037.05 ms /   197 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.24 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     430.98 ms /    78 tokens (    5.53 ms per token,   180.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     438.28 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.51 ms /   209 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.94 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1166.54 ms /   203 tokens (    5.75 ms per token,   174.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1174.90 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.58 ms /   199 tokens (    5.44 ms per token,   183.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.56 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.24 ms /   199 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1090.73 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.38 ms /   156 tokens (    5.71 ms per token,   175.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.15 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     544.22 ms /   102 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     549.80 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     600.75 ms /   114 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     606.93 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.50 ms /   165 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     869.07 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.24 ms /   163 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     875.44 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     494.88 ms /    92 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     500.06 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.60 ms /   195 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.15 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     669.35 ms /   131 tokens (    5.11 ms per token,   195.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     677.82 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.28 ms /   159 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     854.19 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1155.50 ms /   208 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.24 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.52 ms /   150 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.40 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.87 ms /    96 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.45 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     980.67 ms /   184 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     989.20 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.07 ms /   183 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     969.29 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     224.14 ms /    43 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.21 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.36 ms /   147 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.55 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     591.19 ms /   115 tokens (    5.14 ms per token,   194.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     597.77 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1244.92 ms /   231 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.02 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     324.63 ms /    57 tokens (    5.70 ms per token,   175.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.37 ms /    58 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 66/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1124.91 ms /   213 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1133.73 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.94 ms /   150 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.58 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.12 ms /   183 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     968.82 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.16 ms /   200 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.94 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1448.86 ms /   205 tokens (    7.07 ms per token,   141.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1457.53 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.19 ms /   176 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     919.69 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.11 ms /   191 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1009.67 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1460.58 ms /   260 tokens (    5.62 ms per token,   178.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1472.44 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     389.79 ms /    74 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     395.12 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1467.66 ms /   267 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1478.08 ms /   268 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.97 ms /   303 tokens (    5.57 ms per token,   179.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1699.13 ms /   304 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2083.69 ms /   369 tokens (    5.65 ms per token,   177.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2095.71 ms /   370 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.96 ms /   179 tokens (    5.21 ms per token,   191.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.25 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1593.56 ms /   275 tokens (    5.79 ms per token,   172.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1604.05 ms /   276 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     144.54 ms /    26 tokens (    5.56 ms per token,   179.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     147.75 ms /    27 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 68/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1126.48 ms /   212 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.18 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.79 ms /   161 tokens (    5.32 ms per token,   187.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     863.94 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.18 ms /   174 tokens (    5.17 ms per token,   193.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.75 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.15 ms /   177 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     944.19 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     549.89 ms /   106 tokens (    5.19 ms per token,   192.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.72 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1984.40 ms /   354 tokens (    5.61 ms per token,   178.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1996.59 ms /   355 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1157.53 ms /   216 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1165.90 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1232.44 ms /   220 tokens (    5.60 ms per token,   178.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.10 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      37.95 ms /     2 tokens (   18.98 ms per token,    52.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.28 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1250.59 ms /   229 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.41 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     481.13 ms /    94 tokens (    5.12 ms per token,   195.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     486.42 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1331.33 ms /   238 tokens (    5.59 ms per token,   178.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1341.93 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     498.10 ms /    90 tokens (    5.53 ms per token,   180.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     503.59 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.64 ms /   137 tokens (    5.41 ms per token,   184.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     748.27 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.70 ms /   197 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1067.07 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.10 ms /   156 tokens (    5.33 ms per token,   187.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     841.58 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1218.41 ms /   224 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1227.17 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     435.58 ms /    84 tokens (    5.19 ms per token,   192.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     441.62 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1292.34 ms /   236 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1302.41 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     709.63 ms /   118 tokens (    6.01 ms per token,   166.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.88 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1642.24 ms /   232 tokens (    7.08 ms per token,   141.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1653.51 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.36 ms /   112 tokens (    5.03 ms per token,   198.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     570.32 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1244.87 ms /   225 tokens (    5.53 ms per token,   180.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.02 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.10 ms /   145 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     776.26 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.27 ms /   176 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     951.04 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.35 ms /   154 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.73 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.60 ms /   191 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.03 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1183.32 ms /   220 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.53 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.33 ms /   166 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.70 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1423.30 ms /   254 tokens (    5.60 ms per token,   178.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1433.95 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     333.37 ms /    59 tokens (    5.65 ms per token,   176.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     337.63 ms /    60 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 69/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1257.54 ms /   233 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1267.18 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.05 ms /   196 tokens (    5.61 ms per token,   178.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.94 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.07 ms /   104 tokens (    5.58 ms per token,   179.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     586.57 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.16 ms /   126 tokens (    5.10 ms per token,   196.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.22 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1106.22 ms /   210 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1114.84 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.57 ms /   202 tokens (    5.47 ms per token,   182.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.60 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1137.26 ms /   199 tokens (    5.71 ms per token,   174.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1150.19 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     640.74 ms /   120 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     647.76 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1126.59 ms /   211 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1135.73 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.33 ms /   156 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.47 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.11 ms /   195 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1032.64 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.75 ms /   169 tokens (    5.47 ms per token,   182.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.52 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1033.85 ms /   198 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1043.06 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.69 ms /   171 tokens (    5.53 ms per token,   180.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     953.98 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.75 ms /   183 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     956.95 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.92 ms /   142 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.08 ms /   143 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     610.57 ms /   117 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     617.23 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.49 ms /   140 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.42 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     503.27 ms /    95 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     509.92 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.45 ms /   142 tokens (    7.00 ms per token,   142.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.19 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1167.06 ms /   200 tokens (    5.84 ms per token,   171.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1176.10 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.46 ms /   170 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.86 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     418.63 ms /    80 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     423.65 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.51 ms /   181 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     965.94 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.49 ms /   187 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     987.00 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1427.12 ms /   260 tokens (    5.49 ms per token,   182.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.12 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.60 ms /   195 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.53 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.38 ms /   192 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.49 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     269.63 ms /    37 tokens (    7.29 ms per token,   137.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.91 ms /    38 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.28 ms /   210 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1114.34 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     453.49 ms /    79 tokens (    5.74 ms per token,   174.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     459.25 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.57 ms /   133 tokens (    5.34 ms per token,   187.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     718.48 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1192.83 ms /   201 tokens (    5.93 ms per token,   168.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1202.41 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.53 ms /    98 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     531.57 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.79 ms /   174 tokens (    5.17 ms per token,   193.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     907.91 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.74 ms /   185 tokens (    5.18 ms per token,   193.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     965.72 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.79 ms /   168 tokens (    5.12 ms per token,   195.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.94 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.03 ms /   196 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.72 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     569.10 ms /   101 tokens (    5.63 ms per token,   177.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     576.62 ms /   102 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 71/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.15 ms /   179 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.42 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.34 ms /   166 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     907.18 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     857.40 ms /   163 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.15 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.76 ms /   152 tokens (    5.14 ms per token,   194.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     788.01 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.01 ms /   189 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.40 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.19 ms /   151 tokens (    5.19 ms per token,   192.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     793.22 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.54 ms /   110 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.30 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1032.98 ms /   193 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1041.45 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1173.55 ms /   210 tokens (    5.59 ms per token,   178.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.95 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.89 ms /   165 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.65 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.10 ms /   181 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.61 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     429.15 ms /    84 tokens (    5.11 ms per token,   195.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     434.27 ms /    85 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.40 ms /   147 tokens (    5.18 ms per token,   193.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.65 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.75 ms /   154 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     829.62 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      47.00 ms /     6 tokens (    7.83 ms per token,   127.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.79 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.05 ms /   201 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.34 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     410.49 ms /    67 tokens (    6.13 ms per token,   163.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     415.97 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.27 ms /   116 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     614.98 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.69 ms /   200 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.06 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     589.23 ms /   103 tokens (    5.72 ms per token,   174.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.03 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.73 ms /   235 tokens (    6.89 ms per token,   145.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1628.87 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1155.89 ms /   195 tokens (    5.93 ms per token,   168.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1165.45 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.82 ms /   116 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     638.92 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     727.30 ms /   139 tokens (    5.23 ms per token,   191.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     734.17 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.64 ms /   147 tokens (    5.13 ms per token,   195.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.71 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.10 ms /   159 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     828.11 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.72 ms /   188 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     974.94 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     419.49 ms /    80 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     427.31 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.32 ms /   167 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     906.95 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.11 ms /   183 tokens (    5.10 ms per token,   196.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.67 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.97 ms /   192 tokens (    5.17 ms per token,   193.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.69 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.40 ms /   158 tokens (    5.60 ms per token,   178.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     892.17 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.22 ms /   157 tokens (    5.13 ms per token,   194.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     812.79 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.62 ms /   120 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     648.19 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     376.14 ms /    78 tokens (    4.82 ms per token,   207.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.10 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.72 ms /   143 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     772.55 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     501.35 ms /   100 tokens (    5.01 ms per token,   199.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     506.83 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.74 ms /   226 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.20 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     294.54 ms /    57 tokens (    5.17 ms per token,   193.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.15 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.66 ms /   151 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.51 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     648.33 ms /   131 tokens (    4.95 ms per token,   202.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     656.52 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.65 ms /   143 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     767.70 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.69 ms /   199 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.13 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     443.56 ms /    74 tokens (    5.99 ms per token,   166.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     456.07 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.63 ms /   238 tokens (    5.20 ms per token,   192.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.35 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.66 ms /   145 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     784.01 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.36 ms /   153 tokens (    5.07 ms per token,   197.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.81 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     474.46 ms /    89 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     480.58 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1151.11 ms /   213 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.68 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1297.08 ms /   222 tokens (    5.84 ms per token,   171.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.44 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.94 ms /   214 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1143.57 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     333.99 ms /    52 tokens (    6.42 ms per token,   155.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.57 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.50 ms /   150 tokens (    6.97 ms per token,   143.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.33 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1257.44 ms /   221 tokens (    5.69 ms per token,   175.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1273.06 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     568.23 ms /   110 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     575.40 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     498.54 ms /    98 tokens (    5.09 ms per token,   196.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     505.43 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.06 ms /   183 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     982.17 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     628.66 ms /   119 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.89 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1359.68 ms /   251 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1369.40 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.74 ms /   197 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1055.24 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      66.34 ms /     2 tokens (   33.17 ms per token,    30.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      70.57 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.53 ms /   203 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1088.89 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     346.02 ms /    56 tokens (    6.18 ms per token,   161.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     353.71 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     519.86 ms /   102 tokens (    5.10 ms per token,   196.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     525.87 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.84 ms /   176 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     938.94 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1294.07 ms /   222 tokens (    5.83 ms per token,   171.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1303.25 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     458.94 ms /    80 tokens (    5.74 ms per token,   174.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     463.99 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     654.39 ms /   131 tokens (    5.00 ms per token,   200.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     661.27 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.81 ms /   175 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     931.06 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1157.50 ms /   212 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1167.03 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.22 ms /   175 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.52 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1251.11 ms /   230 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1259.79 ms /   231 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 73/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     850.51 ms /   167 tokens (    5.09 ms per token,   196.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     859.11 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.74 ms /   147 tokens (    5.32 ms per token,   187.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     790.14 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1172.70 ms /   215 tokens (    5.45 ms per token,   183.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1181.19 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.50 ms /   101 tokens (    5.78 ms per token,   173.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     589.43 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      55.01 ms /     6 tokens (    9.17 ms per token,   109.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      57.42 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1217.90 ms /   221 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1226.91 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     425.43 ms /    75 tokens (    5.67 ms per token,   176.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     430.02 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.48 ms /   195 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.70 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.42 ms /   151 tokens (    5.00 ms per token,   200.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.93 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     555.25 ms /    98 tokens (    5.67 ms per token,   176.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     560.59 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.57 ms /   212 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.91 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      74.20 ms /     6 tokens (   12.37 ms per token,    80.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      79.19 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.17 ms /   203 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1100.35 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     535.91 ms /    96 tokens (    5.58 ms per token,   179.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     544.26 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.93 ms /   155 tokens (    5.01 ms per token,   199.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     784.61 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.84 ms /   153 tokens (    5.15 ms per token,   194.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.06 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.36 ms /   115 tokens (    5.40 ms per token,   185.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.37 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     606.20 ms /   118 tokens (    5.14 ms per token,   194.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     612.52 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.27 ms /   169 tokens (    5.08 ms per token,   196.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     867.22 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     666.22 ms /   122 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     672.38 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1034.12 ms /   198 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1042.99 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     404.90 ms /    80 tokens (    5.06 ms per token,   197.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     411.38 ms /    81 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.52 ms /   132 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     699.30 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.68 ms /   192 tokens (    5.91 ms per token,   169.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.71 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     341.64 ms /    53 tokens (    6.45 ms per token,   155.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.81 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      93.56 ms /     5 tokens (   18.71 ms per token,    53.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      96.94 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1342.89 ms /   191 tokens (    7.03 ms per token,   142.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1352.87 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.67 ms /   105 tokens (    6.66 ms per token,   150.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     706.26 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1338.60 ms /   246 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1347.89 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1232.93 ms /   234 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.27 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1463.04 ms /   242 tokens (    6.05 ms per token,   165.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1473.25 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     483.98 ms /    97 tokens (    4.99 ms per token,   200.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     489.95 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.54 ms /   170 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     903.77 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.11 ms /   143 tokens (    5.52 ms per token,   181.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     797.06 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.35 ms /   217 tokens (    5.43 ms per token,   184.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1186.05 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      60.02 ms /    10 tokens (    6.00 ms per token,   166.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      62.77 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.44 ms /   207 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.45 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     212.37 ms /    43 tokens (    4.94 ms per token,   202.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     216.15 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     531.65 ms /    90 tokens (    5.91 ms per token,   169.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     540.63 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.36 ms /   176 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     929.13 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.04 ms /   196 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1038.44 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.57 ms /   159 tokens (    5.63 ms per token,   177.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     901.92 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1353.94 ms /   246 tokens (    5.50 ms per token,   181.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1363.38 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1331.31 ms /   241 tokens (    5.52 ms per token,   181.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1346.50 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     649.59 ms /   117 tokens (    5.55 ms per token,   180.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     656.55 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.48 ms /   140 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.43 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1033.40 ms /   197 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1041.84 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     358.51 ms /    65 tokens (    5.52 ms per token,   181.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.81 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.80 ms /   177 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.97 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.28 ms /   142 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.63 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     714.07 ms /   142 tokens (    5.03 ms per token,   198.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.60 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1222.94 ms /   226 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.43 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.38 ms /   156 tokens (    4.94 ms per token,   202.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.60 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1261.36 ms /   172 tokens (    7.33 ms per token,   136.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1269.07 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     693.03 ms /   138 tokens (    5.02 ms per token,   199.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.22 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1263.45 ms /   228 tokens (    5.54 ms per token,   180.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1273.62 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     419.85 ms /    85 tokens (    4.94 ms per token,   202.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     426.28 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     870.14 ms /   163 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     877.80 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1296.28 ms /   242 tokens (    5.36 ms per token,   186.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.12 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1086.93 ms /   201 tokens (    5.41 ms per token,   184.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1094.71 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.83 ms /   187 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.71 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.65 ms /   171 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     925.75 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.25 ms /   156 tokens (    5.37 ms per token,   186.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     844.54 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1392.92 ms /   248 tokens (    5.62 ms per token,   178.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1402.18 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1436.34 ms /   260 tokens (    5.52 ms per token,   181.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1446.68 ms /   261 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.80 ms /   185 tokens (    5.13 ms per token,   194.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     956.81 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.08 ms /   203 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1059.13 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1234.85 ms /   223 tokens (    5.54 ms per token,   180.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.44 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.57 ms /   212 tokens (    5.68 ms per token,   176.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.79 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1122.60 ms /   211 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1131.60 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.87 ms /   185 tokens (    5.46 ms per token,   183.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.24 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.64 ms /   175 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     948.65 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.21 ms /   207 tokens (    5.51 ms per token,   181.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1148.92 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.68 ms /   192 tokens (    5.73 ms per token,   174.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1108.59 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1335.81 ms /   238 tokens (    5.61 ms per token,   178.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1344.94 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.98 ms /   165 tokens (    5.01 ms per token,   199.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     835.30 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.53 ms /   215 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1140.85 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1225.57 ms /   224 tokens (    5.47 ms per token,   182.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1235.57 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     650.90 ms /   131 tokens (    4.97 ms per token,   201.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     657.46 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.27 ms /   224 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.15 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.85 ms /   177 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.92 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1250.19 ms /   231 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.51 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1578.32 ms /   289 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1588.36 ms /   290 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1325.21 ms /   242 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1334.63 ms /   243 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     476.50 ms /    95 tokens (    5.02 ms per token,   199.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     482.06 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1237.32 ms /   227 tokens (    5.45 ms per token,   183.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.43 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     367.57 ms /    64 tokens (    5.74 ms per token,   174.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     373.38 ms /    65 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 74/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1000.24 ms /   188 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1009.77 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.47 ms /   101 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     543.18 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1316.53 ms /   190 tokens (    6.93 ms per token,   144.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1326.41 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.31 ms /    88 tokens (    6.79 ms per token,   147.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.96 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      51.76 ms /     4 tokens (   12.94 ms per token,    77.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.90 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1094.90 ms /   198 tokens (    5.53 ms per token,   180.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1103.97 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.00 ms /    51 tokens (    6.84 ms per token,   146.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     353.14 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.55 ms /    85 tokens (    5.11 ms per token,   195.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     443.71 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     944.30 ms /   180 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     953.58 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.47 ms /   177 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.10 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     224.19 ms /    46 tokens (    4.87 ms per token,   205.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.09 ms /    47 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     925.58 ms /   176 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.24 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.79 ms /   132 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     706.91 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     438.02 ms /    89 tokens (    4.92 ms per token,   203.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     443.36 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1121.12 ms /   210 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1130.33 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.22 ms /   133 tokens (    5.82 ms per token,   171.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.11 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.25 ms /   183 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.59 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.29 ms /   183 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     976.08 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.87 ms /   192 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.84 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.99 ms /   181 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     960.75 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     781.41 ms /   149 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     788.52 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.98 ms /   142 tokens (    5.05 ms per token,   198.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     723.51 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     547.32 ms /   106 tokens (    5.16 ms per token,   193.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     553.83 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.15 ms /   201 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1074.33 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     581.32 ms /   108 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.25 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     617.44 ms /   124 tokens (    4.98 ms per token,   200.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     624.12 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.11 ms /   174 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.86 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     474.78 ms /    92 tokens (    5.16 ms per token,   193.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     480.60 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.61 ms /   172 tokens (    5.03 ms per token,   198.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     873.55 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     314.12 ms /    56 tokens (    5.61 ms per token,   178.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.31 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.53 ms /   204 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1078.62 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     273.23 ms /    45 tokens (    6.07 ms per token,   164.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     279.95 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.29 ms /   103 tokens (    6.44 ms per token,   155.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     669.41 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     777.09 ms /   116 tokens (    6.70 ms per token,   149.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     785.65 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.20 ms /   150 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     813.51 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.60 ms /   148 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     797.99 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.64 ms /   189 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.98 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.76 ms /   191 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.11 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.81 ms /   192 tokens (    5.36 ms per token,   186.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1038.90 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     380.79 ms /    56 tokens (    6.80 ms per token,   147.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     387.12 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.79 ms /    86 tokens (    6.75 ms per token,   148.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     586.29 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.55 ms /   134 tokens (    6.74 ms per token,   148.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.40 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.28 ms /   153 tokens (    6.49 ms per token,   154.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.32 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.17 ms /   160 tokens (    6.64 ms per token,   150.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1070.21 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.02 ms /   185 tokens (    6.11 ms per token,   163.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1138.74 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.59 ms /   168 tokens (    5.55 ms per token,   180.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.31 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.67 ms /   197 tokens (    5.39 ms per token,   185.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.25 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1414.17 ms /   221 tokens (    6.40 ms per token,   156.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.65 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.94 ms /   198 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.97 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.31 ms /   121 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     651.68 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     959.74 ms /   184 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     967.64 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     315.67 ms /    59 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     319.96 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     796.07 ms /   156 tokens (    5.10 ms per token,   195.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     804.63 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     532.90 ms /    99 tokens (    5.38 ms per token,   185.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     540.14 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.93 ms /   178 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     946.89 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     971.38 ms /   188 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     979.35 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.05 ms /   144 tokens (    5.01 ms per token,   199.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     729.52 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.44 ms /   191 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1002.86 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.62 ms /   107 tokens (    5.65 ms per token,   176.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     610.93 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.65 ms /   124 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     645.03 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1276.83 ms /   235 tokens (    5.43 ms per token,   184.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1286.07 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.92 ms /   203 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.01 ms /   204 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 75/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     545.24 ms /    94 tokens (    5.80 ms per token,   172.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     552.24 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.74 ms /    78 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.14 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1050.15 ms /   200 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.22 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     268.88 ms /    45 tokens (    5.98 ms per token,   167.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     275.74 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     575.02 ms /   108 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     581.46 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1436.25 ms /   254 tokens (    5.65 ms per token,   176.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1446.69 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     487.47 ms /    91 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     492.73 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.39 ms /   204 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.87 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.00 ms /   161 tokens (    5.80 ms per token,   172.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     944.65 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1057.37 ms /   160 tokens (    6.61 ms per token,   151.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1067.04 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.28 ms /   118 tokens (    5.38 ms per token,   185.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     645.04 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2953.06 ms /   486 tokens (    6.08 ms per token,   164.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2968.47 ms /   487 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     998.56 ms /   190 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.38 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1229.60 ms /   214 tokens (    5.75 ms per token,   174.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.59 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1495.82 ms /   206 tokens (    7.26 ms per token,   137.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1504.84 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1075.96 ms /   194 tokens (    5.55 ms per token,   180.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1085.73 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     750.66 ms /   137 tokens (    5.48 ms per token,   182.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     758.43 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1119.55 ms /   209 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1128.40 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.26 ms /   128 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.84 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     540.27 ms /   104 tokens (    5.19 ms per token,   192.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     546.52 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1106.76 ms /   210 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1115.73 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.21 ms /   125 tokens (    5.54 ms per token,   180.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.87 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     634.20 ms /   125 tokens (    5.07 ms per token,   197.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     640.81 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1126.33 ms /   195 tokens (    5.78 ms per token,   173.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1136.01 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.23 ms /   148 tokens (    5.20 ms per token,   192.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     777.24 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     327.48 ms /    59 tokens (    5.55 ms per token,   180.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     331.98 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1055.07 ms /   195 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1064.91 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.25 ms /   148 tokens (    5.48 ms per token,   182.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     820.35 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.71 ms /   110 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.77 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.95 ms /   197 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1055.72 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.53 ms /   181 tokens (    5.50 ms per token,   181.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1005.12 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.20 ms /    95 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     522.15 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.23 ms /   164 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.95 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     533.36 ms /   101 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     539.02 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.86 ms /   127 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     663.07 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.87 ms /   175 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     930.13 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     711.37 ms /   138 tokens (    5.15 ms per token,   193.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     718.59 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.28 ms /   116 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     632.85 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1092.02 ms /   171 tokens (    6.39 ms per token,   156.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.85 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     513.67 ms /    74 tokens (    6.94 ms per token,   144.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     520.80 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.82 ms /   145 tokens (    5.10 ms per token,   195.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.16 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     476.52 ms /    85 tokens (    5.61 ms per token,   178.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     481.63 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.46 ms /   135 tokens (    5.09 ms per token,   196.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.22 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     511.76 ms /    95 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     517.21 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.21 ms /   186 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.63 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.29 ms /   172 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     909.20 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.16 ms /   180 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.30 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.60 ms /   120 tokens (    5.08 ms per token,   196.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     616.85 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      38.62 ms /     3 tokens (   12.87 ms per token,    77.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      41.91 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1179.27 ms /   212 tokens (    5.56 ms per token,   179.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1189.59 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.15 ms /    65 tokens (    5.37 ms per token,   186.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     354.52 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     173.31 ms /    32 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     178.10 ms /    33 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      35.22 ms /     3 tokens (   11.74 ms per token,    85.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.77 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1296.79 ms /   221 tokens (    5.87 ms per token,   170.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1305.86 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     328.81 ms /    59 tokens (    5.57 ms per token,   179.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     333.15 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.28 ms /   146 tokens (    5.17 ms per token,   193.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     764.44 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1183.35 ms /   220 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1192.13 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     224.35 ms /    41 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     228.31 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      36.05 ms /     3 tokens (   12.02 ms per token,    83.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      38.82 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.35 ms /   203 tokens (    5.36 ms per token,   186.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1095.89 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.72 ms /   134 tokens (    5.64 ms per token,   177.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.56 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     216.62 ms /    43 tokens (    5.04 ms per token,   198.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.70 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     693.57 ms /   132 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.18 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     620.91 ms /   125 tokens (    4.97 ms per token,   201.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.96 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      34.19 ms /     3 tokens (   11.40 ms per token,    87.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.06 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.17 ms /   196 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1047.88 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     510.07 ms /    86 tokens (    5.93 ms per token,   168.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     516.98 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.70 ms /   157 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.71 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.15 ms /   154 tokens (    5.09 ms per token,   196.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     792.28 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     996.03 ms /   191 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.83 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.60 ms /   119 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     640.55 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1079.96 ms /   200 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1089.71 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1098.48 ms /   199 tokens (    5.52 ms per token,   181.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.95 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1184.54 ms /   209 tokens (    5.67 ms per token,   176.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.91 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     972.27 ms /   188 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.26 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1273.21 ms /   234 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1282.98 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     569.61 ms /   107 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     576.66 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     652.97 ms /   125 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     659.25 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.74 ms /   148 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.75 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     605.27 ms /   120 tokens (    5.04 ms per token,   198.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     613.07 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1295.43 ms /   239 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1304.74 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.31 ms /   136 tokens (    5.39 ms per token,   185.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     739.87 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     650.51 ms /   123 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     656.82 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.40 ms /   161 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.06 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     712.62 ms /   142 tokens (    5.02 ms per token,   199.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.88 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.51 ms /   156 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     867.57 ms /   157 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 77/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1298.18 ms /   221 tokens (    5.87 ms per token,   170.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1308.67 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     342.17 ms /    45 tokens (    7.60 ms per token,   131.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     349.70 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.83 ms /   216 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1174.13 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.88 ms /   137 tokens (    5.53 ms per token,   180.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     764.26 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     623.24 ms /   118 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     630.63 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.37 ms /   110 tokens (    5.32 ms per token,   187.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.05 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.27 ms /   196 tokens (    5.59 ms per token,   178.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.55 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     439.93 ms /    86 tokens (    5.12 ms per token,   195.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     444.99 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1303.27 ms /   197 tokens (    6.62 ms per token,   151.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1312.21 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     169.55 ms /    23 tokens (    7.37 ms per token,   135.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     173.96 ms /    24 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      42.40 ms /     2 tokens (   21.20 ms per token,    47.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      45.62 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1285.25 ms /   200 tokens (    6.43 ms per token,   155.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.21 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1115.43 ms /   210 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.57 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.81 ms /   111 tokens (    5.70 ms per token,   175.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     642.46 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1199.65 ms /   220 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.52 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.54 ms /   164 tokens (    6.11 ms per token,   163.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1009.12 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1260.40 ms /   208 tokens (    6.06 ms per token,   165.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1270.52 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.83 ms /   167 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     883.44 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      35.39 ms /     3 tokens (   11.80 ms per token,    84.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      37.68 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.87 ms /   216 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1172.96 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1186.03 ms /   221 tokens (    5.37 ms per token,   186.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.67 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.33 ms /   149 tokens (    5.43 ms per token,   184.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     820.87 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.44 ms /   189 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     995.12 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     356.29 ms /    62 tokens (    5.75 ms per token,   174.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     360.63 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.92 ms /   196 tokens (    5.12 ms per token,   195.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.72 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     331.93 ms /    48 tokens (    6.92 ms per token,   144.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     339.00 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.26 ms /    98 tokens (    5.48 ms per token,   182.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     543.08 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1114.53 ms /   208 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.76 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     358.27 ms /    69 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.80 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.09 ms /   196 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.02 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     966.31 ms /   178 tokens (    5.43 ms per token,   184.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     975.17 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1409.45 ms /   203 tokens (    6.94 ms per token,   144.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1418.39 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     497.32 ms /    91 tokens (    5.47 ms per token,   182.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     504.60 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     983.91 ms /   190 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     991.95 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.72 ms /   191 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.87 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1254.66 ms /   226 tokens (    5.55 ms per token,   180.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1265.01 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     417.16 ms /    83 tokens (    5.03 ms per token,   198.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     422.90 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.41 ms /   121 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.65 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.90 ms /   113 tokens (    5.11 ms per token,   195.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     582.88 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1182.23 ms /   221 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.08 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.48 ms /   134 tokens (    5.12 ms per token,   195.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.62 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.43 ms /   178 tokens (    5.88 ms per token,   170.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1054.83 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1180.12 ms /   209 tokens (    5.65 ms per token,   177.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1192.57 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     373.59 ms /    71 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.73 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.35 ms /   188 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.19 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     284.41 ms /    55 tokens (    5.17 ms per token,   193.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     289.06 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1131.09 ms /   206 tokens (    5.49 ms per token,   182.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.62 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1127.32 ms /   209 tokens (    5.39 ms per token,   185.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1136.27 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.27 ms /    82 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     440.87 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      36.55 ms /     4 tokens (    9.14 ms per token,   109.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.38 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.59 ms /     5 tokens (    8.92 ms per token,   112.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.40 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1043.90 ms /   197 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1052.83 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.70 ms /   158 tokens (    5.55 ms per token,   180.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.04 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.27 ms /   133 tokens (    5.21 ms per token,   192.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     699.69 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     714.67 ms /   139 tokens (    5.14 ms per token,   194.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     722.08 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.39 ms /    73 tokens (    5.69 ms per token,   175.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.48 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1076.70 ms /   203 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1085.87 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.42 ms /    94 tokens (    6.76 ms per token,   147.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     642.63 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1066.91 ms /   203 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1075.90 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     332.47 ms /    54 tokens (    6.16 ms per token,   162.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.36 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.16 ms /   169 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.81 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.06 ms /   170 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     888.21 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     543.90 ms /   107 tokens (    5.08 ms per token,   196.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     550.34 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.53 ms /   128 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.12 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.01 ms /   164 tokens (    5.13 ms per token,   195.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     848.19 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     857.98 ms /   165 tokens (    5.20 ms per token,   192.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.71 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.01 ms /   161 tokens (    5.21 ms per token,   192.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.45 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.59 ms /   133 tokens (    5.33 ms per token,   187.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.35 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.68 ms /   213 tokens (    5.50 ms per token,   181.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.21 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.52 ms /   162 tokens (    5.34 ms per token,   187.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     873.31 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.85 ms /   187 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     983.56 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.62 ms /   125 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     684.21 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     528.98 ms /   105 tokens (    5.04 ms per token,   198.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     534.59 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     668.43 ms /   124 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     675.10 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     662.28 ms /   127 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     668.34 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.80 ms /   157 tokens (    5.16 ms per token,   193.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     817.24 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.90 ms /   166 tokens (    5.20 ms per token,   192.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     870.34 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     628.38 ms /   114 tokens (    5.51 ms per token,   181.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.74 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      84.08 ms /    15 tokens (    5.61 ms per token,   178.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      88.72 ms /    16 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.43 ms /   219 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1186.57 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.62 ms /   161 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     882.54 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     406.15 ms /    81 tokens (    5.01 ms per token,   199.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     411.15 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.69 ms /   174 tokens (    5.44 ms per token,   183.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.41 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.70 ms /   159 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.15 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.40 ms /   172 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     913.09 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     963.13 ms /   184 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.03 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     403.03 ms /    78 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     408.18 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1121.54 ms /   164 tokens (    6.84 ms per token,   146.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1129.63 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.28 ms /   156 tokens (    6.75 ms per token,   148.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.12 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.58 ms /   142 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.54 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.32 ms /   133 tokens (    5.52 ms per token,   181.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     742.12 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.53 ms /   158 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.29 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.61 ms /   177 tokens (    5.30 ms per token,   188.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     946.83 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.48 ms /   222 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.67 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.60 ms /   118 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     638.63 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.01 ms /   214 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.79 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.96 ms /    93 tokens (    5.57 ms per token,   179.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     523.44 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1061.83 ms /   185 tokens (    5.74 ms per token,   174.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.12 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     474.47 ms /    78 tokens (    6.08 ms per token,   164.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     479.82 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.98 ms /   174 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     913.94 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.25 ms /   176 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     930.78 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1113.28 ms /   209 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1123.44 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     447.05 ms /    85 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     455.13 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1234.40 ms /   218 tokens (    5.66 ms per token,   176.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1244.06 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.45 ms /   183 tokens (    5.53 ms per token,   180.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.03 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.99 ms /   113 tokens (    6.08 ms per token,   164.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.90 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1272.64 ms /   191 tokens (    6.66 ms per token,   150.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1283.36 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     679.79 ms /   128 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.94 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.33 ms /   159 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     838.41 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     327.59 ms /    65 tokens (    5.04 ms per token,   198.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.13 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.05 ms /   178 tokens (    5.39 ms per token,   185.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     968.09 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1000.40 ms /   187 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1008.75 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.98 ms /   182 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.71 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.29 ms /   181 tokens (    5.50 ms per token,   181.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.08 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.33 ms /   189 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.66 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.51 ms /   124 tokens (    6.32 ms per token,   158.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     791.89 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.95 ms /   141 tokens (    5.13 ms per token,   195.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     730.38 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.05 ms /   121 tokens (    5.13 ms per token,   194.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.64 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.84 ms /   123 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     662.00 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1621.43 ms /   293 tokens (    5.53 ms per token,   180.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1632.43 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1883.33 ms /   341 tokens (    5.52 ms per token,   181.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1895.07 ms /   342 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     297.33 ms /    54 tokens (    5.51 ms per token,   181.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     301.56 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1056.75 ms /   200 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1065.53 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1848.99 ms /   278 tokens (    6.65 ms per token,   150.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1861.13 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1770.64 ms /   308 tokens (    5.75 ms per token,   173.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1782.23 ms /   309 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.32 ms /   188 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.46 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1538.89 ms /   276 tokens (    5.58 ms per token,   179.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1560.67 ms /   277 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.62 ms /   236 tokens (    5.25 ms per token,   190.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1248.90 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1374.89 ms /   250 tokens (    5.50 ms per token,   181.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1387.02 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.18 ms /   189 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.67 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1347.72 ms /   245 tokens (    5.50 ms per token,   181.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1358.98 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.48 ms /   101 tokens (    6.19 ms per token,   161.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     631.32 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1306.79 ms /   238 tokens (    5.49 ms per token,   182.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1316.44 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.74 ms /   136 tokens (    5.12 ms per token,   195.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.67 ms /   137 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 78/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.78 ms /   135 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     747.58 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.95 ms /   104 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     544.22 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.24 ms /   158 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.14 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.63 ms /   162 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.13 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.88 ms /   199 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1089.59 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.23 ms /   117 tokens (    5.99 ms per token,   166.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     709.22 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.46 ms /   136 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.93 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.38 ms /   214 tokens (    5.64 ms per token,   177.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1216.32 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     730.07 ms /   142 tokens (    5.14 ms per token,   194.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     737.62 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1254.49 ms /   226 tokens (    5.55 ms per token,   180.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1263.15 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.37 ms /   175 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.45 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.59 ms /   157 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.91 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.83 ms /   172 tokens (    5.13 ms per token,   194.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     890.93 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.54 ms /   165 tokens (    5.16 ms per token,   193.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     860.08 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     458.72 ms /    87 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     464.33 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.91 ms /   163 tokens (    6.03 ms per token,   165.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     991.75 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.11 ms /   121 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     632.69 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.94 ms /   130 tokens (    5.58 ms per token,   179.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     732.94 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1385.04 ms /   199 tokens (    6.96 ms per token,   143.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1394.61 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.97 ms /   182 tokens (    6.52 ms per token,   153.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.88 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.06 ms /   197 tokens (    5.52 ms per token,   181.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1096.49 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.31 ms /    47 tokens (    6.43 ms per token,   155.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     307.44 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.36 ms /   185 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     968.71 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.64 ms /   156 tokens (    5.10 ms per token,   196.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     804.16 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1014.29 ms /   193 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1023.80 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1195.76 ms /   212 tokens (    5.64 ms per token,   177.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1205.51 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.14 ms /   189 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1003.39 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1164.41 ms /   212 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1173.04 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.50 ms /   206 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.08 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1143.42 ms /   205 tokens (    5.58 ms per token,   179.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.00 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.18 ms /   117 tokens (    5.88 ms per token,   170.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     694.28 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.95 ms /   131 tokens (    5.77 ms per token,   173.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.32 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.45 ms /   142 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.73 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1273.01 ms /   192 tokens (    6.63 ms per token,   150.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1281.43 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.80 ms /   147 tokens (    5.60 ms per token,   178.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     831.66 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     633.88 ms /   122 tokens (    5.20 ms per token,   192.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     640.93 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     423.55 ms /    77 tokens (    5.50 ms per token,   181.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     428.62 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1206.66 ms /   221 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1216.89 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.33 ms /   167 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     880.88 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.26 ms /   189 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     999.42 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.54 ms /   176 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     938.69 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1131.11 ms /   213 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1140.22 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.36 ms /   172 tokens (    5.81 ms per token,   172.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1009.59 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.06 ms /   160 tokens (    5.17 ms per token,   193.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     836.42 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.63 ms /   153 tokens (    5.17 ms per token,   193.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     799.18 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.20 ms /   159 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     846.65 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.46 ms /   167 tokens (    5.45 ms per token,   183.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.21 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     956.56 ms /   181 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     964.58 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     599.08 ms /   116 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     605.57 ms /   117 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.79 ms /   160 tokens (    5.80 ms per token,   172.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.83 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.31 ms /   167 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     882.16 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1183.94 ms /   216 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.32 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.58 ms /   177 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     938.53 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.85 ms /   178 tokens (    5.20 ms per token,   192.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     933.57 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1207.30 ms /   221 tokens (    5.46 ms per token,   183.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1217.98 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     293.82 ms /    53 tokens (    5.54 ms per token,   180.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     298.01 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     260.33 ms /    52 tokens (    5.01 ms per token,   199.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     264.69 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.87 ms /   172 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     930.64 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.49 ms /   184 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     973.79 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1120.28 ms /   207 tokens (    5.41 ms per token,   184.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1129.89 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.36 ms /   118 tokens (    5.45 ms per token,   183.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.58 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     492.20 ms /   100 tokens (    4.92 ms per token,   203.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     497.75 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1269.18 ms /   230 tokens (    5.52 ms per token,   181.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1280.93 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.23 ms /   143 tokens (    5.16 ms per token,   193.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     744.67 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.98 ms /   196 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.09 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.16 ms /   198 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.98 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1462.38 ms /   256 tokens (    5.71 ms per token,   175.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1474.06 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1110.00 ms /   190 tokens (    5.84 ms per token,   171.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.22 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     998.17 ms /   183 tokens (    5.45 ms per token,   183.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1005.99 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     314.58 ms /    64 tokens (    4.92 ms per token,   203.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     320.26 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.28 ms /   157 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.84 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     442.86 ms /    85 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     449.86 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1168.80 ms /   216 tokens (    5.41 ms per token,   184.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1178.51 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     309.71 ms /    58 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     313.93 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.11 ms /   168 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     888.10 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     622.06 ms /   122 tokens (    5.10 ms per token,   196.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     628.55 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.23 ms /   197 tokens (    5.29 ms per token,   189.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.90 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.41 ms /   180 tokens (    6.09 ms per token,   164.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1107.26 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.61 ms /   171 tokens (    5.52 ms per token,   181.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.40 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.52 ms /   184 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.75 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     975.93 ms /   190 tokens (    5.14 ms per token,   194.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     985.48 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1458.76 ms /   264 tokens (    5.53 ms per token,   180.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1468.28 ms /   265 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1227.53 ms /   232 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1236.39 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1792.73 ms /   320 tokens (    5.60 ms per token,   178.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1805.06 ms /   321 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.66 ms /   254 tokens (    6.65 ms per token,   150.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1697.79 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1166.61 ms /   189 tokens (    6.17 ms per token,   162.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1175.42 ms /   190 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 79/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1182.70 ms /   215 tokens (    5.50 ms per token,   181.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1192.58 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1411.23 ms /   255 tokens (    5.53 ms per token,   180.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1420.94 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1159.13 ms /   217 tokens (    5.34 ms per token,   187.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1168.92 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1452.80 ms /   256 tokens (    5.67 ms per token,   176.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.28 ms /   257 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1342.43 ms /   244 tokens (    5.50 ms per token,   181.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1354.21 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3007.20 ms /   495 tokens (    6.08 ms per token,   164.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    3023.68 ms /   496 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2045.89 ms /   316 tokens (    6.47 ms per token,   154.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2057.33 ms /   317 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1751.79 ms /   312 tokens (    5.61 ms per token,   178.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1762.37 ms /   313 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2086.66 ms /   368 tokens (    5.67 ms per token,   176.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2099.29 ms /   369 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1348.72 ms /   251 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1358.11 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.87 ms /   166 tokens (    5.73 ms per token,   174.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     961.29 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1174.44 ms /   198 tokens (    5.93 ms per token,   168.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.15 ms /   199 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.19 ms /   159 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.67 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     384.80 ms /    74 tokens (    5.20 ms per token,   192.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     389.98 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.80 ms /   208 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1146.28 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     480.38 ms /    92 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     489.20 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1102.45 ms /   201 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1111.94 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     270.71 ms /    45 tokens (    6.02 ms per token,   166.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     278.23 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.68 ms /   124 tokens (    5.76 ms per token,   173.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     720.86 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.27 ms /   181 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.27 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.82 ms /   192 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.28 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.49 ms /   157 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.13 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.70 ms /   199 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.77 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1187.82 ms /   218 tokens (    5.45 ms per token,   183.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1200.90 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.97 ms /   162 tokens (    5.45 ms per token,   183.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.55 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1057.26 ms /   196 tokens (    5.39 ms per token,   185.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1065.87 ms /   197 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 81/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1115.24 ms /   202 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1126.11 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     380.30 ms /    71 tokens (    5.36 ms per token,   186.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.24 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.44 ms /   190 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.07 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.77 ms /   139 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     741.40 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.80 ms /   170 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     930.62 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1266.20 ms /   209 tokens (    6.06 ms per token,   165.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.96 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.81 ms /   106 tokens (    5.79 ms per token,   172.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     619.93 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.92 ms /   191 tokens (    5.44 ms per token,   183.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1048.73 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.30 ms /   156 tokens (    6.07 ms per token,   164.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.71 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.42 ms /   158 tokens (    5.91 ms per token,   169.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     942.43 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      47.50 ms /     6 tokens (    7.92 ms per token,   126.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.31 ms /     7 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1385.92 ms /   253 tokens (    5.48 ms per token,   182.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1397.24 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     422.96 ms /    78 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     428.75 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.08 ms /    57 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     305.12 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1239.31 ms /   227 tokens (    5.46 ms per token,   183.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1251.13 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.53 ms /   131 tokens (    6.42 ms per token,   155.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     849.37 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1244.31 ms /   213 tokens (    5.84 ms per token,   171.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.99 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.70 ms /   148 tokens (    5.44 ms per token,   183.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     811.84 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.08 ms /   180 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     976.30 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1370.53 ms /   249 tokens (    5.50 ms per token,   181.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1381.43 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1545.89 ms /   255 tokens (    6.06 ms per token,   164.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1557.03 ms /   256 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.20 ms /   192 tokens (    5.30 ms per token,   188.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1027.65 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.21 ms /   136 tokens (    6.20 ms per token,   161.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.94 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.74 ms /   135 tokens (    6.90 ms per token,   144.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     940.46 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1524.46 ms /   220 tokens (    6.93 ms per token,   144.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1535.54 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1524.14 ms /   237 tokens (    6.43 ms per token,   155.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1534.91 ms /   238 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 82/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1308.74 ms /   240 tokens (    5.45 ms per token,   183.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1321.47 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1917.95 ms /   336 tokens (    5.71 ms per token,   175.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1933.36 ms /   337 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.49 ms /   130 tokens (    6.87 ms per token,   145.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     900.24 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.95 ms /   103 tokens (    6.69 ms per token,   149.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.04 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.32 ms /   138 tokens (    5.60 ms per token,   178.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.00 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.58 ms /   157 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     847.43 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.00 ms /   164 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.82 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.44 ms /   178 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.40 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.86 ms /   146 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.32 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.27 ms /   154 tokens (    5.13 ms per token,   194.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     797.55 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.87 ms /   182 tokens (    5.86 ms per token,   170.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1075.22 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1364.02 ms /   228 tokens (    5.98 ms per token,   167.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1378.23 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     444.26 ms /    60 tokens (    7.40 ms per token,   135.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     451.39 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.67 ms /   164 tokens (    6.13 ms per token,   163.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.32 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1392.19 ms /   201 tokens (    6.93 ms per token,   144.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1402.13 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.76 ms /   197 tokens (    5.50 ms per token,   181.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.90 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.17 ms /   145 tokens (    5.80 ms per token,   172.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.72 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1516.69 ms /   194 tokens (    7.82 ms per token,   127.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1526.54 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1701.67 ms /   218 tokens (    7.81 ms per token,   128.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1714.12 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1204.92 ms /   156 tokens (    7.72 ms per token,   129.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1213.96 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2381.49 ms /   308 tokens (    7.73 ms per token,   129.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2395.14 ms /   309 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.15 ms /    75 tokens (    7.35 ms per token,   136.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     557.16 ms /    76 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 84/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     244.12 ms /    33 tokens (    7.40 ms per token,   135.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.31 ms /    34 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1237.12 ms /   173 tokens (    7.15 ms per token,   139.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1246.18 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1508.57 ms /   195 tokens (    7.74 ms per token,   129.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1518.77 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.78 ms /   190 tokens (    5.54 ms per token,   180.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.25 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.21 ms /   160 tokens (    5.67 ms per token,   176.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.42 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.50 ms /   145 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     796.76 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1200.24 ms /   208 tokens (    5.77 ms per token,   173.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.64 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.31 ms /   169 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.16 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.14 ms /   185 tokens (    5.62 ms per token,   178.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1047.67 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.38 ms /   147 tokens (    5.94 ms per token,   168.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.04 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.11 ms /   123 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     662.02 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.48 ms /   188 tokens (    5.58 ms per token,   179.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.86 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.56 ms /   110 tokens (    5.86 ms per token,   170.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     651.58 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1290.25 ms /   234 tokens (    5.51 ms per token,   181.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.28 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.85 ms /   186 tokens (    5.47 ms per token,   182.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.27 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     963.10 ms /   157 tokens (    6.13 ms per token,   163.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     972.97 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1135.53 ms /   205 tokens (    5.54 ms per token,   180.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1146.16 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     320.81 ms /    62 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     326.29 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.29 ms /   146 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.36 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1211.62 ms /   216 tokens (    5.61 ms per token,   178.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1222.36 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     543.35 ms /   101 tokens (    5.38 ms per token,   185.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     549.51 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     319.91 ms /    61 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     324.30 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      37.48 ms /     3 tokens (   12.49 ms per token,    80.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      40.09 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1244.80 ms /   224 tokens (    5.56 ms per token,   179.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.75 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     285.53 ms /    54 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     290.83 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.77 ms /   178 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.13 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1056.30 ms /   195 tokens (    5.42 ms per token,   184.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1065.78 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1158.04 ms /   195 tokens (    5.94 ms per token,   168.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1170.42 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      87.70 ms /     8 tokens (   10.96 ms per token,    91.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      91.20 ms /     9 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.15 ms /   219 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.32 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.52 ms /   128 tokens (    5.64 ms per token,   177.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     728.91 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.04 ms /   208 tokens (    5.45 ms per token,   183.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.17 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     337.06 ms /    54 tokens (    6.24 ms per token,   160.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     342.70 ms /    55 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      51.91 ms /     5 tokens (   10.38 ms per token,    96.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      54.62 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1232.80 ms /   226 tokens (    5.45 ms per token,   183.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.86 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.23 ms /   166 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     895.65 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.63 ms /   170 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.94 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.50 ms /   168 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.13 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     750.75 ms /   139 tokens (    5.40 ms per token,   185.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     757.82 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.19 ms /   147 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     782.28 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1044.64 ms /   189 tokens (    5.53 ms per token,   180.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1053.75 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1364.92 ms /   216 tokens (    6.32 ms per token,   158.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1375.69 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.06 ms /   181 tokens (    5.49 ms per token,   182.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1002.88 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      57.81 ms /     5 tokens (   11.56 ms per token,    86.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      61.72 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1224.56 ms /   216 tokens (    5.67 ms per token,   176.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1234.33 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.64 ms /    97 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.01 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     445.65 ms /    86 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.03 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.40 ms /   170 tokens (    5.81 ms per token,   171.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.52 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1136.15 ms /   167 tokens (    6.80 ms per token,   146.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1144.14 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.03 ms /    93 tokens (    7.23 ms per token,   138.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     678.07 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1277.56 ms /   208 tokens (    6.14 ms per token,   162.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1287.35 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1153.95 ms /   210 tokens (    5.50 ms per token,   181.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.54 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.00 ms /   146 tokens (    5.48 ms per token,   182.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     806.94 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     619.46 ms /   113 tokens (    5.48 ms per token,   182.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     625.46 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.50 ms /   150 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     806.10 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.53 ms /   167 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.69 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.64 ms /   169 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     901.58 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.49 ms /   158 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     834.82 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1550.65 ms /   224 tokens (    6.92 ms per token,   144.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1561.20 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.83 ms /   175 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.23 ms /   176 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 86/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     320.05 ms /    59 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     325.81 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     401.09 ms /    75 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     406.47 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.30 ms /   170 tokens (    5.15 ms per token,   194.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.89 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.07 ms /   107 tokens (    5.46 ms per token,   183.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     591.50 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.43 ms /   132 tokens (    5.16 ms per token,   193.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.89 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     645.45 ms /   124 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     652.13 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.12 ms /   194 tokens (    5.90 ms per token,   169.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.79 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.64 ms /    87 tokens (    5.95 ms per token,   168.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     523.60 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.86 ms /   161 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.08 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     472.39 ms /    89 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     477.51 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1284.24 ms /   233 tokens (    5.51 ms per token,   181.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1294.18 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     528.61 ms /    97 tokens (    5.45 ms per token,   183.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     534.11 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1215.35 ms /   224 tokens (    5.43 ms per token,   184.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.48 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.09 ms /   186 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     987.16 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.36 ms /   162 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     862.91 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.13 ms /   193 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.09 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.81 ms /   194 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1026.77 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.47 ms /   151 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     835.87 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.17 ms /   170 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.98 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.44 ms /   164 tokens (    5.06 ms per token,   197.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     837.46 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     586.34 ms /   111 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.24 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.11 ms /   152 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     792.46 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.25 ms /   137 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     710.31 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.80 ms /   192 tokens (    5.15 ms per token,   194.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     997.83 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1191.26 ms /   217 tokens (    5.49 ms per token,   182.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.67 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.10 ms /   135 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.39 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     145.76 ms /    28 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.36 ms /    29 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 87/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.13 ms /   143 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     757.14 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1382.89 ms /   251 tokens (    5.51 ms per token,   181.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1393.35 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.40 ms /   108 tokens (    6.35 ms per token,   157.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     692.71 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.88 ms /   158 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     819.04 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.16 ms /   171 tokens (    5.42 ms per token,   184.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.03 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1247.26 ms /   224 tokens (    5.57 ms per token,   179.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1257.73 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.62 ms /   167 tokens (    5.17 ms per token,   193.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     872.27 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.26 ms /   173 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.01 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.52 ms /   173 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     919.22 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     363.57 ms /    69 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.07 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.56 ms /   160 tokens (    5.04 ms per token,   198.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     814.90 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.28 ms /   148 tokens (    5.35 ms per token,   187.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.31 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     448.75 ms /    85 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     453.79 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.11 ms /   156 tokens (    5.10 ms per token,   196.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.56 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.81 ms /   168 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     900.46 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     545.17 ms /   100 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     552.35 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1145.06 ms /   209 tokens (    5.48 ms per token,   182.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1155.82 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.24 ms /   171 tokens (    5.44 ms per token,   183.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.96 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1079.37 ms /   206 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1088.07 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     420.59 ms /    77 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     425.40 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.33 ms /   192 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.51 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.27 ms /   210 tokens (    5.81 ms per token,   172.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1230.63 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.21 ms /    94 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     501.02 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.65 ms /   193 tokens (    5.39 ms per token,   185.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1048.62 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     440.31 ms /    78 tokens (    5.65 ms per token,   177.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     446.83 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.22 ms /   153 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.57 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.70 ms /   135 tokens (    5.46 ms per token,   183.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     744.43 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1218.20 ms /   226 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1227.04 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     550.45 ms /    96 tokens (    5.73 ms per token,   174.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     555.99 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.55 ms /   162 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     851.68 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1083.17 ms /   202 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.87 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1562.81 ms /   278 tokens (    5.62 ms per token,   177.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1573.54 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.21 ms /   167 tokens (    5.26 ms per token,   189.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.85 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1777.74 ms /   278 tokens (    6.39 ms per token,   156.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1788.13 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1932.34 ms /   289 tokens (    6.69 ms per token,   149.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1943.11 ms /   290 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2243.60 ms /   385 tokens (    5.83 ms per token,   171.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2257.23 ms /   386 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.47 ms /   134 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     707.21 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2025.72 ms /   312 tokens (    6.49 ms per token,   154.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2037.35 ms /   313 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1454.12 ms /   262 tokens (    5.55 ms per token,   180.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1464.50 ms /   263 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.29 ms /   143 tokens (    5.33 ms per token,   187.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.52 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1280.68 ms /   228 tokens (    5.62 ms per token,   178.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1290.35 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     381.30 ms /    66 tokens (    5.78 ms per token,   173.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.89 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1411.30 ms /   234 tokens (    6.03 ms per token,   165.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1421.14 ms /   235 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1147.40 ms /   210 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1155.77 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1427.61 ms /   257 tokens (    5.55 ms per token,   180.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.31 ms /   258 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.42 ms /   186 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.26 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.20 ms /   136 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     732.23 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     579.54 ms /   108 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     585.70 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1098.60 ms /   208 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.42 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     374.42 ms /    52 tokens (    7.20 ms per token,   138.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     381.59 ms /    53 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.10 ms /   138 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     740.48 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.89 ms /   157 tokens (    5.20 ms per token,   192.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.30 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     492.95 ms /    97 tokens (    5.08 ms per token,   196.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     498.79 ms /    98 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.36 ms /   198 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.68 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.27 ms /   144 tokens (    5.56 ms per token,   179.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     808.25 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.50 ms /   170 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     921.12 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1302.58 ms /   237 tokens (    5.50 ms per token,   181.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1313.56 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     606.91 ms /   111 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     612.77 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1075.55 ms /   203 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1084.69 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     449.46 ms /    82 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     456.04 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1346.74 ms /   245 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1357.44 ms /   246 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1218.62 ms /   222 tokens (    5.49 ms per token,   182.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1227.49 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1557.76 ms /   281 tokens (    5.54 ms per token,   180.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1568.40 ms /   282 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1251.83 ms /   227 tokens (    5.51 ms per token,   181.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1261.31 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.67 ms /   164 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     864.93 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.95 ms /   141 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     753.44 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     503.93 ms /    92 tokens (    5.48 ms per token,   182.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     510.71 ms /    93 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     586.06 ms /   117 tokens (    5.01 ms per token,   199.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     593.69 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1029.13 ms /   195 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.61 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.97 ms /   107 tokens (    5.73 ms per token,   174.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     620.37 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     441.07 ms /    86 tokens (    5.13 ms per token,   194.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     446.52 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.84 ms /   132 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     695.83 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.31 ms /   146 tokens (    5.39 ms per token,   185.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     794.63 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.26 ms /   193 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.81 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.85 ms /   192 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.52 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.14 ms /   118 tokens (    5.43 ms per token,   184.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     649.81 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.92 ms /   144 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     757.91 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.73 ms /   179 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     952.36 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1240.54 ms /   213 tokens (    5.82 ms per token,   171.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.64 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.37 ms /   173 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     903.53 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.64 ms /   197 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.96 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     494.15 ms /    87 tokens (    5.68 ms per token,   176.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     502.93 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.55 ms /   145 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     761.08 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1371.28 ms /   250 tokens (    5.49 ms per token,   182.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1380.48 ms /   251 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 88/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1601.65 ms /   292 tokens (    5.49 ms per token,   182.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1613.69 ms /   293 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1962.16 ms /   327 tokens (    6.00 ms per token,   166.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1983.94 ms /   328 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1582.95 ms /   283 tokens (    5.59 ms per token,   178.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1594.92 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1923.90 ms /   338 tokens (    5.69 ms per token,   175.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1935.02 ms /   339 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2013.25 ms /   357 tokens (    5.64 ms per token,   177.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2025.98 ms /   358 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.67 ms /   170 tokens (    5.85 ms per token,   170.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1002.34 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1064.37 ms /   195 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1073.21 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1177.76 ms /   191 tokens (    6.17 ms per token,   162.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1187.98 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.64 ms /   130 tokens (    7.14 ms per token,   139.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.85 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.69 ms /   164 tokens (    6.33 ms per token,   157.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.82 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.16 ms /   180 tokens (    5.88 ms per token,   170.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.72 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.19 ms /   166 tokens (    5.60 ms per token,   178.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     938.24 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.29 ms /   162 tokens (    6.32 ms per token,   158.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1032.16 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.56 ms /   110 tokens (    6.41 ms per token,   156.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     713.37 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1398.57 ms /   254 tokens (    5.51 ms per token,   181.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1408.51 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1143.30 ms /   214 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.35 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.98 ms /   198 tokens (    5.59 ms per token,   179.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1114.99 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2612.16 ms /   435 tokens (    6.00 ms per token,   166.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2628.68 ms /   436 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2434.60 ms /   425 tokens (    5.73 ms per token,   174.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2449.77 ms /   426 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2439.24 ms /   427 tokens (    5.71 ms per token,   175.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2453.77 ms /   428 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2115.64 ms /   378 tokens (    5.60 ms per token,   178.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2127.40 ms /   379 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2169.48 ms /   384 tokens (    5.65 ms per token,   177.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2181.86 ms /   385 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2179.20 ms /   367 tokens (    5.94 ms per token,   168.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2193.23 ms /   368 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2136.90 ms /   377 tokens (    5.67 ms per token,   176.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2150.56 ms /   378 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2139.34 ms /   381 tokens (    5.62 ms per token,   178.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2150.86 ms /   382 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2020.84 ms /   357 tokens (    5.66 ms per token,   176.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2032.63 ms /   358 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2068.36 ms /   363 tokens (    5.70 ms per token,   175.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    2080.83 ms /   364 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.67 ms /   148 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.01 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     149.19 ms /    29 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     152.81 ms /    30 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 90/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1123.96 ms /   208 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1134.51 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     371.24 ms /    68 tokens (    5.46 ms per token,   183.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     375.91 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.88 ms /   187 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     986.88 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     217.37 ms /    40 tokens (    5.43 ms per token,   184.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     222.63 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     512.92 ms /    99 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     519.56 ms /   100 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1398.21 ms /   250 tokens (    5.59 ms per token,   178.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1408.93 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     645.41 ms /   126 tokens (    5.12 ms per token,   195.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     652.23 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.23 ms /   173 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.27 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1138.84 ms /   209 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1150.23 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     410.45 ms /    75 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     417.82 ms /    76 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.84 ms /   182 tokens (    5.47 ms per token,   182.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.58 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     463.97 ms /    78 tokens (    5.95 ms per token,   168.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     469.97 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.29 ms /   163 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     889.13 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.49 ms /   144 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.53 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.45 ms /   175 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     924.16 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1314.10 ms /   240 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1323.47 ms /   241 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.62 ms /   158 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.74 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     485.63 ms /    96 tokens (    5.06 ms per token,   197.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     491.99 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.72 ms /   158 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     831.55 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     407.83 ms /    72 tokens (    5.66 ms per token,   176.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     412.68 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.43 ms /   146 tokens (    5.15 ms per token,   194.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     760.31 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     698.84 ms /   130 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.83 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.17 ms /   122 tokens (    5.34 ms per token,   187.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     657.65 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1473.28 ms /   239 tokens (    6.16 ms per token,   162.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1483.12 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     381.14 ms /    69 tokens (    5.52 ms per token,   181.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     385.88 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.32 ms /   160 tokens (    5.36 ms per token,   186.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.72 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     531.34 ms /   100 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     536.93 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.60 ms /   177 tokens (    5.36 ms per token,   186.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.73 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.83 ms /   179 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     947.67 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1234.02 ms /   222 tokens (    5.56 ms per token,   179.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.92 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     291.75 ms /    57 tokens (    5.12 ms per token,   195.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     296.14 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     377.81 ms /    72 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     382.71 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1231.18 ms /   222 tokens (    5.55 ms per token,   180.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.37 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     968.43 ms /   185 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     977.03 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     373.93 ms /    74 tokens (    5.05 ms per token,   197.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.27 ms /    75 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1221.36 ms /   217 tokens (    5.63 ms per token,   177.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1231.11 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     435.66 ms /    63 tokens (    6.92 ms per token,   144.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     441.23 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1525.20 ms /   218 tokens (    7.00 ms per token,   142.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1535.67 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     866.42 ms /   163 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     875.10 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.00 ms /   162 tokens (    7.00 ms per token,   142.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.33 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.01 ms /   201 tokens (    5.64 ms per token,   177.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1144.71 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.93 ms /   168 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     905.10 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.32 ms /   135 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     718.32 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.76 ms /   163 tokens (    5.39 ms per token,   185.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.73 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.17 ms /   187 tokens (    5.78 ms per token,   172.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1090.43 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.19 ms /   165 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.85 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     987.80 ms /   186 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     996.27 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.92 ms /    86 tokens (    5.06 ms per token,   197.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     440.87 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.40 ms /   175 tokens (    5.36 ms per token,   186.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     947.06 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.37 ms /   201 tokens (    5.38 ms per token,   185.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1091.97 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1072.96 ms /   174 tokens (    6.17 ms per token,   162.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.37 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.75 ms /   140 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     768.36 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.57 ms /   129 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     699.69 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.10 ms /    89 tokens (    4.88 ms per token,   205.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     439.49 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     814.44 ms /   154 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     822.28 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1183.83 ms /   215 tokens (    5.51 ms per token,   181.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.20 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     668.76 ms /   122 tokens (    5.48 ms per token,   182.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     675.12 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.02 ms /   196 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1032.72 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1193.57 ms /   212 tokens (    5.63 ms per token,   177.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1203.77 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.72 ms /   128 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     687.50 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.60 ms /   144 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     764.50 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.45 ms /   114 tokens (    5.12 ms per token,   195.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.20 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.78 ms /   174 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     927.04 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.42 ms /   145 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.56 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.74 ms /   179 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.42 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     679.16 ms /   129 tokens (    5.26 ms per token,   189.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     685.59 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     624.81 ms /   117 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     631.30 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.98 ms /   132 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     732.98 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1139.29 ms /   208 tokens (    5.48 ms per token,   182.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1148.65 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.48 ms /    89 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     473.60 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.59 ms /   146 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.74 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     778.12 ms /   146 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     784.85 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.60 ms /   186 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1006.30 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.10 ms /   146 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     764.82 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     512.99 ms /    90 tokens (    5.70 ms per token,   175.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     519.68 ms /    91 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.94 ms /   148 tokens (    5.55 ms per token,   180.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     828.39 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.21 ms /   180 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.64 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.05 ms /   178 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     931.10 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.13 ms /   164 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     862.63 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.23 ms /   193 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.36 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.55 ms /   136 tokens (    5.44 ms per token,   183.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     748.53 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     581.87 ms /   108 tokens (    5.39 ms per token,   185.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     587.72 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.90 ms /   151 tokens (    5.38 ms per token,   185.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     819.76 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     963.53 ms /   182 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     971.97 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.38 ms /   182 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     960.28 ms /   183 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     457.20 ms /    91 tokens (    5.02 ms per token,   199.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     463.05 ms /    92 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.08 ms /   130 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     704.04 ms /   131 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.74 ms /   152 tokens (    5.08 ms per token,   196.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     781.06 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1033.13 ms /   194 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1048.93 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.06 ms /   136 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.29 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     547.96 ms /   103 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     554.35 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.74 ms /   157 tokens (    5.20 ms per token,   192.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     823.02 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     337.65 ms /    61 tokens (    5.54 ms per token,   180.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     342.93 ms /    62 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.37 ms /   198 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.48 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.24 ms /   172 tokens (    5.52 ms per token,   181.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.35 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.20 ms /   166 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.61 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     561.57 ms /   109 tokens (    5.15 ms per token,   194.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     567.77 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.09 ms /   202 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1082.26 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     304.47 ms /    47 tokens (    6.48 ms per token,   154.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     310.06 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1077.71 ms /   202 tokens (    5.34 ms per token,   187.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1087.96 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.43 ms /   129 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     704.67 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.08 ms /   134 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     723.80 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.42 ms /   190 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.31 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     391.05 ms /    71 tokens (    5.51 ms per token,   181.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     395.63 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.77 ms /   188 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.20 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.98 ms /   144 tokens (    5.60 ms per token,   178.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     814.54 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.10 ms /   191 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1029.05 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.38 ms /   161 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     881.86 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.64 ms /   177 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.38 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     255.24 ms /    48 tokens (    5.32 ms per token,   188.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     260.44 ms /    49 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1146.15 ms /   189 tokens (    6.06 ms per token,   164.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1156.27 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     499.50 ms /    71 tokens (    7.04 ms per token,   142.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     504.78 ms /    72 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1396.78 ms /   189 tokens (    7.39 ms per token,   135.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1407.12 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.94 ms /   139 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     749.79 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.61 ms /   144 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     755.92 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.03 ms /   163 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.86 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.85 ms /   164 tokens (    5.77 ms per token,   173.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.16 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1174.79 ms /   209 tokens (    5.62 ms per token,   177.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.29 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     980.49 ms /   187 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     989.27 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.37 ms /   128 tokens (    5.03 ms per token,   198.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.03 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.47 ms /   185 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     998.61 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1306.25 ms /   213 tokens (    6.13 ms per token,   163.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1316.89 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1174.68 ms /   215 tokens (    5.46 ms per token,   183.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.12 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     406.45 ms /    78 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     411.97 ms /    79 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 91/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.66 ms /   164 tokens (    5.40 ms per token,   185.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     894.01 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1136.41 ms /   211 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1152.08 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.59 ms /   188 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.70 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1174.44 ms /   211 tokens (    5.57 ms per token,   179.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1184.11 ms /   212 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.09 ms /   168 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     898.90 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1268.85 ms /   233 tokens (    5.45 ms per token,   183.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1278.30 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1139.63 ms /   213 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1150.15 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     357.26 ms /    64 tokens (    5.58 ms per token,   179.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.70 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1119.74 ms /   210 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1130.09 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     961.35 ms /   173 tokens (    5.56 ms per token,   179.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     969.57 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     460.86 ms /    95 tokens (    4.85 ms per token,   206.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     466.69 ms /    96 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.08 ms /   193 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.34 ms /   194 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.19 ms /   222 tokens (    5.50 ms per token,   181.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.09 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.18 ms /   127 tokens (    4.98 ms per token,   200.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     638.51 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.26 ms /   163 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     879.29 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.41 ms /   137 tokens (    5.22 ms per token,   191.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     721.99 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1462.77 ms /   266 tokens (    5.50 ms per token,   181.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1473.44 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      45.77 ms /     5 tokens (    9.15 ms per token,   109.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.15 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1644.54 ms /   293 tokens (    5.61 ms per token,   178.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1656.23 ms /   294 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.35 ms /   117 tokens (    5.51 ms per token,   181.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     650.41 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.46 ms /   152 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     841.89 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1347.91 ms /   248 tokens (    5.44 ms per token,   183.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1358.37 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1179.52 ms /   219 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1188.09 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1430.73 ms /   254 tokens (    5.63 ms per token,   177.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1441.61 ms /   255 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     483.02 ms /    86 tokens (    5.62 ms per token,   178.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     488.52 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.06 ms /   175 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     922.39 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1425.96 ms /   249 tokens (    5.73 ms per token,   174.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.47 ms /   250 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     416.19 ms /    63 tokens (    6.61 ms per token,   151.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.95 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1210.90 ms /   222 tokens (    5.45 ms per token,   183.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1222.69 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.94 ms /   106 tokens (    5.51 ms per token,   181.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.81 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1329.13 ms /   237 tokens (    5.61 ms per token,   178.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1340.74 ms /   238 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     328.30 ms /    63 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     332.67 ms /    64 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.97 ms /   154 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     820.01 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1085.13 ms /   201 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1103.33 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.14 ms /   161 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     864.42 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.81 ms /   181 tokens (    5.13 ms per token,   194.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     936.86 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.49 ms /   144 tokens (    5.00 ms per token,   199.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     727.41 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.05 ms /   151 tokens (    5.40 ms per token,   185.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     823.13 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.94 ms /   196 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1048.49 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     573.14 ms /   100 tokens (    5.73 ms per token,   174.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     579.60 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.60 ms /   227 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1230.43 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.57 ms /    85 tokens (    4.89 ms per token,   204.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     423.25 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     418.94 ms /    78 tokens (    5.37 ms per token,   186.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     424.10 ms /    79 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1056.19 ms /   197 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1065.70 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     417.21 ms /    77 tokens (    5.42 ms per token,   184.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     430.01 ms /    78 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     972.11 ms /   183 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     980.59 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     565.49 ms /   108 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.40 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1060.65 ms /   174 tokens (    6.10 ms per token,   164.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.81 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1265.24 ms /   225 tokens (    5.62 ms per token,   177.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1275.74 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     255.85 ms /    50 tokens (    5.12 ms per token,   195.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     260.05 ms /    51 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     459.57 ms /    85 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     465.97 ms /    86 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      36.58 ms /     4 tokens (    9.15 ms per token,   109.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      39.14 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1101.84 ms /   210 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1112.52 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     348.64 ms /    62 tokens (    5.62 ms per token,   177.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     353.73 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     653.11 ms /   121 tokens (    5.40 ms per token,   185.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     660.48 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.47 ms /   183 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     963.78 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1438.05 ms /   201 tokens (    7.15 ms per token,   139.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1447.45 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.02 ms /    55 tokens (    7.20 ms per token,   138.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     400.31 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1522.54 ms /   225 tokens (    6.77 ms per token,   147.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1531.58 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     422.19 ms /    60 tokens (    7.04 ms per token,   142.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     426.39 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1132.95 ms /   213 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.74 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     324.03 ms /    55 tokens (    5.89 ms per token,   169.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     328.89 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1153.69 ms /   218 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1163.09 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.90 ms /   134 tokens (    5.55 ms per token,   180.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     751.03 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.27 ms /   173 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.56 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.00 ms /   208 tokens (    5.43 ms per token,   184.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1139.53 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1242.07 ms /   230 tokens (    5.40 ms per token,   185.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1251.54 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.51 ms /   163 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     878.93 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.19 ms /   187 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     989.58 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     509.54 ms /   105 tokens (    4.85 ms per token,   206.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     516.51 ms /   106 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.91 ms /   165 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.71 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.43 ms /   159 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     868.78 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     984.62 ms /   188 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     993.09 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.15 ms /   194 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.42 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1249.65 ms /   222 tokens (    5.63 ms per token,   177.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1259.30 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.23 ms /   191 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.24 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     683.73 ms /   126 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     690.96 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     636.96 ms /   120 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     644.30 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1397.38 ms /   241 tokens (    5.80 ms per token,   172.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1406.61 ms /   242 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.26 ms /   156 tokens (    5.96 ms per token,   167.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     937.51 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.65 ms /    89 tokens (    6.01 ms per token,   166.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     540.34 ms /    90 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1227.20 ms /   190 tokens (    6.46 ms per token,   154.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1236.66 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.32 ms /   129 tokens (    6.38 ms per token,   156.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     830.51 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1410.68 ms /   217 tokens (    6.50 ms per token,   153.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1419.74 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     467.30 ms /    73 tokens (    6.40 ms per token,   156.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     472.89 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.95 ms /   136 tokens (    6.39 ms per token,   156.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     875.83 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.53 ms /   151 tokens (    6.25 ms per token,   160.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     951.23 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1684.43 ms /   261 tokens (    6.45 ms per token,   154.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1695.28 ms /   262 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1154.41 ms /   185 tokens (    6.24 ms per token,   160.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1162.42 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     559.77 ms /    87 tokens (    6.43 ms per token,   155.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     565.43 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1255.23 ms /   204 tokens (    6.15 ms per token,   162.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1264.83 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1440.68 ms /   230 tokens (    6.26 ms per token,   159.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1450.52 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     577.71 ms /    86 tokens (    6.72 ms per token,   148.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     584.32 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.56 ms /   154 tokens (    6.00 ms per token,   166.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.29 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1343.38 ms /   218 tokens (    6.16 ms per token,   162.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1352.86 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.83 ms /   142 tokens (    6.19 ms per token,   161.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     885.53 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1587.91 ms /   244 tokens (    6.51 ms per token,   153.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1598.53 ms /   245 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.81 ms /   179 tokens (    6.40 ms per token,   156.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1153.58 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1462.39 ms /   218 tokens (    6.71 ms per token,   149.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1471.65 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1364.65 ms /   214 tokens (    6.38 ms per token,   156.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1373.93 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.35 ms /   121 tokens (    6.27 ms per token,   159.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.58 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1410.33 ms /   219 tokens (    6.44 ms per token,   155.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1421.63 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1400.17 ms /   218 tokens (    6.42 ms per token,   155.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1411.97 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1255.62 ms /   210 tokens (    5.98 ms per token,   167.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1265.43 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1465.75 ms /   229 tokens (    6.40 ms per token,   156.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1478.20 ms /   230 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.89 ms /   126 tokens (    6.03 ms per token,   165.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.65 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.39 ms /   127 tokens (    5.96 ms per token,   167.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.88 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1333.11 ms /   212 tokens (    6.29 ms per token,   159.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.45 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1289.48 ms /   210 tokens (    6.14 ms per token,   162.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.41 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.27 ms /    53 tokens (    6.33 ms per token,   158.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     340.46 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.11 ms /   118 tokens (    6.14 ms per token,   162.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     731.12 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.72 ms /   115 tokens (    6.12 ms per token,   163.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     711.17 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1200.37 ms /   206 tokens (    5.83 ms per token,   171.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1209.87 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1395.90 ms /   225 tokens (    6.20 ms per token,   161.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1404.35 ms /   226 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.22 ms /   135 tokens (    6.19 ms per token,   161.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.75 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     653.04 ms /    86 tokens (    7.59 ms per token,   131.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     660.55 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.24 ms /   163 tokens (    6.32 ms per token,   158.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1039.38 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.43 ms /   168 tokens (    6.58 ms per token,   151.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.76 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1092.33 ms /   151 tokens (    7.23 ms per token,   138.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1100.57 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.04 ms /   128 tokens (    7.40 ms per token,   135.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     954.90 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.21 ms /   145 tokens (    6.26 ms per token,   159.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.99 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.34 ms /   154 tokens (    5.81 ms per token,   172.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     903.40 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     633.56 ms /   100 tokens (    6.34 ms per token,   157.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     639.76 ms /   101 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1262.24 ms /   223 tokens (    5.66 ms per token,   176.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1272.35 ms /   224 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.68 ms /   191 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1028.01 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.86 ms /   158 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.69 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.18 ms /   151 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     815.12 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.52 ms /   171 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     899.41 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.78 ms /   188 tokens (    5.18 ms per token,   193.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     981.96 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     845.40 ms /   161 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.98 ms /   162 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 92/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.08 ms /   176 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.67 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1158.17 ms /   216 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1173.93 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     378.97 ms /    73 tokens (    5.19 ms per token,   192.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     384.72 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.69 ms /   164 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     883.25 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.80 ms /   135 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     729.00 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.35 ms /   187 tokens (    5.09 ms per token,   196.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     960.75 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.43 ms /   203 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1082.89 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1437.88 ms /   253 tokens (    5.68 ms per token,   175.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1449.38 ms /   254 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     602.30 ms /   111 tokens (    5.43 ms per token,   184.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     608.71 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     857.49 ms /   168 tokens (    5.10 ms per token,   195.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     865.01 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.59 ms /   141 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     745.57 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.03 ms /   210 tokens (    5.43 ms per token,   184.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1149.91 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1135.15 ms /   212 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1143.75 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1163.76 ms /   210 tokens (    5.54 ms per token,   180.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1174.63 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1387.13 ms /   222 tokens (    6.25 ms per token,   160.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1397.02 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.18 ms /   129 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     691.45 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.60 ms /   187 tokens (    5.08 ms per token,   196.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.99 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.62 ms /   187 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     978.87 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     523.76 ms /   101 tokens (    5.19 ms per token,   192.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     529.54 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     582.67 ms /   106 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     588.84 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.14 ms /   124 tokens (    4.80 ms per token,   208.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     601.61 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.82 ms /   110 tokens (    5.58 ms per token,   179.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     620.10 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.17 ms /   166 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     882.07 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.71 ms /   108 tokens (    4.79 ms per token,   208.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     524.56 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.00 ms /   139 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     756.34 ms /   140 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.02 ms /   104 tokens (    5.85 ms per token,   171.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     614.12 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1215.80 ms /   221 tokens (    5.50 ms per token,   181.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1224.57 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1191.10 ms /   224 tokens (    5.32 ms per token,   188.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.73 ms /   225 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     321.27 ms /    57 tokens (    5.64 ms per token,   177.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     325.57 ms /    58 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      41.25 ms /     3 tokens (   13.75 ms per token,    72.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.66 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.86 ms /   179 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     959.94 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     244.84 ms /    43 tokens (    5.69 ms per token,   175.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     249.23 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1070.01 ms /   201 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1079.03 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.23 ms /    41 tokens (    6.47 ms per token,   154.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     269.00 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.32 ms /   179 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     955.29 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.91 ms /   177 tokens (    6.01 ms per token,   166.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.63 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     518.26 ms /    93 tokens (    5.57 ms per token,   179.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     524.98 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     968.75 ms /   187 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     977.57 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     363.10 ms /    64 tokens (    5.67 ms per token,   176.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     368.63 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.55 ms /   121 tokens (    4.92 ms per token,   203.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     602.44 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.52 ms /   175 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     928.72 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.89 ms /    96 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     521.34 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     568.28 ms /   113 tokens (    5.03 ms per token,   198.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     574.41 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.95 ms /   127 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     679.70 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.27 ms /   164 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.59 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1233.29 ms /   227 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.13 ms /   228 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1389.66 ms /   246 tokens (    5.65 ms per token,   177.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1398.90 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.55 ms /   207 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.56 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.60 ms /    82 tokens (    5.69 ms per token,   175.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     475.25 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.69 ms /     2 tokens (   22.34 ms per token,    44.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      47.88 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.19 ms /   194 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1021.81 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     357.80 ms /    70 tokens (    5.11 ms per token,   195.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     364.53 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.82 ms /   132 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     709.33 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     693.73 ms /   133 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     701.29 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     814.48 ms /   160 tokens (    5.09 ms per token,   196.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     822.31 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     410.95 ms /    79 tokens (    5.20 ms per token,   192.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     415.97 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.75 ms /   179 tokens (    5.37 ms per token,   186.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     969.18 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     845.81 ms /   153 tokens (    5.53 ms per token,   180.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.92 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1104.11 ms /   160 tokens (    6.90 ms per token,   144.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1114.72 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1224.85 ms /   216 tokens (    5.67 ms per token,   176.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1234.43 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.38 ms /   122 tokens (    6.07 ms per token,   164.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     747.75 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.86 ms /   163 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     850.24 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.34 ms /   162 tokens (    5.14 ms per token,   194.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.60 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.42 ms /   122 tokens (    6.18 ms per token,   161.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     763.07 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.89 ms /   117 tokens (    7.02 ms per token,   142.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     828.20 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.68 ms /   125 tokens (    6.51 ms per token,   153.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     822.80 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     600.29 ms /   121 tokens (    4.96 ms per token,   201.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     606.78 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.97 ms /   144 tokens (    5.15 ms per token,   194.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     750.10 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1185.82 ms /   217 tokens (    5.46 ms per token,   183.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.67 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.49 ms /   217 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1179.88 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.25 ms /   104 tokens (    5.50 ms per token,   181.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.90 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.55 ms /   119 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     654.42 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     567.53 ms /   115 tokens (    4.94 ms per token,   202.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     575.54 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.60 ms /   172 tokens (    5.20 ms per token,   192.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     902.53 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.20 ms /   108 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     589.24 ms /   109 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.55 ms /   191 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     995.51 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.72 ms /    83 tokens (    5.38 ms per token,   185.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.56 ms /    84 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.23 ms /   198 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1083.42 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.15 ms /   149 tokens (    6.14 ms per token,   162.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     922.88 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.71 ms /   143 tokens (    5.36 ms per token,   186.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.72 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.24 ms /   127 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     664.03 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.45 ms /   177 tokens (    5.09 ms per token,   196.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     910.12 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.14 ms /   168 tokens (    5.14 ms per token,   194.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     872.07 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.90 ms /   174 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     923.87 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     983.64 ms /   187 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     992.08 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.17 ms /   148 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.39 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.45 ms /   160 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.16 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.69 ms /   168 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.08 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.14 ms /   165 tokens (    5.12 ms per token,   195.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     853.26 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.39 ms /   170 tokens (    5.20 ms per token,   192.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     891.77 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.22 ms /   131 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     705.76 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1059.95 ms /   199 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.68 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     399.02 ms /    68 tokens (    5.87 ms per token,   170.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     406.31 ms /    69 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     971.20 ms /   191 tokens (    5.08 ms per token,   196.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     980.15 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.02 ms /   179 tokens (    5.06 ms per token,   197.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.79 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.42 ms /   176 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.91 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1385.88 ms /   250 tokens (    5.54 ms per token,   180.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1398.25 ms /   251 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.95 ms /   168 tokens (    4.97 ms per token,   201.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     842.83 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.22 ms /   121 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     635.61 ms /   122 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1766.20 ms /   301 tokens (    5.87 ms per token,   170.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1777.25 ms /   302 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     483.58 ms /    98 tokens (    4.93 ms per token,   202.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     489.84 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.92 ms /   141 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     765.38 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1248.47 ms /   230 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1257.64 ms /   231 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     574.68 ms /   107 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     580.74 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.26 ms /   135 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     715.10 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.54 ms /   295 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1631.54 ms /   296 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.14 ms /   198 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.36 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.28 ms /   147 tokens (    5.65 ms per token,   176.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     839.60 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.28 ms /   164 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     893.84 ms /   165 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.18 ms /   209 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.87 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.36 ms /   150 tokens (    5.56 ms per token,   180.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     843.52 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1186.25 ms /   218 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1195.20 ms /   219 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1127.40 ms /   213 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.13 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     478.16 ms /    79 tokens (    6.05 ms per token,   165.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     483.14 ms /    80 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     340.94 ms /    66 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     345.87 ms /    67 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.99 ms /   132 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     713.42 ms /   133 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     488.27 ms /    94 tokens (    5.19 ms per token,   192.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     496.38 ms /    95 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.82 ms /   149 tokens (    5.59 ms per token,   178.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     840.02 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.88 ms /   181 tokens (    5.57 ms per token,   179.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1017.08 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1058.86 ms /   184 tokens (    5.75 ms per token,   173.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1067.67 ms /   185 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.26 ms /   159 tokens (    5.63 ms per token,   177.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     904.46 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.45 ms /   165 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     876.07 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.19 ms /   133 tokens (    5.11 ms per token,   195.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     686.63 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.13 ms /   192 tokens (    5.14 ms per token,   194.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     994.62 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.92 ms /   196 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.22 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.56 ms /   183 tokens (    5.56 ms per token,   179.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1025.85 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1240.89 ms /   165 tokens (    7.52 ms per token,   132.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1250.94 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1320.41 ms /   210 tokens (    6.29 ms per token,   159.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1329.05 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1219.30 ms /   185 tokens (    6.59 ms per token,   151.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1230.45 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1523.83 ms /   239 tokens (    6.38 ms per token,   156.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.82 ms /   240 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.27 ms /   113 tokens (    7.43 ms per token,   134.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     847.05 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.87 ms /   183 tokens (    5.53 ms per token,   180.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1022.88 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1307.07 ms /   178 tokens (    7.34 ms per token,   136.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1317.03 ms /   179 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 93/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     582.04 ms /    88 tokens (    6.61 ms per token,   151.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     588.37 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.22 ms /   189 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1041.05 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1470.01 ms /   251 tokens (    5.86 ms per token,   170.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1480.99 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     521.31 ms /   102 tokens (    5.11 ms per token,   195.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     526.75 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1123.31 ms /   203 tokens (    5.53 ms per token,   180.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1134.63 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1109.92 ms /   205 tokens (    5.41 ms per token,   184.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.46 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.02 ms /    65 tokens (    7.17 ms per token,   139.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     474.83 ms /    66 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1203.64 ms /   206 tokens (    5.84 ms per token,   171.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1214.83 ms /   207 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1404.64 ms /   246 tokens (    5.71 ms per token,   175.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1414.05 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.44 ms /   157 tokens (    5.16 ms per token,   193.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     817.59 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1086.99 ms /   203 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1100.02 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1600.37 ms /   278 tokens (    5.76 ms per token,   173.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1614.35 ms /   279 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     488.26 ms /    86 tokens (    5.68 ms per token,   176.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     493.21 ms /    87 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.68 ms /   172 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.12 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.84 ms /   124 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     666.37 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.46 ms /   181 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     958.26 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.68 ms /   205 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.25 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.26 ms /   172 tokens (    5.52 ms per token,   181.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     957.50 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1304.21 ms /   238 tokens (    5.48 ms per token,   182.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1314.26 ms /   239 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1132.47 ms /   210 tokens (    5.39 ms per token,   185.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.92 ms /   211 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.27 ms /   120 tokens (    5.65 ms per token,   176.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     686.65 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.60 ms /   173 tokens (    5.38 ms per token,   185.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.82 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1171.05 ms /   214 tokens (    5.47 ms per token,   182.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.34 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1175.64 ms /   215 tokens (    5.47 ms per token,   182.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1186.10 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     329.89 ms /    56 tokens (    5.89 ms per token,   169.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     334.71 ms /    57 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.55 ms /   192 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.00 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1123.11 ms /   208 tokens (    5.40 ms per token,   185.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1132.38 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1151.52 ms /   200 tokens (    5.76 ms per token,   173.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.84 ms /   201 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 94/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1235.84 ms /   215 tokens (    5.75 ms per token,   173.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1245.93 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.81 ms /    93 tokens (    6.41 ms per token,   156.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     601.80 ms /    94 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1220.31 ms /   216 tokens (    5.65 ms per token,   177.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.28 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.29 ms /   118 tokens (    5.82 ms per token,   171.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.68 ms /   119 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.48 ms /   142 tokens (    5.14 ms per token,   194.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     737.56 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.19 ms /   214 tokens (    5.79 ms per token,   172.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1247.08 ms /   215 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.43 ms /   181 tokens (    5.41 ms per token,   184.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     987.77 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.88 ms /   148 tokens (    5.17 ms per token,   193.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     774.14 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.30 ms /   138 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     754.08 ms /   139 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1095.70 ms /   205 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1104.22 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     962.51 ms /   174 tokens (    5.53 ms per token,   180.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     970.17 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1516.02 ms /   272 tokens (    5.57 ms per token,   179.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1527.54 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1097.11 ms /   205 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1106.03 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     664.46 ms /   124 tokens (    5.36 ms per token,   186.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.28 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1063.36 ms /   204 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.72 ms /   205 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1129.29 ms /   202 tokens (    5.59 ms per token,   178.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.23 ms /   203 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.71 ms /   149 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     796.15 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     219.87 ms /    42 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     223.58 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.78 ms /   188 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1008.85 ms /   189 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.80 ms /   167 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     917.83 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     522.50 ms /    98 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     528.35 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1324.12 ms /   246 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1334.60 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1158.13 ms /   217 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1167.02 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     388.51 ms /    62 tokens (    6.27 ms per token,   159.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     392.77 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1465.93 ms /   263 tokens (    5.57 ms per token,   179.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1477.85 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     535.78 ms /    72 tokens (    7.44 ms per token,   134.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     541.37 ms /    73 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1406.28 ms /   213 tokens (    6.60 ms per token,   151.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1417.51 ms /   214 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1234.21 ms /   226 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1243.34 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     286.14 ms /    53 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     291.22 ms /    54 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.23 ms /   141 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     748.04 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1204.77 ms /   220 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1214.44 ms /   221 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.24 ms /   113 tokens (    5.54 ms per token,   180.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     634.20 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.09 ms /   186 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1000.60 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.73 ms /   166 tokens (    5.61 ms per token,   178.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.13 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     718.64 ms /   135 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     725.63 ms /   136 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.81 ms /   155 tokens (    6.01 ms per token,   166.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     938.99 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1401.50 ms /   194 tokens (    7.22 ms per token,   138.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1410.51 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.49 ms /   155 tokens (    5.19 ms per token,   192.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     811.73 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1130.23 ms /   212 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1139.61 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1117.11 ms /   197 tokens (    5.67 ms per token,   176.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1125.29 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     301.26 ms /    51 tokens (    5.91 ms per token,   169.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     305.69 ms /    52 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.52 ms /   149 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     817.24 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1032.10 ms /   198 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1042.60 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.45 ms /   156 tokens (    5.51 ms per token,   181.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     867.40 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     383.80 ms /    76 tokens (    5.05 ms per token,   198.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     389.55 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.40 ms /   129 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     702.96 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.58 ms /   150 tokens (    5.25 ms per token,   190.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     798.27 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     365.37 ms /    69 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     369.90 ms /    70 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.98 ms /   111 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     592.13 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.20 ms /   145 tokens (    5.09 ms per token,   196.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     745.06 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.46 ms /   159 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     844.27 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     522.67 ms /    96 tokens (    5.44 ms per token,   183.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     528.92 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.00 ms /   158 tokens (    5.11 ms per token,   195.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     816.15 ms /   159 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1202.92 ms /   217 tokens (    5.54 ms per token,   180.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.57 ms /   218 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     522.79 ms /   104 tokens (    5.03 ms per token,   198.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     528.55 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.82 ms /   173 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     932.23 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1244.76 ms /   232 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1254.94 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     444.74 ms /    76 tokens (    5.85 ms per token,   170.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     453.14 ms /    77 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.25 ms /   190 tokens (    5.37 ms per token,   186.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1030.24 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.17 ms /   201 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1098.15 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.49 ms /   197 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.40 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     357.72 ms /    62 tokens (    5.77 ms per token,   173.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.99 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.93 ms /   175 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     916.20 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     870.27 ms /   161 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     878.39 ms /   162 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     664.22 ms /   128 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     671.75 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.97 ms /   200 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1081.18 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1110.07 ms /   196 tokens (    5.66 ms per token,   176.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1121.43 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.16 ms /   189 tokens (    5.51 ms per token,   181.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.13 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.84 ms /   200 tokens (    5.48 ms per token,   182.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1106.35 ms /   201 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.42 ms /   198 tokens (    5.56 ms per token,   179.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1109.19 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.34 ms /   127 tokens (    5.55 ms per token,   180.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     711.11 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1187.30 ms /   221 tokens (    5.37 ms per token,   186.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1196.59 ms /   222 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     307.41 ms /    60 tokens (    5.12 ms per token,   195.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     312.45 ms /    61 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.25 ms /   143 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     764.81 ms /   144 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.40 ms /   131 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     698.82 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.26 ms /   115 tokens (    5.01 ms per token,   199.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     582.49 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.68 ms /   152 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.12 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.25 ms /   120 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     635.67 ms /   121 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.97 ms /   151 tokens (    5.08 ms per token,   196.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     776.33 ms /   152 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     572.70 ms /   110 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     578.58 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1253.62 ms /   232 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1263.16 ms /   233 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1086.38 ms /   203 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1094.41 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.39 ms /   181 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     983.51 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1262.07 ms /   236 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.67 ms /   237 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     355.71 ms /    64 tokens (    5.56 ms per token,   179.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     361.38 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1328.20 ms /   246 tokens (    5.40 ms per token,   185.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.12 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.80 ms /   197 tokens (    5.31 ms per token,   188.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1055.52 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.49 ms /   189 tokens (    5.48 ms per token,   182.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1046.49 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1223.53 ms /   219 tokens (    5.59 ms per token,   178.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.69 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     247.25 ms /    44 tokens (    5.62 ms per token,   177.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     252.18 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.72 ms /   144 tokens (    5.01 ms per token,   199.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     729.34 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.45 ms /   169 tokens (    5.20 ms per token,   192.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     886.69 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     711.94 ms /   136 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     721.02 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.73 ms /   174 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     935.43 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.45 ms /   146 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     773.19 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1324.30 ms /   186 tokens (    7.12 ms per token,   140.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1333.01 ms /   187 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.02 ms /   149 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     809.35 ms /   150 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.48 ms /   131 tokens (    5.03 ms per token,   198.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     665.21 ms /   132 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     593.80 ms /   115 tokens (    5.16 ms per token,   193.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     601.36 ms /   116 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.73 ms /   156 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     838.73 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.12 ms /   170 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     904.72 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     235.90 ms /    47 tokens (    5.02 ms per token,   199.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     241.11 ms /    48 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1262.75 ms /   235 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1272.57 ms /   236 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     819.45 ms /   154 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     827.18 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.65 ms /   180 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     954.69 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1344.00 ms /   248 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1353.70 ms /   249 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.55 ms /   104 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     558.40 ms /   105 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1610.88 ms /   263 tokens (    6.13 ms per token,   163.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1621.65 ms /   264 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1542.18 ms /   228 tokens (    6.76 ms per token,   147.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1551.44 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.98 ms /   136 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.92 ms /   137 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.93 ms /   117 tokens (    4.99 ms per token,   200.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.36 ms /   118 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.91 ms /   161 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     861.42 ms /   162 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 96/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     575.32 ms /   102 tokens (    5.64 ms per token,   177.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     582.57 ms /   103 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     510.49 ms /   103 tokens (    4.96 ms per token,   201.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     516.21 ms /   104 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     656.38 ms /   119 tokens (    5.52 ms per token,   181.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     663.14 ms /   120 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.33 ms /   141 tokens (    5.14 ms per token,   194.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     732.74 ms /   142 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.38 ms /   148 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     780.22 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.63 ms /   172 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     890.07 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.65 ms /   128 tokens (    5.55 ms per token,   180.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     717.21 ms /   129 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     420.92 ms /    82 tokens (    5.13 ms per token,   194.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     425.88 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     584.01 ms /   110 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     590.16 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.80 ms /   156 tokens (    5.22 ms per token,   191.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     821.15 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.59 ms /   150 tokens (    5.08 ms per token,   196.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     769.79 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.56 ms /   125 tokens (    5.11 ms per token,   195.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     645.28 ms /   126 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1097.05 ms /   197 tokens (    5.57 ms per token,   179.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.55 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     295.09 ms /    41 tokens (    7.20 ms per token,   138.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     300.64 ms /    42 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.91 ms /   145 tokens (    5.10 ms per token,   195.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     747.43 ms /   146 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.08 ms /   134 tokens (    5.50 ms per token,   181.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     743.90 ms /   135 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.61 ms /   185 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     984.71 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     216.33 ms /    44 tokens (    4.92 ms per token,   203.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     220.49 ms /    45 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.96 ms /   152 tokens (    5.37 ms per token,   186.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     824.91 ms /   153 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     907.40 ms /   169 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     915.73 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     394.67 ms /    81 tokens (    4.87 ms per token,   205.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     400.33 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.42 ms /   150 tokens (    6.20 ms per token,   161.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.78 ms /   151 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     441.19 ms /    70 tokens (    6.30 ms per token,   158.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     447.14 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.11 ms /   174 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     908.30 ms /   175 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     217.12 ms /    40 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     221.73 ms /    41 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      47.74 ms /     5 tokens (    9.55 ms per token,   104.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      50.71 ms /     6 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1444.64 ms /   266 tokens (    5.43 ms per token,   184.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1455.69 ms /   267 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1420.50 ms /   246 tokens (    5.77 ms per token,   173.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1429.55 ms /   247 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.79 ms /   180 tokens (    5.09 ms per token,   196.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     926.40 ms /   181 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      78.55 ms /     9 tokens (    8.73 ms per token,   114.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      81.66 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1793.32 ms /   323 tokens (    5.55 ms per token,   180.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1806.61 ms /   324 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1499.02 ms /   272 tokens (    5.51 ms per token,   181.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1508.31 ms /   273 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.46 ms /   301 tokens (    5.61 ms per token,   178.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1699.34 ms /   302 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1232.41 ms /   226 tokens (    5.45 ms per token,   183.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.76 ms /   227 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1241.15 ms /   231 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1253.57 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.77 ms /   163 tokens (    5.56 ms per token,   179.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     914.38 ms /   164 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 97/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1089.62 ms /   205 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.44 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1146.07 ms /   215 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1155.89 ms /   216 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.46 ms /   175 tokens (    5.57 ms per token,   179.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     982.52 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.91 ms /   169 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     911.28 ms /   170 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1149.83 ms /   203 tokens (    5.66 ms per token,   176.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1159.34 ms /   204 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1382.04 ms /   251 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1392.74 ms /   252 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.65 ms /   155 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     852.13 ms /   156 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.23 ms /   160 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     860.46 ms /   161 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     387.47 ms /    67 tokens (    5.78 ms per token,   172.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     392.51 ms /    68 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      44.01 ms /     3 tokens (   14.67 ms per token,    68.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      48.61 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1486.78 ms /   271 tokens (    5.49 ms per token,   182.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1497.54 ms /   272 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.32 ms /    64 tokens (    4.88 ms per token,   204.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     317.56 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.83 ms /   195 tokens (    5.39 ms per token,   185.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.09 ms /   196 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.89 ms /   137 tokens (    5.63 ms per token,   177.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     779.83 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.71 ms /   181 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     969.98 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.64 ms /   140 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     759.51 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1205.47 ms /   212 tokens (    5.69 ms per token,   175.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1215.09 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.64 ms /   114 tokens (    7.59 ms per token,   131.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     884.63 ms /   115 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.22 ms /   144 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     772.38 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     436.83 ms /    87 tokens (    5.02 ms per token,   199.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     442.54 ms /    88 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1059.46 ms /   198 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.61 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.43 ms /   170 tokens (    5.50 ms per token,   181.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     944.27 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     624.55 ms /   110 tokens (    5.68 ms per token,   176.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     630.57 ms /   111 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.03 ms /   165 tokens (    5.07 ms per token,   197.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     844.44 ms /   166 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.29 ms /   187 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     974.16 ms /   188 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.94 ms /   199 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1043.59 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.47 ms /   154 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     814.81 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.88 ms /   153 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     825.34 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.05 ms /   124 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     678.73 ms /   125 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.24 ms /   154 tokens (    5.16 ms per token,   193.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     802.06 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.72 ms /   159 tokens (    4.95 ms per token,   201.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     795.31 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.29 ms /   167 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     890.90 ms /   168 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.61 ms /   148 tokens (    5.95 ms per token,   168.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     888.12 ms /   149 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.28 ms /   144 tokens (    6.63 ms per token,   150.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     962.26 ms /   145 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1245.98 ms /   191 tokens (    6.52 ms per token,   153.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.80 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.95 ms /   156 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     830.93 ms /   157 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     590.63 ms /   109 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     596.51 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1243.44 ms /   228 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1252.46 ms /   229 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.73 ms /   110 tokens (    4.89 ms per token,   204.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     543.61 ms /   111 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 98/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.98 ms /   175 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.74 ms /   176 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.11 ms /   181 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     966.49 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.33 ms /   178 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     941.47 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.34 ms /   159 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     859.94 ms /   160 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     355.46 ms /    70 tokens (    5.08 ms per token,   196.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     360.38 ms /    71 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.21 ms /   191 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1018.16 ms /   192 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.49 ms /   172 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.19 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1097.67 ms /   205 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1108.14 ms /   206 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.99 ms /   129 tokens (    5.71 ms per token,   175.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     745.85 ms /   130 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1270.65 ms /   233 tokens (    5.45 ms per token,   183.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.58 ms /   234 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1284.15 ms /   216 tokens (    5.95 ms per token,   168.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1296.04 ms /   217 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.30 ms /   154 tokens (    5.13 ms per token,   195.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     796.47 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     803.08 ms /   157 tokens (    5.12 ms per token,   195.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     810.86 ms /   158 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.72 ms /   189 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.15 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     357.67 ms /    59 tokens (    6.06 ms per token,   164.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     362.14 ms /    60 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     619.11 ms /   127 tokens (    4.87 ms per token,   205.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     627.67 ms /   128 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.60 ms /   179 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.95 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.45 ms /   171 tokens (    5.47 ms per token,   182.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     943.35 ms /   172 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.45 ms /   123 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     669.03 ms /   124 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.42 ms /   122 tokens (    4.90 ms per token,   204.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     603.89 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.27 ms /   133 tokens (    5.83 ms per token,   171.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     783.19 ms /   134 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.37 ms /   112 tokens (    5.44 ms per token,   183.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     615.40 ms /   113 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.60 ms /   168 tokens (    5.05 ms per token,   198.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     855.85 ms /   169 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.21 ms /   163 tokens (    5.02 ms per token,   199.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     826.32 ms /   164 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     144.79 ms /    25 tokens (    5.79 ms per token,   172.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     149.90 ms /    26 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.19 ms /   196 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1050.25 ms /   197 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1030.66 ms /   192 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1044.01 ms /   193 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     343.19 ms /    62 tokens (    5.54 ms per token,   180.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     350.45 ms /    63 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     504.54 ms /   101 tokens (    5.00 ms per token,   200.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     510.78 ms /   102 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.08 ms /   178 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.44 ms /   179 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     374.93 ms /    64 tokens (    5.86 ms per token,   170.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     379.91 ms /    65 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1049.93 ms /   199 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1058.91 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     745.71 ms /   142 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     754.95 ms /   143 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.15 ms /   181 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     949.65 ms /   182 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     273.38 ms /    43 tokens (    6.36 ms per token,   157.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     277.11 ms /    44 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.00 ms /   197 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1047.60 ms /   198 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     439.96 ms /    81 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     445.90 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     671.00 ms /   122 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     678.54 ms /   123 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     487.90 ms /    98 tokens (    4.98 ms per token,   200.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     494.53 ms /    99 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     971.35 ms /   185 tokens (    5.25 ms per token,   190.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     980.36 ms /   186 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     632.28 ms /   109 tokens (    5.80 ms per token,   172.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     638.27 ms /   110 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.75 ms /   162 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.11 ms /   163 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.05 ms /   137 tokens (    5.01 ms per token,   199.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     693.25 ms /   138 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.64 ms /   153 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     821.01 ms /   154 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     304.17 ms /    58 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     308.49 ms /    59 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.80 ms /   177 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     939.99 ms /   178 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     526.42 ms /    96 tokens (    5.48 ms per token,   182.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     532.70 ms /    97 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.67 ms /   126 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     662.39 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.20 ms /   170 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     887.68 ms /   171 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.58 ms /   198 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.62 ms /   199 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.17 ms /   106 tokens (    5.61 ms per token,   178.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     603.10 ms /   107 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.21 ms /   172 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     918.30 ms /   173 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1459.33 ms /   219 tokens (    6.66 ms per token,   150.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.36 ms /   220 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     343.51 ms /    45 tokens (    7.63 ms per token,   131.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     349.02 ms /    46 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.24 ms /   154 tokens (    5.15 ms per token,   194.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     800.78 ms /   155 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      40.86 ms /     4 tokens (   10.21 ms per token,    97.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      44.91 ms /     5 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1050.61 ms /   199 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.39 ms /   200 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     422.40 ms /    73 tokens (    5.79 ms per token,   172.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     427.81 ms /    74 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1158.10 ms /   212 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1167.21 ms /   213 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     352.57 ms /    55 tokens (    6.41 ms per token,   156.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     357.01 ms /    56 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     233.65 ms /    42 tokens (    5.56 ms per token,   179.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     239.08 ms /    43 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.14 ms /   166 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     866.28 ms /   167 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.76 ms /   111 tokens (    5.14 ms per token,   194.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     577.55 ms /   112 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.29 ms /   107 tokens (    5.59 ms per token,   178.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     604.40 ms /   108 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     565.78 ms /   113 tokens (    5.01 ms per token,   199.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     571.76 ms /   114 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.43 ms /   183 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     965.72 ms /   184 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     445.76 ms /    82 tokens (    5.44 ms per token,   183.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     450.88 ms /    83 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.56 ms /   189 tokens (    5.12 ms per token,   195.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     976.64 ms /   190 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.93 ms /   146 tokens (    5.03 ms per token,   198.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     743.57 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1217.90 ms /   222 tokens (    5.49 ms per token,   182.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1227.07 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.38 ms /   147 tokens (    5.17 ms per token,   193.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     767.49 ms /   148 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.44 ms /   176 tokens (    5.13 ms per token,   195.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     910.54 ms /   177 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1091.41 ms /   207 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1101.07 ms /   208 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1215.73 ms /   179 tokens (    6.79 ms per token,   147.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1227.32 ms /   180 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      46.33 ms /     3 tokens (   15.44 ms per token,    64.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      49.89 ms /     4 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1496.92 ms /   222 tokens (    6.74 ms per token,   148.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1506.56 ms /   223 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.15 ms /   140 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     766.56 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.21 ms /   173 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     934.38 ms /   174 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1154.09 ms /   209 tokens (    5.52 ms per token,   181.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1163.12 ms /   210 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.88 ms /   146 tokens (    5.17 ms per token,   193.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     762.01 ms /   147 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.78 ms /   194 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1052.50 ms /   195 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.57 ms /   140 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     775.94 ms /   141 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     472.47 ms /    88 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     477.67 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.22 ms /   190 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1014.72 ms /   191 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     416.37 ms /    81 tokens (    5.14 ms per token,   194.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     421.97 ms /    82 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     477.86 ms /    88 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     483.29 ms /    89 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.68 ms /   303 tokens (    5.55 ms per token,   180.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1692.34 ms /   304 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1563.62 ms /   280 tokens (    5.58 ms per token,   179.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1573.65 ms /   281 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1586.14 ms /   283 tokens (    5.60 ms per token,   178.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1596.27 ms /   284 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.19 ms /    86 tokens (    5.19 ms per token,   192.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     452.71 ms /    87 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 99/100 articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1107.17 ms /   208 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1116.86 ms /   209 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1288.92 ms /   231 tokens (    5.58 ms per token,   179.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1297.92 ms /   232 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.45 ms /   126 tokens (    5.54 ms per token,   180.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     704.94 ms /   127 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1127.66 ms /   201 tokens (    5.61 ms per token,   178.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.41 ms /   202 tokens\n",
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1405.49 ms /   242 tokens (    5.81 ms per token,   172.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    1415.04 ms /   243 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/100 articles...\n",
      "Vectorstore saved to faiss_db\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "client.build_vectorstore_from_wiki(sample_size=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d7ec448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore loaded and retriever initialized.\n"
     ]
    }
   ],
   "source": [
    "client.load_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abfc0866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =     539.69 ms\n",
      "llama_perf_context_print: prompt eval time =      88.81 ms /     8 tokens (   11.10 ms per token,    90.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =      97.99 ms /     9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9952266216278076, -16.86469268798828, 0.44079113006591797, -12.166587829589844, 2.918513774871826, -1.7121270895004272, 1.0849204063415527, -50.32857894897461, 1.9396106004714966, 6.704031467437744, -2.515451192855835, -1.750204086303711, 15.22193431854248, 0.6257795691490173, -7.34955358505249, 2.6439383029937744, -12.371712684631348, 4.164959907531738, -17.326148986816406, 3.081815481185913, -0.8964845538139343, -0.3004414737224579, -3.47270131111145, -6.245206832885742, -0.5454325675964355, -1.021567940711975, -2.2698965072631836, -15.29393196105957, -0.0789736956357956, -2.1437089443206787, 6.799513816833496, 5.4126877784729, -11.917704582214355, 1.8241513967514038, 0.07318972796201706, 0.7108349204063416, -1.1951684951782227, -2.7781360149383545, -3.081969976425171, 0.49996235966682434, 2.287668466567993, -0.5753247141838074, 1.0012001991271973, -1.489026665687561, -2.2935118675231934, -7.600603103637695, 2.375309944152832, 2.7748098373413086, 1.7590562105178833, 2.028740644454956, -1.5499111413955688, -5.669724941253662, 4.800023078918457, 1.2407944202423096, -1.5686097145080566, 3.7527661323547363, -0.5554340481758118, -3.754683494567871, -0.4325094223022461, -0.2355242818593979, -5.413068771362305, -2.816835641860962, -15.812119483947754, 3.7999491691589355, 4.382754325866699, -6.174947738647461, 1.9128080606460571, -0.4164719879627228, -3.341303586959839, -2.8465986251831055, 0.35086703300476074, 1.3643170595169067, -1.337054967880249, 0.9961527585983276, -0.5385751128196716, 2.9622650146484375, 1.2074873447418213, -2.311743974685669, 0.2793431282043457, 6.069080352783203, 2.2074320316314697, 6.765609264373779, 0.6788661479949951, -1.3294564485549927, 2.2829909324645996, 11.376182556152344, -1.0282129049301147, -5.99466609954834, -1.5929988622665405, 4.021782398223877, -3.775308132171631, 7.005568981170654, 1.4539183378219604, 4.166699409484863, -2.859079122543335, -0.6442031860351562, -2.7160019874572754, -3.048292398452759, -0.685684084892273, -4.015141010284424, -0.5381662249565125, 0.35594430565834045, -4.1134443283081055, -4.989150524139404, -4.090411186218262, 9.721495628356934, -2.6899051666259766, 0.9951114654541016, 10.476396560668945, -6.976810455322266, -0.09276431053876877, 4.649531364440918, -2.3975889682769775, -0.32768514752388, -2.6006946563720703, -4.141170978546143, 1.6269588470458984, -4.255619049072266, -0.9775565266609192, -1.2291126251220703, -2.6962413787841797, -5.217698574066162, 3.6405704021453857, -1.3540124893188477, 3.6659438610076904, 5.093318939208984, -4.35052490234375, 2.1722021102905273, 5.959056377410889, 1.190685510635376, 1.7530145645141602, -0.2281254529953003, -3.5977540016174316, -0.6066855788230896, 1.8861570358276367, 2.067631483078003, -1.025741457939148, 2.858318567276001, 5.819235324859619, 2.7542121410369873, 3.311164379119873, -0.30038636922836304, -1.9639214277267456, 3.903669834136963, 0.308626264333725, -2.165687322616577, -1.7077080011367798, -4.1832122802734375, 2.087482452392578, -8.22357177734375, -1.1126827001571655, -0.902222752571106, -0.40153202414512634, -0.4010484218597412, -2.6706724166870117, -1.5161521434783936, 2.4953949451446533, -5.4969482421875, 4.615926265716553, 2.283686876296997, 4.422821998596191, 6.256451606750488, 1.6821025609970093, -1.7636950016021729, 0.6874397993087769, 4.45118522644043, -5.028634071350098, -2.317047119140625, 1.1150593757629395, -3.5050606727600098, -1.8103314638137817, 2.1197969913482666, -2.4460325241088867, -1.069606065750122, 5.146204471588135, -6.332101345062256, 1.1602851152420044, -1.5614681243896484, -2.0747296810150146, -0.057531073689460754, 3.405190944671631, -0.2621842920780182, 3.617033004760742, -4.775761604309082, 0.9147538542747498, -4.773451328277588, 2.8604159355163574, 1.103332757949829, 1.8136998414993286, -2.2224814891815186, -2.8929197788238525, -2.729980945587158, 1.2171543836593628, -3.4383463859558105, 0.14188069105148315, -1.5426579713821411, 0.856146514415741, -1.1770321130752563, 1.0103586912155151, -8.531007766723633, 1.2574200630187988, 1.0459574460983276, -3.8021204471588135, 1.2193491458892822, 1.1246241331100464, 3.9559237957000732, 2.135049819946289, 1.9093645811080933, -6.188846111297607, -4.983675956726074, 1.496827244758606, 2.190030336380005, -1.9831560850143433, -1.006758213043213, 2.3636317253112793, -2.1309173107147217, -1.6717123985290527, -1.1069467067718506, -0.9456434845924377, 3.888692855834961, 2.152712345123291, 4.292142391204834, 2.1345739364624023, -1.2661646604537964, -0.16125290095806122, -5.539858341217041, 3.2857468128204346, -0.4351677894592285, 3.746382236480713, -1.9442955255508423, 0.23396891355514526, -0.2593838572502136, 1.0382870435714722, 0.6599343419075012, 2.166944980621338, 2.500182628631592, 0.8602508902549744, 0.6052660346031189, 3.6106717586517334, -2.550140380859375, 3.992323875427246, 0.28794267773628235, 0.15377217531204224, -1.2712291479110718, -5.306496620178223, 3.3547613620758057, -0.5895595550537109, 1.2610459327697754, 1.3756310939788818, 2.6160166263580322, 4.108285427093506, -16.61225128173828, -3.980245351791382, 3.4171712398529053, 5.693586826324463, 0.4158453941345215, -1.2893925905227661, -1.9006458520889282, 1.0278892517089844, 1.783605933189392, -0.9374716281890869, -1.4411470890045166, -2.5133986473083496, 0.25496864318847656, -4.881509304046631, -2.4625861644744873, -4.369086265563965, 0.8141003847122192, -0.25073152780532837, -0.5848764181137085, 1.0048320293426514, 0.2562676966190338, 2.4997479915618896, 1.0952115058898926, 1.7865923643112183, 2.677036762237549, 0.4318520426750183, -13.142080307006836, 1.3556500673294067, 1.4104162454605103, -1.788225769996643, -1.5166029930114746, 0.49578699469566345, -3.179461717605591, 3.057260274887085, 4.382822036743164, 0.14498953521251678, 2.3073277473449707, -1.224945068359375, -1.0012919902801514, 0.7456643581390381, 0.3927323520183563, -5.190168380737305, 1.8907246589660645, -0.4818192720413208, -5.021162986755371, 1.5321522951126099, 4.786508560180664, 5.461974143981934, -0.16201412677764893, 3.8393714427948, -4.478050708770752, 0.9979797601699829, -0.9885320067405701, 1.8046492338180542, -3.423720121383667, 2.5744378566741943, -1.8686977624893188, 1.5520343780517578, -0.15557244420051575, -1.2782776355743408, -0.5987744331359863, 0.5568654537200928, -6.031786918640137, -2.074023962020874, -4.4780426025390625, 0.13491761684417725, 0.998045027256012, 0.5897628664970398, 0.9312027096748352, -1.5777589082717896, 3.493642568588257, -2.9450018405914307, -2.2308926582336426, -3.8677964210510254, 0.747770369052887, 3.064732789993286, -1.239664077758789, 1.9291346073150635, -1.0967216491699219, 2.2510435581207275, 5.353758335113525, 3.4465582370758057, 2.390720844268799, 0.26593512296676636, 2.3249855041503906, 3.392367362976074, 2.0924932956695557, 2.701430559158325, -0.9277298450469971, 4.070204257965088, -1.5204484462738037, 6.72592830657959, -4.0769243240356445, -4.403485298156738, 2.4889748096466064, 3.382176160812378, 1.2921576499938965, 4.318751335144043, 2.4666497707366943, -3.0262622833251953, 4.164314270019531, 0.493274062871933, -4.406208038330078, 1.7731688022613525, -0.7538079619407654, -1.4902235269546509, 3.398953914642334, -0.373711496591568, -0.2706151306629181, -2.827279567718506, -3.3930559158325195, 5.513217926025391, 4.574575901031494, -4.223286151885986, -0.7259922027587891, -1.628636360168457, -0.670605480670929, 4.1222310066223145, 3.1442668437957764, -10.23847770690918, 0.22337985038757324, 3.327068328857422, 1.8033454418182373, 1.2360286712646484, 2.5899996757507324, -1.8526604175567627, -2.3508384227752686, 1.3141485452651978, 3.148303747177124, 0.5271286368370056, 0.4959234893321991, -0.08209986984729767, -0.9989457130432129, -3.232759475708008, -0.836683452129364, 1.7092938423156738, 1.1875104904174805, -1.114266276359558, 1.7137532234191895, 0.6033095717430115, 0.38889607787132263, 0.7034329175949097, -1.4472291469573975, 3.9084060192108154, 3.118328332901001, -10.574341773986816, 0.931807816028595, 1.2115509510040283, 1.6712957620620728, 1.708178997039795, -3.1974449157714844, -4.857341289520264, 1.2527257204055786, 0.973137378692627, 0.6014237999916077, 2.6781647205352783, 0.33487987518310547, 2.3613901138305664, -2.3770523071289062, 0.14927370846271515, -1.5254571437835693, -2.86002516746521, -0.9814906120300293, -0.4933846592903137, 4.006114959716797, -2.767943859100342, 0.008421271108090878, -3.923034429550171, 3.46799898147583, -2.0170865058898926, 4.200793266296387, -0.4335065484046936, -0.9841041564941406, -1.7900402545928955, 1.4588576555252075, -1.2745269536972046, -2.02632737159729, -0.057490333914756775, -11.065129280090332, -0.25056806206703186, -1.6540850400924683, -3.7034988403320312, 2.77689528465271, -1.4694788455963135, -1.3835594654083252, 0.3378753662109375, 3.9505560398101807, 0.9281010627746582, 0.37691766023635864, -3.7128968238830566, 1.5147820711135864, 1.119865894317627, 0.17181099951267242, -3.5773415565490723, 0.6737563610076904, 1.8726989030838013, 1.6037336587905884, -0.6673489212989807, -4.786366939544678, 3.9963607788085938, -4.006119251251221, -5.34166145324707, -1.1802724599838257, 0.5456860065460205, -3.1248316764831543, 2.6257388591766357, 2.7510783672332764, 5.34337854385376, 2.321072816848755, -4.417232513427734, 0.8600021600723267, -1.208173155784607, -1.8365755081176758, -0.42841100692749023, -1.925279974937439, -0.9650883674621582, -3.5371713638305664, 2.6042251586914062, -0.7070696949958801, 0.7921218276023865, 0.10998903214931488, 2.732274055480957, -3.041159152984619, 0.0496724508702755, 0.560935914516449, -4.007209777832031, -2.0096585750579834, 0.15082471072673798, 3.626246929168701, 3.601768970489502, -3.954557418823242, -3.353919744491577, -1.1909394264221191, 5.26597261428833, -0.11387506127357483, 2.2426421642303467, -0.29714205861091614, -3.599435806274414, -1.3783737421035767, 3.9168787002563477, 1.5835542678833008, 0.3118272125720978, -5.699824810028076, 0.47697359323501587, 4.129884243011475, 2.4577829837799072, -4.99277400970459, -2.9637677669525146, 2.5245237350463867, -0.27728167176246643, 0.6444819569587708, -1.954874038696289, 4.10734224319458, 1.4059805870056152, 0.3750970959663391, 1.064645767211914, -1.2380802631378174, 3.311265230178833, -0.16318950057029724, -1.329727053642273, -3.4851675033569336, -3.8486456871032715, 2.5029752254486084, -4.611121654510498, 3.089489459991455, -2.118992328643799, 3.5472216606140137, -2.589838981628418, 2.740140199661255, -0.05363389477133751, -3.666264772415161, -0.11875676363706589, -3.167597532272339, -2.2030789852142334, 4.597341060638428, 1.1018948554992676, -5.727247714996338, 3.0915963649749756, -3.526554822921753, -0.6754766702651978, 5.401186943054199, 1.4662760496139526, 0.5522363185882568, 2.3338186740875244, 0.25528255105018616, 1.6594808101654053, 0.133508563041687, 1.507733941078186, -1.9982755184173584, -1.3588505983352661, -2.4444308280944824, -4.70810079574585, -3.5069382190704346, 0.20423272252082825, -0.22493192553520203, 2.7049708366394043, -0.16224253177642822, 2.6163249015808105, 3.5373799800872803, 2.941497564315796, -0.38961783051490784, 6.3527679443359375, -0.1280258595943451, 3.6943318843841553, -3.1313791275024414, -1.1922001838684082, 3.111215591430664, 4.774577617645264, -2.173408031463623, -3.7153944969177246, 1.0742299556732178, 1.8165799379348755, 3.411770820617676, 3.13997745513916, -0.8764622211456299, 0.5958877801895142, -1.9004898071289062, 1.678378701210022, 0.5867350697517395, 3.796053171157837, 0.3667011559009552, 3.126723051071167, 7.008902549743652, 3.268580675125122, -3.8932552337646484, -2.513355255126953, 5.595463275909424, 2.2541911602020264, -2.3934073448181152, -0.539852499961853, 1.0663790702819824, -4.299989700317383, 0.5505124926567078, -1.1454265117645264, -3.4657998085021973, -0.05248904600739479, 4.453425884246826, 0.23991183936595917, -1.5761866569519043, -0.37296366691589355, -2.0237627029418945, 2.0912256240844727, -0.7570459842681885, 2.976524591445923, 5.939031600952148, -5.662892818450928, 0.3975580632686615, -1.510405421257019, 0.14957471191883087, 2.057497024536133, 6.72456169128418, 4.0885539054870605, 1.3606687784194946, -3.0514163970947266, -0.5459769368171692, -6.667004108428955, -0.8554378747940063, -0.36721786856651306, 1.9532437324523926, 1.0406599044799805, 2.6494550704956055, -6.926774978637695, 1.773946762084961, -2.215015172958374, -0.08220784366130829, -1.8272122144699097, 5.319707870483398, -2.6064224243164062, 2.504452705383301, 2.276329278945923, -5.024774551391602, -0.2316620796918869, -0.2477479875087738, -2.0394046306610107, 0.0618743970990181, 0.921053946018219, -6.200129985809326, -5.343725681304932, -4.757595539093018, -2.6230483055114746, -2.0313174724578857, -3.006493091583252, -0.9016073942184448, 2.7047765254974365, -0.7877737879753113, -3.8356964588165283, -0.3788861334323883, -1.119370937347412, -4.604187965393066, -3.465632200241089, -4.597110271453857, 6.321610450744629, -0.45260462164878845, 4.722064971923828, 1.1585079431533813, -1.3710464239120483, -0.07121925055980682, 2.0482218265533447, -2.972172498703003, 1.1937484741210938, 0.07216498255729675, 0.5496525168418884, -1.6509120464324951, -3.662484645843506, -0.010390905663371086, 0.06318271160125732, 4.766472816467285, 6.753085613250732, -2.6822121143341064, 2.627014636993408, -5.456484317779541, 2.503709554672241, -3.6769816875457764, -1.8381690979003906, -5.911593914031982, 1.9406193494796753, 6.559052467346191, 3.2175440788269043, -2.608076572418213, -2.2915995121002197, -4.652566909790039, -1.448084831237793, 3.578160285949707, -3.1544482707977295, -4.65946102142334, -7.531773090362549, -3.7645766735076904, -4.537412643432617, -2.830937385559082, -3.225512742996216, -2.320927858352661, 3.3807992935180664, -5.651443004608154, 3.3041903972625732, -4.768829822540283, -3.908503532409668, 3.382093667984009, 0.7962502241134644, 0.2843576967716217, -2.8476510047912598, -2.076275110244751, -0.035842303186655045, -3.6741113662719727, 0.08391052484512329, 0.3559429347515106, -3.7282721996307373, -3.9206302165985107, -3.2540371417999268, -4.519423484802246, 4.5037031173706055, -0.04000956937670708, -3.8682069778442383, -0.581689178943634, -0.015392763540148735, -3.7881784439086914, -2.1842401027679443, -3.994706392288208, -4.318194389343262, 0.519132673740387, 1.9988473653793335, 2.2647125720977783, 1.033731460571289, 0.1479114592075348, 0.6223960518836975, 3.7031795978546143, -0.2860320210456848, 2.119734525680542, -1.645936369895935, -5.453441619873047, 5.989831924438477, -4.235732555389404, 3.982813596725464, 7.474565029144287, -4.765337944030762, 2.9685921669006348, 3.663276433944702, 4.487347602844238, 1.6354873180389404, 1.3183887004852295, 2.245177745819092, -4.465125560760498, 0.9982928037643433, -1.792883038520813, -0.10581571608781815, -0.4741305410861969, 5.749240875244141, 5.889673233032227, 2.8232288360595703, -4.909786224365234, 1.2680538892745972, 3.4579944610595703, -2.6156270503997803, -0.6869779229164124, 1.7857606410980225, 1.4939301013946533, 0.05497892200946808, 0.9861235618591309, 4.066676616668701, 3.2266812324523926, 4.752328872680664, -4.842889308929443, 3.0631113052368164, 4.532838821411133, -2.7433953285217285, -5.350592136383057, -0.57570481300354, 1.3980991840362549, 1.8361001014709473, 1.7551249265670776, -4.308610916137695, -4.841179847717285, 3.0248615741729736, -1.0951011180877686, 5.126919269561768, -1.3206950426101685, 3.59678316116333, -4.835726261138916, 0.814202070236206, -3.0897419452667236, 2.357055425643921, -2.8218069076538086, 3.0678815841674805, 3.9065492153167725, 4.594244956970215, -2.340768575668335, 2.3328793048858643, -4.625723361968994, -6.864002704620361, 0.12539435923099518, 4.1503987312316895, -0.032580357044935226, 3.8086748123168945, -1.7218008041381836, -0.9097718596458435, 2.9885852336883545, 0.5580856204032898, 0.13068176805973053, 4.7065534591674805, 0.9117993712425232, 1.1978894472122192, 3.037327766418457, -3.8369035720825195, 4.350522994995117, 0.21538178622722626, 4.441908836364746, -3.3534774780273438, 0.5463405251502991, -2.06707763671875, 2.2612502574920654, -4.165812969207764, 3.632268190383911, -5.8073554039001465, -5.058210372924805, 5.096567630767822, 0.028424948453903198, -2.520446538925171, 5.922929286956787, 1.6496413946151733, -4.035646438598633, 7.820371150970459, 6.154574871063232, 0.39779263734817505, 1.6471548080444336, 0.7206231951713562, 6.357724666595459, -4.823351860046387, 2.7387099266052246, -3.754349708557129, -4.7576069831848145, -4.322739601135254, 3.7561464309692383, 2.4731178283691406, 2.7489633560180664, -2.6136178970336914, 3.2580502033233643, 2.7597861289978027, -1.0410884618759155, -5.571250915527344, -3.953562021255493, -5.887686729431152, -1.9162046909332275, 2.1183903217315674, 0.28949639201164246, 8.233386993408203, 2.2311670780181885, -3.5529356002807617, -2.643293619155884, -1.8416061401367188, 7.131979942321777, 2.3351285457611084, -1.4269213676452637, -0.85086590051651, -0.48846563696861267, -4.541535377502441, 2.0962255001068115, -2.6586129665374756, 0.9495123028755188, -0.8836294412612915, 0.44930872321128845, 1.4791151285171509, 3.3238420486450195, -2.257009506225586, 1.6461312770843506, -4.849607467651367, 3.8974621295928955, -1.5526306629180908, 2.4772558212280273, -4.326792240142822, 8.61785888671875, 1.2026883363723755, -3.7826876640319824, -2.053244113922119, -3.1211681365966797, -3.5982766151428223, 6.510812282562256, -0.2243189960718155, 8.017280578613281, 2.1643271446228027, 0.950945258140564, 5.187899589538574, -4.220043659210205, 3.71073579788208, 5.161187648773193, -3.731133460998535, -2.275681734085083, -2.512789249420166, -2.011044979095459, 1.836180329322815, 7.172702789306641, 0.15588003396987915, 5.514421463012695, 8.09901237487793, -3.3998539447784424, -2.997169256210327, 5.374350070953369, 2.926640748977661, -7.436622619628906, -7.034511566162109, -1.6523222923278809, 1.2369799613952637, -3.0074946880340576, 1.8315211534500122, 2.7563438415527344, -9.116050720214844, -5.102133274078369, 4.055469989776611, 2.9950454235076904, 4.590507984161377, -1.692582368850708, 0.7984551191329956, -5.3019185066223145, -0.06852202862501144, -3.7150042057037354, -2.0982139110565186, -0.07140384614467621, 4.781858444213867, -4.459731578826904, -1.5355530977249146, -0.5093459486961365, -0.789536714553833, 8.102843284606934, -5.256875514984131, -1.2448501586914062, -5.749516010284424, -6.028833389282227, -4.274893760681152, -3.5609548091888428, -3.8610758781433105, -2.704477071762085, 2.9139726161956787, -1.9035634994506836, 6.529038906097412, 5.944677352905273, -7.822903156280518, -2.5894052982330322, -2.2777163982391357, -0.19120076298713684, -1.3835922479629517, 2.394542694091797, 2.421032428741455, -2.801820755004883, -1.5972418785095215, 6.072237968444824, -1.7254198789596558, -5.68459939956665, 0.06754796206951141, -1.1668142080307007, 1.9448058605194092, -0.9484390020370483, 3.118873357772827, -5.211850643157959, 3.280510425567627, 4.882993698120117, 6.493790626525879, -3.800312042236328, 2.5117509365081787, -1.1420294046401978, 7.598190784454346, 3.8732213973999023, 6.9952192306518555, -2.630741834640503, -1.892288088798523, 2.985478401184082, 2.433664560317993, -6.471496105194092, -7.9437947273254395, 5.042108058929443, -0.5437279939651489, 1.1976752281188965, 2.2981512546539307, -3.7111027240753174, 3.3262720108032227, 10.3472900390625, 3.669952392578125, 0.9841178059577942, 0.8794299960136414, 2.8301219940185547, 3.0346720218658447, 0.4674162268638611, 2.1204230785369873, -3.3679044246673584, 2.4085652828216553, 2.510449171066284, 2.777186393737793, 4.645934581756592, -3.059882164001465, -2.8493964672088623, -0.19682390987873077, -1.5669375658035278, -6.948241710662842, 3.6433095932006836, 2.6539382934570312, 1.1181501150131226, 0.18531712889671326, -2.276588201522827, 0.7305612564086914, 6.074500560760498, 1.3303896188735962, -4.0264997482299805, 0.026560239493846893, 8.586174964904785, 5.026446342468262, -5.263956546783447, 1.3130379915237427, 1.2676525115966797, 1.3794225454330444, 2.801145553588867, -11.750125885009766, -3.0439460277557373, -8.086867332458496, 6.798789024353027, 1.6708695888519287, -0.9141707420349121, -11.387279510498047, -3.6083474159240723, 1.503063440322876, -2.138742685317993, -0.060467686504125595, -3.5409722328186035, -0.0036644914653152227, -0.8201667666435242, 6.515537738800049, -1.3160024881362915, 3.8281965255737305, 1.269404649734497, -0.538519561290741, -2.859877586364746, -4.557811260223389, 3.7938337326049805, 3.0973575115203857, -6.176447868347168, -14.74587345123291, 0.47113892436027527]\n"
     ]
    }
   ],
   "source": [
    "docs, vecs = client.retrieve(\"What is Abkhaz alphabet?\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff1112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
