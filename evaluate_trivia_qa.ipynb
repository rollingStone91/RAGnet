{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f5df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c82b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from client import Client\n",
    "from server_algo import Server_with_Algorithm\n",
    "from server import Server\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "import validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1f633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwei/RAGnet/client.py:63: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore common_sense_db_0.6b loaded.\n"
     ]
    }
   ],
   "source": [
    "# 1.首先选择要进行实验的client\n",
    "clients = [Client(vectorstore_path=\"common_sense_db_0.6b\")]\n",
    "            # Client(vectorstore_path=\"computer_science_coding_related_db_0.6b\"),\n",
    "            # Client(vectorstore_path=\"law_related_db_0.6b\"), Client(vectorstore_path=\"medicine_related_db_0.6b\")]\n",
    "# 2.对每个client进行加载\n",
    "for c in clients:\n",
    "    c.load_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28adee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weiwei/RAGnet/server.py:21: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  self.llm = ChatOllama(model=model_name)\n"
     ]
    }
   ],
   "source": [
    "# 3.创建server对象，这里需要选择模型，请预先在ollama上部署\n",
    "# server = Server(model_name=\"qwen3:4b\")\n",
    "server = Server(model_name=\"qwen3:4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a68c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 3 个 validation parquet 文件\n"
     ]
    }
   ],
   "source": [
    "# 4.加载测试数据集，这里以trivia_qa为例子，这里取前100个\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = \"./test_dataset/trivia_qa_test\"\n",
    "parquet_files = []\n",
    "\n",
    "# 递归查找所有符合的文件\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        parquet_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "print(f\"找到 {len(parquet_files)} 个 validation parquet 文件\")\n",
    "\n",
    "# 加载所有文件为一个dataset列表\n",
    "datasets_list = load_dataset(\"arrow\", data_files={\"train\": parquet_files}, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd13fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽样选取 100 条（打乱顺序）\n",
    "random_samples = datasets_list.shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70e46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: What is the US state capital of Florida?\n",
      "Gold answers: ['Tallahasee', 'Talahassee', 'Tallahassee', 'Tallahassee, Fl', 'Tallahassee, FL.', 'Tallahassee (FL)', 'Swift Creek Middle School', 'Flag of Tallahassee, FL', 'Tallahasse', 'Tallahassee, Florida', 'Tallahassee, FL', 'Tallahassee, Fl.', 'Capital of Florida', 'UN/LOCODE:USTLH']\n",
      "uncleaned answer: <think>\n",
      "Okay, let's tackle this question: \"What is the US state capital of Florida?\" \n",
      "\n",
      "First, I need to look through the provided contexts and metadata to find the answer. The user has given a list of contexts, so I'll go through them one by one.\n",
      "\n",
      "Starting with Context 1: It mentions \"List of places in California (Z)\" but that's about California, not Florida. So probably not relevant.\n",
      "\n",
      "Context 2 is about Jacksonville, disambiguation. It says Jacksonville is the largest city in Florida. But the question is about the capital, not the largest city. However, maybe there's more info here. The context lists Jacksonville as a city in Florida, but the capital is a different thing. So maybe not directly the answer, but I need to check other contexts.\n",
      "\n",
      "Context 3 talks about Republic of West Florida, which seems unrelated to the capital.\n",
      "\n",
      "Context 4 and 5 mention lakes in Florida, which isn't helpful here.\n",
      "\n",
      "Context 6 is about Ohio cities, so not relevant.\n",
      "\n",
      "Context 7 is about US capitals, but the answer is for Florida's capital, not the US capital. The US capital is Washington, D.C., but that's not what's being asked.\n",
      "\n",
      "Context 8 mentions Spanish language in the US, not helpful.\n",
      "\n",
      "Context 9 and 10 are about museums and islands in Florida, not capitals.\n",
      "\n",
      "Wait, maybe I missed something. Let me check again. The user's question is about Florida's state capital. The answer is Tallahassee. But where is that mentioned in the contexts?\n",
      "\n",
      "Looking through the contexts again, maybe none of them directly state the capital. The only mention of Florida is in Context 2 (Jacksonville as a city) and Context 3 (Republic of West Florida). But the capital isn't mentioned in any of the contexts provided. \n",
      "\n",
      "So according to the given contexts, there's no information about Florida's capital. Therefore, the answer should be that the information isn't present here. But wait, the user might have expected me to know that Tallahassee is the capital, but according to the instructions, I can't use outside knowledge. So if the contexts don't mention it, I have to say I don't know. But wait, maybe I made a mistake. Let me check again.\n",
      "\n",
      "Wait, the user provided Context 2: Jacksonville is the largest city in Florida. But the capital is a different city. The answer is Tallahassee, but if the contexts don't mention it, then I can't use that. So according to the given contexts, there's no mention of the capital of Florida. Therefore, the answer should be \"I don’t know.\" But wait, maybe I need to check if any other context mentions it. Let me check again.\n",
      "\n",
      "Looking at all the contexts again. Context 1 is about California. Context 2 is about Jacksonville in Florida. Context 3 is about West Florida. Context 4 and 5 are about lakes. Context 6 is Ohio. Context 7 is US capitals. Context 8 is Spanish in US. Context 9 and 10 are about museums and islands. No mention of Tallahassee or any other capital. Therefore, the answer is that the information isn't present in the given contexts. So the correct response is \"I don’t know.\"\n",
      "</think>\n",
      "\n",
      "I don’t know.\n",
      "answer:I don’t know.\n",
      "[0] F1=0.00, P=0.00, R=0.00\n",
      "Processing question: What is the title of the second novel featuring Sherlock Holmes, by Arthur Conan Doyle?\n",
      "Gold answers: ['The Sign of Four (disambiguation)', 'The Sign of Four', 'The Sign of Four (film)']\n",
      "uncleaned answer: <think>\n",
      "Okay, let's tackle this question. The user is asking for the title of the second novel featuring Sherlock Holmes by Arthur Conan Doyle. \n",
      "\n",
      "First, I need to look through the provided contexts to find any mentions of Sherlock Holmes novels. Let's go through each context one by one.\n",
      "\n",
      "Context 2 mentions \"A Study in Scarlet\" as an 1888 detective-mystery novel by Sir Arthur Conan Doyle, introducing Sherlock Holmes. That's the first novel. The question is about the second one. \n",
      "\n",
      "Looking further, Context 8 talks about \"The Sign of Four\" as a novel that included a romantic plot. It says that \"The Sign of Four\" was the first novel with a romantic element, but the second novel might be the one that follows. However, the context also mentions that after \"The Sign of Four,\" there's \"The Adventure of the Norwood Builder,\" but that's a short story, not a novel. \n",
      "\n",
      "Wait, the user is asking for the second novel. The first is \"A Study in Scarlet,\" then the second would be \"The Sign of Four.\" But I need to confirm if there's any other mention. \n",
      "\n",
      "Looking at Context 8 again: \"The Sign of Four\" is mentioned as including a romantic plot, and then it says that Watson's marriage to Mary was killed off in the next novel. Wait, no, the context says that \"The Sign of Four\" had a happy ending with Watson and Mary marrying, but then in the next story, Watson's wife died. However, the novels after \"The Sign of Four\" would be \"The Hound of the Baskervilles,\" \"The Adventure of the Speckled Band,\" etc. But the user is asking for the second novel. \n",
      "\n",
      "Wait, the first novel is \"A Study in Scarlet,\" the second is \"The Sign of Four.\" The context in Context 2 explicitly states that \"A Study in Scarlet\" was the first, and then \"The Sign of Four\" comes next. So the answer should be \"The Sign of Four.\"\n",
      "</think>\n",
      "\n",
      "The second novel featuring Sherlock Holmes by Arthur Conan Doyle is \"The Sign of Four.\" \n",
      "\n",
      "Step-by-Step Reasoning:\n",
      "1. Identify contexts mentioning Sherlock Holmes novels. Context 2 explicitly states \"A Study in Scarlet\" (1888) as the first novel introducing Sherlock Holmes.\n",
      "2. Context 8 confirms \"The Sign of Four\" as the next novel in the series, featuring a romantic plot line involving Watson and Mary Morstan.\n",
      "3. The question asks for the second novel, so \"The Sign of Four\" follows \"A Study in Scarlet\" as the immediate successor. \n",
      "\n",
      "Answer: The Sign of Four.\n",
      "answer:The Sign of Four.\n",
      "Processing question: Which book by Harper Lee won the 1961 Pulitzer Prize for Fiction?\n",
      "Gold answers: ['To Assassinate a Mockingbird', 'To Kill a Mockingbird (novel)', 'To Kill a Mocking Bird', 'To Kill a Mocking-Bird', 'To Kill A Mockingbird', 'Tkam', 'TKAM', 'To kill a mockingbird', 'TKMB', 'Maycomb, AL', 'Maycomb disease', 'Maycomb', 'To Kill a Mockingbird (play)', 'To Klil A Mockingbird', 'How to Kill a Mockingbird', 'Prejudices in mockingbird', 'Tkmb', 'Tkamb', 'To Kill A Mocking Bird', 'Maycomb, Alabama', 'To Kill a Mockingbird', 'To kill a mockingbird book', 'To kill a Mocking bird']\n"
     ]
    }
   ],
   "source": [
    "# 5.进行评估，并生成csv文件\n",
    "validation.evaluate_datasets(clients, server, samples=random_samples, top_k=10,\n",
    "                        output_csv=\"trivia_qa_results_baseline_topk_10.csv\", dataset_name=\"trivia_qa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
